{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Tensorboard logging and visualization\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list that specifies convolution-pooling architecture; \n",
    "# list index indicate layer position in stack; \n",
    "# a pooling layer is represented by a tuple: (pooling type, kernel_size, strides) \n",
    "# a convolution layer is represented by a typle: (filter_height, filter_width, depth)\n",
    "layers = [(5, 5, 6),\n",
    "          ('max', (1,2,2,1), (1,2,2,1)),\n",
    "          (5, 5, 16), \n",
    "          ('max', (1,2,2,1), (1,2,2,1)),\n",
    "          (5, 5, 60),\n",
    "          ('max', (1,2,2,1), (1,2,2,1))]  \n",
    "\n",
    "def conv_pool(x, layers):\n",
    "    out = x\n",
    "    n_conv, n_pool = 0, 0\n",
    "    prev_depth = int(x.shape[3])\n",
    "    for l in layers:\n",
    "        if type(l[0]) == int:\n",
    "            n_conv += 1\n",
    "            with tf.variable_scope('conv_{}'.format(n_conv), reuse = tf.AUTO_REUSE):\n",
    "                w = tf.get_variable('filter', initializer=tf.truncated_normal((l[0], l[1], prev_depth, l[2]),0,0.1))\n",
    "                b = tf.get_variable('bias', initializer=tf.zeros(l[2]))  \n",
    "                out = tf.nn.relu(tf.nn.conv2d(out, w, strides=(1,1,1,1), padding='SAME') + b)\n",
    "            prev_depth = l[2]\n",
    "        elif l[0] == 'max':\n",
    "            n_pool += 1\n",
    "            out = tf.nn.max_pool(out, l[1], l[2], padding='SAME', name='pool_{}'.format(n_pool))\n",
    "        elif l[0] == 'avg':\n",
    "            n_pool += 1\n",
    "            out = tf.nn.avg_pool(out, l[1], l[2], padding='SAME', name='pool_{}'.format(n_pool))\n",
    "    return out\n",
    "\n",
    "# get all frames from video downscaled by a factor\n",
    "# return an ndarray of shape (n_frames, height, width, channels)\n",
    "def get_frames(path, n_frames, downscale_factor):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    seq = []\n",
    "    count = 0\n",
    "    while True:\n",
    "        success,frame = cap.read()\n",
    "        if count == n_frames or not success:\n",
    "            break\n",
    "        # downscale frame\n",
    "        width = int(frame.shape[1] / downscale_factor)\n",
    "        height = int(frame.shape[0] / downscale_factor)\n",
    "        seq.append(cv2.resize(frame, (width, height), interpolation = cv2.INTER_AREA))\n",
    "        count += 1\n",
    "    return np.stack(seq)\n",
    "\n",
    "# mini-batch generator\n",
    "def next_batch(path, labels, n_batches, batch_size, n_frames, downscale_factor):\n",
    "    for i in range(n_batches):\n",
    "        x_batch, y_batch = [], []\n",
    "        for j in range(0, batch_size):\n",
    "            x_batch.append(get_frames(path.format(i*batch_size+j), n_frames, downscale_factor))\n",
    "            y_batch.append(labels[i*batch_size+j])\n",
    "        x_batch = np.stack(x_batch)\n",
    "        yield x_batch, y_batch\n",
    "        \n",
    "# generate feature maps for each video in mini-batch\n",
    "# x has shape (batch_size, n_frames, height, width, channels)\n",
    "def get_feature_maps(x):\n",
    "    instances = []\n",
    "    for i in range(x.shape[0]):\n",
    "        instances.append(tf.contrib.layers.flatten(conv_pool(x[i, :, :, :, :], layers)))\n",
    "    return tf.stack(instances, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ysqyang/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "(5, 50, 18000)\n"
     ]
    }
   ],
   "source": [
    "path = '/home/ysqyang/Dropbox/BenchPress ({}).avi'\n",
    "\n",
    "height, width, channels = 240, 320, 3\n",
    "downscale_factor = 2\n",
    "n_frames = 50\n",
    "n_classes = 3\n",
    "n_batches, batch_size = 4, 5\n",
    "n_hidden = 200 # number of hidden cells in LSTM\n",
    "\n",
    "X = tf.placeholder(dtype=tf.float32, \n",
    "                   shape=(batch_size, n_frames, int(height/downscale_factor), int(width/downscale_factor), channels))\n",
    "y = tf.placeholder(dtype=tf.int32, shape=(batch_size,))\n",
    "\n",
    "labels = np.random.randint(0, high=2, size=20) \n",
    "\n",
    "X_features = get_feature_maps(X)\n",
    "print(X_features.shape)\n",
    "\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(n_hidden)\n",
    "output, _ = tf.nn.dynamic_rnn(cell, X_features, initial_state = cell.zero_state(batch_size, dtype=tf.float32))\n",
    "\n",
    "with tf.variable_scope('out', reuse = tf.AUTO_REUSE):\n",
    "    w = tf.get_variable('weight', shape=(n_hidden, n_classes))\n",
    "    b = tf.get_variable('bias', initializer=tf.zeros(n_classes))\n",
    "    pred = tf.matmul(output[:,-1,:], w) + b\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "training_op = optimizer.minimize(loss)\n",
    "loss_summary = tf.summary.scalar('loss', loss)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 50, 120, 160, 3)\n",
      "[[ 0.29842168 -0.09643143  0.00508654]\n",
      " [ 0.5214707   0.47156107  0.1378365 ]\n",
      " [ 0.18558514  0.2355089   0.29197365]\n",
      " [ 0.42201093  0.23631538  0.06043892]\n",
      " [ 0.28713176  0.2371669  -0.12906916]]\n",
      "1.0569654\n",
      "(5, 50, 120, 160, 3)\n",
      "[[ 1.1509163   0.4360936   0.43221557]\n",
      " [ 1.03426     0.4587123   0.29691675]\n",
      " [ 1.0846407   0.38448873  0.3850946 ]\n",
      " [ 1.0154705  -0.57733554  0.43001953]\n",
      " [ 0.89260465 -0.2639995   0.37984625]]\n",
      "0.942766\n",
      "(5, 50, 120, 160, 3)\n",
      "[[0.80285484 0.48759004 0.6547006 ]\n",
      " [0.9006973  1.0073901  0.8847123 ]\n",
      " [0.7121032  0.75908434 0.5425482 ]\n",
      " [0.64985144 0.67178065 0.464167  ]\n",
      " [0.7529783  0.5797617  0.7808617 ]]\n",
      "1.0583283\n",
      "(5, 50, 120, 160, 3)\n",
      "[[0.85404426 0.5370007  0.5224493 ]\n",
      " [0.81446964 0.5452881  0.52517176]\n",
      " [0.82173425 0.5437668  0.524672  ]\n",
      " [0.81446964 0.5452881  0.52517176]\n",
      " [0.8144697  0.545288   0.52517194]]\n",
      "1.0765269\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    batch_num = 0\n",
    "    for X_batch, y_batch in next_batch(path, labels, n_batches, batch_size, 50, 2):      \n",
    "        print(X_batch.shape)\n",
    "        batch_num += 1\n",
    "        summary_str = loss_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        file_writer.add_summary(summary_str, batch_num)\n",
    "        sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        saver.save(sess, '/tmp/after_batch_{}.ckpt'.format(batch_num))\n",
    "        print(pred.eval(feed_dict={X: X_batch, y: y_batch}))\n",
    "        print(loss.eval(feed_dict={X: X_batch, y: y_batch}))\n",
    "    \n",
    "    saver.save(sess, '/tmp/final.ckpt')\n",
    "\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
