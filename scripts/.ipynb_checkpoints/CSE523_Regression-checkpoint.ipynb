{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "from decimal import Decimal\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier as ovr\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, auc, precision_score, recall_score, f1_score \n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dr = '~/Projects/video-qoe-labeling/new-data/Skype/'\n",
    "dtype = {'BitRate': np.float64, 'FreezeRatio': np.float64, 'Freezes': np.int32, 'Freezelength': np.float64, 'Quality': np.float64}\n",
    "df_reg = pd.read_table(dr + 'all-data.txt', delim_whitespace=True, dtype = dtype)\n",
    "df_reg['BitRate'] /= 100  # transforming BitRate to percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get (X, y) and set fold\n",
    "features = ['BitRate', 'FreezeRatio', 'Freezes', 'Freezelength']\n",
    "X, y = np.array(df_reg[features]), np.array(df_reg['Quality'])\n",
    "mse = {}\n",
    "mae = {}\n",
    "fold = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regressors = {'Random Forest': RandomForestRegressor(random_state = 1), \n",
    "               'Nearest Neighbors': KNeighborsRegressor(),\n",
    "               'SVM': SVR(),\n",
    "               'MLP': MLPRegressor(random_state = 1, max_iter = 10000),\n",
    "               'AdaBoost': AdaBoostRegressor(random_state = 1)\n",
    "              }\n",
    "\n",
    "params = {'Random Forest': {'n_estimators': range(1, 21), 'criterion': ('mse', 'mae')},\n",
    "          'Nearest Neighbors': {'n_neighbors':range(1, 11)},\n",
    "          'SVM': {'kernel':('poly', 'rbf', 'sigmoid'), 'C':[0.1, 1, 10]},\n",
    "          'MLP': {'hidden_layer_sizes': [(10,), (20,), (40,), (80,), (10,10), (20, 20), (40, 40), (80, 80)], \n",
    "                  'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "                  'activation': ('logistic', 'tanh', 'relu'), \n",
    "                  'solver': ('lbfgs', 'sgd', 'adam')},\n",
    "          'AdaBoost': {'n_estimators': [10, 20, 40, 80], 'learning_rate': [0.01, 0.1, 1, 10]}\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# function for obtaining best estimator using grid search\n",
    "def grid_search_reg(estimator, params, scoring):\n",
    "    reg = GridSearchCV(estimator, params, scoring = scoring)\n",
    "    reg.fit(X, y)\n",
    "    return (reg.best_estimator_, reg.best_score_)\n",
    "\n",
    "# function for performing k-fold cross validation on the regressors\n",
    "def k_Fold_CV_reg(estimator, n):\n",
    "    mse = []\n",
    "    kf = KFold(n_splits = n)\n",
    "    for train, test in kf.split(X):\n",
    "        pred = estimator.fit(X[train], y[train]).predict(X[test])\n",
    "        mse.append(mean_squared_error(y[test], pred))\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best_regressors_mse = {}\n",
    "best_regressors_mae = {}\n",
    "for k in regressors:\n",
    "    best_regressors_mse[k], _ = grid_search_reg(regressors[k], params[k], 'neg_mean_squared_error')\n",
    "    best_regressors_mae[k], _ = grid_search_reg(regressors[k], params[k], 'neg_mean_absolute_error')\n",
    "    mse[k] = k_Fold_CV_reg(best_regressors_mse[k], fold)\n",
    "    mae[k] = k_Fold_CV_reg(best_regressors_mae[k], fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for k, v in mse.items():\n",
    "    print(k)\n",
    "    rmse = np.sqrt(v)\n",
    "    print(\"{}_fold RMSE: \".format(fold), np.around(rmse, decimals = 3))\n",
    "    print(\"Average RMSE: {0:0.3f}\".format(np.mean(rmse)))\n",
    "    print(\"#################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for k, v in mae.items():\n",
    "    print(k)\n",
    "    print(\"{}_fold MAE: \".format(fold), np.around(v, decimals = 3))\n",
    "    print(\"Average MAE: {0:0.3f}\".format(np.mean(v)))\n",
    "    print(\"#################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_regressors_mse = {'AdaBoost': AdaBoostRegressor(base_estimator=None, learning_rate=0.1, loss='linear',\n",
    "          n_estimators=10, random_state=1),\n",
    " 'MLP': MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "        hidden_layer_sizes=(10,), learning_rate='constant',\n",
    "        learning_rate_init=0.001, max_iter=10000, momentum=0.9,\n",
    "        nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
    "        solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
    "        warm_start=False),\n",
    " 'Nearest Neighbors': KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
    "           weights='uniform'),\n",
    " 'Random Forest': RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=None,\n",
    "            max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
    "            oob_score=False, random_state=1, verbose=0, warm_start=False),\n",
    " 'SVM': SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
    "   kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)}\n",
    "\n",
    "best_regressors_mae = {'AdaBoost': AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='linear',\n",
    "          n_estimators=10, random_state=1),\n",
    " 'MLP': MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "        hidden_layer_sizes=(10,), learning_rate='constant',\n",
    "        learning_rate_init=0.001, max_iter=10000, momentum=0.9,\n",
    "        nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
    "        solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
    "        warm_start=False),\n",
    " 'Nearest Neighbors': KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
    "           weights='uniform'),\n",
    " 'Random Forest': RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=None,\n",
    "            max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
    "            oob_score=False, random_state=1, verbose=0, warm_start=False),\n",
    " 'SVM': SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
    "   kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mserr = {}\n",
    "for k, v in best_regressors_mse.items():\n",
    "    pred = v.fit(X_train, y_train).predict(X_test)\n",
    "    mserr[k] = mean_squared_error(y_test, pred)\n",
    "\n",
    "maerr = {}\n",
    "for k, v in best_regressors_mae.items():\n",
    "    pred = v.fit(X_train, y_train).predict(X_test)\n",
    "    maerr[k] = mean_absolute_error(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for k, v in mserr.items():\n",
    "    print(k)\n",
    "    print(\"MSE: \", np.around(v, decimals = 3))\n",
    "    print(\"#################################\")\n",
    "    \n",
    "for k, v in maerr.items():\n",
    "    print(k)\n",
    "    print(\"MAE: \", np.around(v, decimals = 3))\n",
    "    print(\"#################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_label(score, thresh):\n",
    "    label = []\n",
    "    for s in np.nditer(score):\n",
    "        if s < thresh[0]:\n",
    "            label.append(0)\n",
    "        elif s < thresh[1]:\n",
    "            label.append(1)\n",
    "        else:\n",
    "            label.append(2)\n",
    "    return np.array(label, dtype = int) \n",
    "\n",
    "def optimize_thresh(regressor, X_train, y_train, X_test, y_test, t1_range, top_num):\n",
    "    i = 0\n",
    "    thresh_accuracy = []\n",
    "    model = regressor.fit(X_train, y_train)\n",
    "    pred = model.predict(X_train) \n",
    "    # find optimal thresholds from training set\n",
    "    for t1 in t1_range:\n",
    "        for t2 in np.arange(t1+1, 4.01, 0.05):\n",
    "            y_label_true = to_label(y_train, (t1, t2))\n",
    "            y_label_pred = to_label(pred, (t1, t2))\n",
    "            thresh_accuracy.append(((t1, t2), accuracy_score(y_label_true, y_label_pred)))\n",
    "    thresh_accuracy.sort(key = lambda x:x[1], reverse = True)\n",
    "    # determine average thresholds\n",
    "    thresh = [x[0] for x in thresh_accuracy[:top_num]]\n",
    "    avg_thresh = np.average(thresh, axis = 0) \n",
    "    # find accuracy on test set\n",
    "    pred = model.predict(X_test)\n",
    "    y_label_true = to_label(y_test, avg_thresh)\n",
    "    y_label_pred = to_label(pred, avg_thresh)   \n",
    "    return avg_thresh, accuracy_score(y_label_true, y_label_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t1_range = np.arange(2, 3.01, 0.05)\n",
    "thresh_accuracy_mse = {}\n",
    "\n",
    "for k, reg in best_regressors_mse.items():\n",
    "    thresh_accuracy_mse[k] = [optimize_thresh(reg, X_train[i], y_train[i], X_test[i], y_test[i], t1_range, 1) for i in range(split_num)]\n",
    "\n",
    "thresh_accuracy_mae = {}\n",
    "for k, reg in best_regressors_mae.items():\n",
    "    thresh_accuracy_mae[k] = [optimize_thresh(reg, X_train[i], y_train[i], X_test[i], y_test[i], t1_range, 1) for i in range(split_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regressors with minimized mean squared error\n",
      "AdaBoost\n",
      "Optimal thresholds: [ 2.18  3.58], Test accuracy: 0.853\n",
      "#################################\n",
      "MLP\n",
      "Optimal thresholds: [ 2.36  3.71], Test accuracy: 0.867\n",
      "#################################\n",
      "Nearest Neighbors\n",
      "Optimal thresholds: [ 2.31  3.67], Test accuracy: 0.747\n",
      "#################################\n",
      "Random Forest\n",
      "Optimal thresholds: [ 2.12  3.98], Test accuracy: 0.893\n",
      "#################################\n",
      "SVM\n",
      "Optimal thresholds: [ 2.33  3.95], Test accuracy: 0.84\n",
      "#################################\n",
      "\n",
      "regressors with minimized mean absolute error\n",
      "AdaBoost\n",
      "Optimal thresholds: [ 2.05  3.76], Test accuracy: 0.907\n",
      "#################################\n",
      "MLP\n",
      "Optimal thresholds: [ 2.36  3.71], Test accuracy: 0.867\n",
      "#################################\n",
      "Nearest Neighbors\n",
      "Optimal thresholds: [ 2.31  3.67], Test accuracy: 0.747\n",
      "#################################\n",
      "Random Forest\n",
      "Optimal thresholds: [ 2.12  3.98], Test accuracy: 0.893\n",
      "#################################\n",
      "SVM\n",
      "Optimal thresholds: [ 2.33  3.95], Test accuracy: 0.84\n",
      "#################################\n"
     ]
    }
   ],
   "source": [
    "print('regressors with minimized mean squared error')\n",
    "for k, v in thresh_accuracy_mse.items():\n",
    "    print(k)\n",
    "    print(\"Optimal thresholds: {}, Test accuracy: {}\".format(np.around(v[0], decimals = 2), np.around(v[1], decimals = 3)))\n",
    "    print(\"#################################\")\n",
    "    \n",
    "print()\n",
    "print('regressors with minimized mean absolute error')\n",
    "for k, v in thresh_accuracy_mae.items():\n",
    "    print(k)\n",
    "    print(\"Optimal thresholds: {}, Test accuracy: {}\".format(np.around(v[0], decimals = 2), np.around(v[1], decimals = 3)))\n",
    "    print(\"#################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S2, S6 and Pixel Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {}\n",
    "df['s2'] = pd.read_table(dr + 's2.txt', delim_whitespace=True, dtype = dtype)\n",
    "df['s6'] = pd.read_table(dr + 's6.txt', delim_whitespace=True, dtype = dtype)\n",
    "df['px'] = pd.read_table(dr + 'pixel.txt', delim_whitespace=True, dtype = dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for d in df.values():\n",
    "    d['BitRate'] /= 100     # transforming BitRate to percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = {}\n",
    "y = {}\n",
    "# y_bin = {}\n",
    "for k, d in df.items():\n",
    "    X[k], y[k] = np.array(d[features]), np.array(d['Quality'])\n",
    "    # y_bin[k] = label_binarize(y[k], classes = classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#mae = {}\n",
    "\n",
    "thresh = {}\n",
    "accuracy = {}\n",
    "'''\n",
    "acc = {}\n",
    "prec = {}\n",
    "recl = {}\n",
    "f1 = {}\n",
    "'''\n",
    "for r, reg in best_regressors_mae.items():\n",
    "    #mae[r] = {}\n",
    "    thresh[r] = {}\n",
    "    '''\n",
    "    acc[r] = {}\n",
    "    prec[r] = {}\n",
    "    recl[r] = {} \n",
    "    f1[r] = {}    \n",
    "    '''\n",
    "    for k in X.keys():\n",
    "        #mae[r][k] = {}\n",
    "        thresh[r][k] = {}\n",
    "        '''\n",
    "        acc[r][k] = {}\n",
    "        prec[r][k] = {}\n",
    "        recl[r][k] = {} \n",
    "        f1[r][k] = {}\n",
    "        '''\n",
    "        for k1 in X.keys():\n",
    "            if k1 != k: # train and test on other datasets\n",
    "                #pred = reg.fit(X[k], y[k]).predict(X[k1])\n",
    "                #mae[r][k][k1] = mean_absolute_error(y[k1], pred)\n",
    "                thresh[r][k][k1] = optimize_thresh(reg, X[k], y[k], X[k1], y[k1], t1_range, 10)\n",
    "                #y_label_true = to_label(y[k1], thresh_accuracy_mae[r][0])\n",
    "                #y_label_pred = to_label(pred, thresh_accuracy_mae[r][0])\n",
    "                #acc[r][k][k1] = accuracy_score(y_label_true, y_label_pred)\n",
    "                #prec[r][k][k1] = precision_score(y_label_true, y_label_pred, average = None) \n",
    "                #recl[r][k][k1] = recall_score(y_label_true, y_label_pred, average = None) \n",
    "                #f1[r][k][k1] = f1_score(y_label_true, y_label_pred, average = None)  \n",
    "            else:    # train and test on itself\n",
    "                X_tr, X_te, y_tr, y_te = train_test_split(X[k], y[k], test_size = 0.25, random_state = 1)\n",
    "                thresh[r][k][k] = optimize_thresh(reg, X_tr, y_tr, X_te, y_te, t1_range, 10)\n",
    "                #pred = reg.fit(X_tr, y_tr).predict(X_te)\n",
    "                #mae[r][k][k1] = mean_absolute_error(y_te, pred)\n",
    "                #y_label_true = to_label(y_te, thresh_accuracy_mae[r][0])\n",
    "                #y_label_pred = to_label(pred, thresh_accuracy_mae[r][0])\n",
    "                #acc[r][k][k] = accuracy_score(y_label_true, y_label_pred)\n",
    "                #prec[r][k][k] = precision_score(y_label_true, y_label_pred, average = None) \n",
    "                #recl[r][k][k] = recall_score(y_label_true, y_label_pred, average = None) \n",
    "                #f1[r][k][k] = f1_score(y_label_true, y_label_pred, average = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def print_results(dic, title):\n",
    "    print('#################################')\n",
    "    print('{} results:'.format(title))\n",
    "    for k, v in dic.items():\n",
    "        print(k)\n",
    "        for k1, v1 in v.items():\n",
    "            print(\"training set: {}\".format(k1))\n",
    "            for k2, v2 in v1.items():\n",
    "                print(\"optimal thresholds on {}: {}, {}\".format(k2, np.around(v2[0][0], decimals = 3), np.around(v2[0][1], decimals = 3)))\n",
    "                print(\"optimal accuracy on {}: {}\".format(k2, np.around(v2[1], decimals = 3)))\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = {}\n",
    "prec = {}\n",
    "recl = {}\n",
    "f1 = {}\n",
    "for r, reg in best_regressors_mae.items():\n",
    "    acc[r] = {}\n",
    "    prec[r] = {}\n",
    "    recl[r] = {} \n",
    "    f1[r] = {}    \n",
    "    for k in X.keys():\n",
    "        acc[r][k] = {}\n",
    "        prec[r][k] = {}\n",
    "        recl[r][k] = {} \n",
    "        f1[r][k] = {}\n",
    "        for k1 in X.keys():\n",
    "            if k1 != k: # train and test on other datasets\n",
    "                pred = reg.fit(X[k], y[k]).predict(X[k1])\n",
    "                y_label_true = to_label(y[k1], thresh_accuracy[r][0])\n",
    "                y_label_pred = to_label(pred, thresh_accuracy[r][0])\n",
    "                acc[r][k][k1] = accuracy_score(y_label_true, y_label_pred)\n",
    "                prec[r][k][k1] = precision_score(y_label_true, y_label_pred, average = None) \n",
    "                recl[r][k][k1] = recall_score(y_label_true, y_label_pred, average = None) \n",
    "                f1[r][k][k1] = f1_score(y_label_true, y_label_pred, average = None)  \n",
    "            else:    # train and test on itself\n",
    "                X_tr, X_te, y_tr, y_te = train_test_split(X[k], y[k], test_size = 0.25, random_state = 1)\n",
    "                pred = reg.fit(X_tr, y_tr).predict(X_te)\n",
    "                y_label_true = to_label(y_te, thresh_accuracy[r][0])\n",
    "                y_label_pred = to_label(pred, thresh_accuracy[r][0])\n",
    "                acc[r][k][k] = accuracy_score(y_label_true, y_label_pred)\n",
    "                prec[r][k][k] = precision_score(y_label_true, y_label_pred, average = None) \n",
    "                recl[r][k][k] = recall_score(y_label_true, y_label_pred, average = None) \n",
    "                f1[r][k][k] = f1_score(y_label_true, y_label_pred, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_results(dic, title):\n",
    "    print('#################################')\n",
    "    print('{} results:'.format(title))\n",
    "    for k, v in dic.items():\n",
    "        print(k)\n",
    "        for k1, v1 in v.items():\n",
    "            print(\"training set: {}\".format(k1))\n",
    "            for k2, v2 in v1.items():\n",
    "                print(\"{} on {}: {}\".format(title, k2, np.around(v2, decimals = 3)))\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################\n",
      "accuracy results:\n",
      "AdaBoost\n",
      "training set: s2\n",
      "accuracy on s2: 0.68\n",
      "accuracy on s6: 0.79\n",
      "accuracy on px: 0.72\n",
      "training set: s6\n",
      "accuracy on s2: 0.85\n",
      "accuracy on s6: 0.88\n",
      "accuracy on px: 0.65\n",
      "training set: px\n",
      "accuracy on s2: 0.78\n",
      "accuracy on s6: 0.64\n",
      "accuracy on px: 0.84\n",
      "\n",
      "MLP\n",
      "training set: s2\n",
      "accuracy on s2: 0.76\n",
      "accuracy on s6: 0.74\n",
      "accuracy on px: 0.79\n",
      "training set: s6\n",
      "accuracy on s2: 0.81\n",
      "accuracy on s6: 0.84\n",
      "accuracy on px: 0.77\n",
      "training set: px\n",
      "accuracy on s2: 0.79\n",
      "accuracy on s6: 0.7\n",
      "accuracy on px: 0.84\n",
      "\n",
      "Nearest Neighbors\n",
      "training set: s2\n",
      "accuracy on s2: 0.56\n",
      "accuracy on s6: 0.64\n",
      "accuracy on px: 0.68\n",
      "training set: s6\n",
      "accuracy on s2: 0.72\n",
      "accuracy on s6: 0.56\n",
      "accuracy on px: 0.64\n",
      "training set: px\n",
      "accuracy on s2: 0.68\n",
      "accuracy on s6: 0.6\n",
      "accuracy on px: 0.68\n",
      "\n",
      "Random Forest\n",
      "training set: s2\n",
      "accuracy on s2: 0.76\n",
      "accuracy on s6: 0.8\n",
      "accuracy on px: 0.76\n",
      "training set: s6\n",
      "accuracy on s2: 0.86\n",
      "accuracy on s6: 0.92\n",
      "accuracy on px: 0.71\n",
      "training set: px\n",
      "accuracy on s2: 0.79\n",
      "accuracy on s6: 0.7\n",
      "accuracy on px: 0.88\n",
      "\n",
      "SVM\n",
      "training set: s2\n",
      "accuracy on s2: 0.6\n",
      "accuracy on s6: 0.79\n",
      "accuracy on px: 0.79\n",
      "training set: s6\n",
      "accuracy on s2: 0.82\n",
      "accuracy on s6: 0.72\n",
      "accuracy on px: 0.78\n",
      "training set: px\n",
      "accuracy on s2: 0.75\n",
      "accuracy on s6: 0.69\n",
      "accuracy on px: 0.84\n",
      "\n",
      "\n",
      "#################################\n",
      "precision results:\n",
      "AdaBoost\n",
      "training set: s2\n",
      "precision on s2: [ 1.     1.     0.273]\n",
      "precision on s6: [ 0.905  0.682  0.722]\n",
      "precision on px: [ 0.643  0.656  0.825]\n",
      "training set: s6\n",
      "precision on s2: [ 1.     0.8    0.757]\n",
      "precision on s6: [ 1.     0.8    0.833]\n",
      "precision on px: [ 0.548  0.559  0.829]\n",
      "training set: px\n",
      "precision on s2: [ 1.     0.649  0.763]\n",
      "precision on s6: [ 1.     0.419  0.694]\n",
      "precision on px: [ 1.   0.8  0.8]\n",
      "\n",
      "MLP\n",
      "training set: s2\n",
      "precision on s2: [ 1.     0.8    0.545]\n",
      "precision on s6: [ 0.925  0.471  0.674]\n",
      "precision on px: [ 0.9    0.594  0.875]\n",
      "training set: s6\n",
      "precision on s2: [ 1.     0.778  0.707]\n",
      "precision on s6: [ 1.     1.     0.667]\n",
      "precision on px: [ 0.739  0.586  0.896]\n",
      "training set: px\n",
      "precision on s2: [ 1.     0.579  0.759]\n",
      "precision on s6: [ 0.935  0.4    0.705]\n",
      "precision on px: [ 1.     0.6    0.875]\n",
      "\n",
      "Nearest Neighbors\n",
      "training set: s2\n",
      "precision on s2: [ 1.     0.571  0.2  ]\n",
      "precision on s6: [ 1.     0.441  0.553]\n",
      "precision on px: [ 0.947  0.564  0.667]\n",
      "training set: s6\n",
      "precision on s2: [ 0.969  0.586  0.615]\n",
      "precision on s6: [ 1.     0.417  0.556]\n",
      "precision on px: [ 0.84   0.514  0.632]\n",
      "training set: px\n",
      "precision on s2: [ 1.     0.512  0.667]\n",
      "precision on s6: [ 1.     0.404  0.64 ]\n",
      "precision on px: [ 1.     0.444  0.727]\n",
      "\n",
      "Random Forest\n",
      "training set: s2\n",
      "precision on s2: [ 1.     1.     0.333]\n",
      "precision on s6: [ 0.905  0.679  0.767]\n",
      "precision on px: [ 0.667  0.727  0.85 ]\n",
      "training set: s6\n",
      "precision on s2: [ 1.     0.88   0.738]\n",
      "precision on s6: [ 1.     1.     0.778]\n",
      "precision on px: [ 0.586  0.667  0.842]\n",
      "training set: px\n",
      "precision on s2: [ 1.     0.667  0.757]\n",
      "precision on s6: [ 1.     0.5    0.649]\n",
      "precision on px: [ 1.     0.75   0.923]\n",
      "\n",
      "SVM\n",
      "training set: s2\n",
      "precision on s2: [ 1.     0.5    0.385]\n",
      "precision on s6: [ 0.949  0.625  0.711]\n",
      "precision on px: [ 0.909  0.615  0.827]\n",
      "training set: s6\n",
      "precision on s2: [ 1.     0.733  0.736]\n",
      "precision on s6: [ 1.     0.6    0.615]\n",
      "precision on px: [ 0.808  0.615  0.854]\n",
      "training set: px\n",
      "precision on s2: [ 1.     0.5    0.672]\n",
      "precision on s6: [ 1.    0.35  0.64]\n",
      "precision on px: [ 1.     0.667  0.824]\n",
      "\n",
      "\n",
      "#################################\n",
      "recall results:\n",
      "AdaBoost\n",
      "training set: s2\n",
      "recall on s2: [ 1.     0.333  1.   ]\n",
      "recall on s6: [ 0.95   0.517  0.839]\n",
      "recall on px: [ 0.72   0.6    0.825]\n",
      "training set: s6\n",
      "recall on s2: [ 1.     0.727  0.824]\n",
      "recall on s6: [ 1.     0.889  0.714]\n",
      "recall on px: [ 0.68   0.543  0.725]\n",
      "training set: px\n",
      "recall on s2: [ 0.758  0.727  0.853]\n",
      "recall on s6: [ 0.525  0.621  0.806]\n",
      "recall on px: [ 0.833  0.571  1.   ]\n",
      "\n",
      "MLP\n",
      "training set: s2\n",
      "recall on s2: [ 0.9    0.444  1.   ]\n",
      "recall on s6: [ 0.925  0.32   0.829]\n",
      "recall on px: [ 0.72  0.76  0.84]\n",
      "training set: s6\n",
      "recall on s2: [ 1.     0.292  0.953]\n",
      "recall on s6: [ 1.   0.5  1. ]\n",
      "recall on px: [ 0.68  0.68  0.86]\n",
      "training set: px\n",
      "recall on s2: [ 0.818  0.458  0.953]\n",
      "recall on s6: [ 0.725  0.4    0.886]\n",
      "recall on px: [ 0.667  0.6    1.   ]\n",
      "\n",
      "Nearest Neighbors\n",
      "training set: s2\n",
      "recall on s2: [ 0.8    0.333  0.667]\n",
      "recall on s6: [ 0.7  0.5  0.7]\n",
      "recall on px: [ 0.72   0.611  0.718]\n",
      "training set: s6\n",
      "recall on s2: [ 0.939  0.515  0.706]\n",
      "recall on s6: [ 0.444  0.556  0.714]\n",
      "recall on px: [ 0.84   0.528  0.615]\n",
      "training set: px\n",
      "recall on s2: [ 0.697  0.636  0.706]\n",
      "recall on s6: [ 0.575  0.7    0.533]\n",
      "recall on px: [ 0.833  0.571  0.667]\n",
      "\n",
      "Random Forest\n",
      "training set: s2\n",
      "recall on s2: [ 1.   0.5  1. ]\n",
      "recall on s6: [ 0.95   0.633  0.767]\n",
      "recall on px: [ 0.72   0.667  0.872]\n",
      "training set: s6\n",
      "recall on s2: [ 1.     0.667  0.912]\n",
      "recall on s6: [ 1.     0.778  1.   ]\n",
      "recall on px: [ 0.68   0.611  0.821]\n",
      "training set: px\n",
      "recall on s2: [ 0.818  0.727  0.824]\n",
      "recall on s6: [ 0.725  0.567  0.8  ]\n",
      "recall on px: [ 0.667  0.857  1.   ]\n",
      "\n",
      "SVM\n",
      "training set: s2\n",
      "recall on s2: [ 0.8  0.2  1. ]\n",
      "recall on s6: [ 0.925  0.4    0.914]\n",
      "recall on px: [ 0.8    0.615  0.878]\n",
      "training set: s6\n",
      "recall on s2: [ 0.97   0.44   0.929]\n",
      "recall on s6: [ 0.778  0.375  1.   ]\n",
      "recall on px: [ 0.84   0.615  0.837]\n",
      "training set: px\n",
      "recall on s2: [ 0.909  0.24   0.929]\n",
      "recall on s6: [ 0.75   0.28   0.914]\n",
      "recall on px: [ 0.833  0.4    1.   ]\n",
      "\n",
      "\n",
      "#################################\n",
      "f1_score results:\n",
      "AdaBoost\n",
      "training set: s2\n",
      "f1_score on s2: [ 1.     0.5    0.429]\n",
      "f1_score on s6: [ 0.927  0.588  0.776]\n",
      "f1_score on px: [ 0.679  0.627  0.825]\n",
      "training set: s6\n",
      "f1_score on s2: [ 1.     0.762  0.789]\n",
      "f1_score on s6: [ 1.     0.842  0.769]\n",
      "f1_score on px: [ 0.607  0.551  0.773]\n",
      "training set: px\n",
      "f1_score on s2: [ 0.862  0.686  0.806]\n",
      "f1_score on s6: [ 0.689  0.5    0.746]\n",
      "f1_score on px: [ 0.909  0.667  0.889]\n",
      "\n",
      "MLP\n",
      "training set: s2\n",
      "f1_score on s2: [ 0.947  0.571  0.706]\n",
      "f1_score on s6: [ 0.925  0.381  0.744]\n",
      "f1_score on px: [ 0.8    0.667  0.857]\n",
      "training set: s6\n",
      "f1_score on s2: [ 1.     0.424  0.812]\n",
      "f1_score on s6: [ 1.     0.667  0.8  ]\n",
      "f1_score on px: [ 0.708  0.63   0.878]\n",
      "training set: px\n",
      "f1_score on s2: [ 0.9    0.512  0.845]\n",
      "f1_score on s6: [ 0.817  0.4    0.785]\n",
      "f1_score on px: [ 0.8    0.6    0.933]\n",
      "\n",
      "Nearest Neighbors\n",
      "training set: s2\n",
      "f1_score on s2: [ 0.889  0.421  0.308]\n",
      "f1_score on s6: [ 0.824  0.469  0.618]\n",
      "f1_score on px: [ 0.818  0.587  0.691]\n",
      "training set: s6\n",
      "f1_score on s2: [ 0.954  0.548  0.658]\n",
      "f1_score on s6: [ 0.615  0.476  0.625]\n",
      "f1_score on px: [ 0.84   0.521  0.623]\n",
      "training set: px\n",
      "f1_score on s2: [ 0.821  0.568  0.686]\n",
      "f1_score on s6: [ 0.73   0.512  0.582]\n",
      "f1_score on px: [ 0.909  0.5    0.696]\n",
      "\n",
      "Random Forest\n",
      "training set: s2\n",
      "f1_score on s2: [ 1.     0.667  0.5  ]\n",
      "f1_score on s6: [ 0.927  0.655  0.767]\n",
      "f1_score on px: [ 0.692  0.696  0.861]\n",
      "training set: s6\n",
      "f1_score on s2: [ 1.     0.759  0.816]\n",
      "f1_score on s6: [ 1.     0.875  0.875]\n",
      "f1_score on px: [ 0.63   0.638  0.831]\n",
      "training set: px\n",
      "f1_score on s2: [ 0.9    0.696  0.789]\n",
      "f1_score on s6: [ 0.841  0.531  0.716]\n",
      "f1_score on px: [ 0.8   0.8   0.96]\n",
      "\n",
      "SVM\n",
      "training set: s2\n",
      "f1_score on s2: [ 0.889  0.286  0.556]\n",
      "f1_score on s6: [ 0.937  0.488  0.8  ]\n",
      "f1_score on px: [ 0.851  0.615  0.851]\n",
      "training set: s6\n",
      "f1_score on s2: [ 0.985  0.55   0.821]\n",
      "f1_score on s6: [ 0.875  0.462  0.762]\n",
      "f1_score on px: [ 0.824  0.615  0.845]\n",
      "training set: px\n",
      "f1_score on s2: [ 0.952  0.324  0.78 ]\n",
      "f1_score on s6: [ 0.857  0.311  0.753]\n",
      "f1_score on px: [ 0.909  0.5    0.903]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_results(acc, 'accuracy')\n",
    "print_results(prec, 'precision')\n",
    "print_results(recl, 'recall')\n",
    "print_results(f1, 'f1_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def make_meshgrid(x, y, h=.02):\n",
    "    x_min, x_max = x.min() - 1, x.max() + 1\n",
    "    y_min, y_max = y.min() - 1, y.max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "\n",
    "def plot_contours(reg_name, xx, yy, **params):\n",
    "    Z = best_regressors_mae[reg_name].predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = to_label(Z, thresh_accuracy_mae[reg_name][0])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = plt.contourf(xx, yy, Z, **params)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "colors = ['red', 'green', 'blue']\n",
    "cmap = mpl.colors.ListedColormap(colors)\n",
    "rg = np.arange(0, 1.01, 0.01)\n",
    "x1, x2, lb = np.array(df_reg['BitRate']), np.array(df_reg['FreezeRatio']), np.array(df_reg['Quality'])\n",
    "xx1, xx2 = make_meshgrid(rg, rg)\n",
    "for reg, name in zip(list(best_regressors_mae.values()), list(best_regressors_mae.keys())):\n",
    "    plot_contours(name, xx1, xx2, cmap=cmap, alpha=0.8)\n",
    "    plt.scatter(x1, x2, c = lb, cmap=cmap, s=20, edgecolors='k')\n",
    "    plt.xlim(rg.min(), rg.max())\n",
    "    plt.ylim(rg.min(), rg.max())\n",
    "    plt.xlabel('Bit Rate')\n",
    "    plt.ylabel('Freeze Ratio')\n",
    "    plt.xticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.title(name)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
