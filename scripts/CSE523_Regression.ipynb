{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "from decimal import Decimal\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier as ovr\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, auc, precision_score, recall_score, f1_score \n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dr = '~/Projects/video-qoe-labeling/new-data/Skype/'\n",
    "dtype = {'BitRate': np.float64, 'FreezeRatio': np.float64, 'Freezes': np.int32, 'Freezelength': np.float64, 'Quality': np.float64}\n",
    "df_reg = pd.read_table(dr + 'all-data.txt', delim_whitespace=True, dtype = dtype)\n",
    "df_reg['BitRate'] /= 100  # transforming BitRate to percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get (X, y) and set fold\n",
    "features = ['BitRate', 'FreezeRatio', 'Freezes', 'Freezelength']\n",
    "X, y = np.array(df_reg[features]), np.array(df_reg['Quality'])\n",
    "mse = {}\n",
    "mae = {}\n",
    "fold = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regressors = {'Random Forest': RandomForestRegressor(random_state = 1), \n",
    "               'Nearest Neighbors': KNeighborsRegressor(),\n",
    "               'SVM': SVR(),\n",
    "               'MLP': MLPRegressor(random_state = 1, max_iter = 10000),\n",
    "               'AdaBoost': AdaBoostRegressor(random_state = 1)\n",
    "              }\n",
    "\n",
    "params = {'Random Forest': {'n_estimators': range(1, 21), 'criterion': ('mse', 'mae')},\n",
    "          'Nearest Neighbors': {'n_neighbors':range(1, 11)},\n",
    "          'SVM': {'kernel':('poly', 'rbf', 'sigmoid'), 'C':[0.1, 1, 10]},\n",
    "          'MLP': {'hidden_layer_sizes': [(10,), (20,), (40,), (80,), (10,10), (20, 20), (40, 40), (80, 80)], \n",
    "                  'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "                  'activation': ('logistic', 'tanh', 'relu'), \n",
    "                  'solver': ('lbfgs', 'sgd', 'adam')},\n",
    "          'AdaBoost': {'n_estimators': [10, 20, 40, 80], 'learning_rate': [0.01, 0.1, 1, 10]}\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# function for obtaining best estimator using grid search\n",
    "def grid_search_reg(estimator, params, scoring):\n",
    "    reg = GridSearchCV(estimator, params, scoring = scoring)\n",
    "    reg.fit(X, y)\n",
    "    return (reg.best_estimator_, reg.best_score_)\n",
    "\n",
    "# function for performing k-fold cross validation on the regressors\n",
    "def k_Fold_CV_reg(estimator, n):\n",
    "    mse = []\n",
    "    kf = KFold(n_splits = n)\n",
    "    for train, test in kf.split(X):\n",
    "        pred = estimator.fit(X[train], y[train]).predict(X[test])\n",
    "        mse.append(mean_squared_error(y[test], pred))\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best_regressors_mse = {}\n",
    "best_regressors_mae = {}\n",
    "for k in regressors:\n",
    "    best_regressors_mse[k], _ = grid_search_reg(regressors[k], params[k], 'neg_mean_squared_error')\n",
    "    best_regressors_mae[k], _ = grid_search_reg(regressors[k], params[k], 'neg_mean_absolute_error')\n",
    "    mse[k] = k_Fold_CV_reg(best_regressors_mse[k], fold)\n",
    "    mae[k] = k_Fold_CV_reg(best_regressors_mae[k], fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for k, v in mse.items():\n",
    "    print(k)\n",
    "    rmse = np.sqrt(v)\n",
    "    print(\"{}_fold RMSE: \".format(fold), np.around(rmse, decimals = 3))\n",
    "    print(\"Average RMSE: {0:0.3f}\".format(np.mean(rmse)))\n",
    "    print(\"#################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for k, v in mae.items():\n",
    "    print(k)\n",
    "    print(\"{}_fold MAE: \".format(fold), np.around(v, decimals = 3))\n",
    "    print(\"Average MAE: {0:0.3f}\".format(np.mean(v)))\n",
    "    print(\"#################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_regressors_mse = {'AdaBoost': AdaBoostRegressor(base_estimator=None, learning_rate=0.1, loss='linear',\n",
    "          n_estimators=10, random_state=1),\n",
    " 'MLP': MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "        hidden_layer_sizes=(10,), learning_rate='constant',\n",
    "        learning_rate_init=0.001, max_iter=10000, momentum=0.9,\n",
    "        nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
    "        solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
    "        warm_start=False),\n",
    " 'Nearest Neighbors': KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
    "           weights='uniform'),\n",
    " 'Random Forest': RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=None,\n",
    "            max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
    "            oob_score=False, random_state=1, verbose=0, warm_start=False),\n",
    " 'SVM': SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
    "   kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)}\n",
    "\n",
    "best_regressors_mae = {'AdaBoost': AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='linear',\n",
    "          n_estimators=10, random_state=1),\n",
    " 'MLP': MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "        hidden_layer_sizes=(10,), learning_rate='constant',\n",
    "        learning_rate_init=0.001, max_iter=10000, momentum=0.9,\n",
    "        nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
    "        solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
    "        warm_start=False),\n",
    " 'Nearest Neighbors': KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
    "           weights='uniform'),\n",
    " 'Random Forest': RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=None,\n",
    "            max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
    "            oob_score=False, random_state=1, verbose=0, warm_start=False),\n",
    " 'SVM': SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
    "   kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_splits = 20\n",
    "X_train, X_test, y_train, y_test = [], [], [], []\n",
    "for i in range(num_splits): \n",
    "    split = train_test_split(X, y, test_size = 0.25)\n",
    "    X_train.append(split[0])\n",
    "    X_test.append(split[1])\n",
    "    y_train.append(split[2])\n",
    "    y_test.append(split[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mserr = {}\n",
    "for k, v in best_regressors_mse.items():\n",
    "    pred = v.fit(X_train, y_train).predict(X_test)\n",
    "    mserr[k] = mean_squared_error(y_test, pred)\n",
    "\n",
    "maerr = {}\n",
    "for k, v in best_regressors_mae.items():\n",
    "    pred = v.fit(X_train, y_train).predict(X_test)\n",
    "    maerr[k] = mean_absolute_error(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for k, v in mserr.items():\n",
    "    print(k)\n",
    "    print(\"MSE: \", np.around(v, decimals = 3))\n",
    "    print(\"#################################\")\n",
    "    \n",
    "for k, v in maerr.items():\n",
    "    print(k)\n",
    "    print(\"MAE: \", np.around(v, decimals = 3))\n",
    "    print(\"#################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_label(score, thresh):\n",
    "    label = []\n",
    "    for s in np.nditer(score):\n",
    "        if s < thresh[0]:\n",
    "            label.append(0)\n",
    "        elif s < thresh[1]:\n",
    "            label.append(1)\n",
    "        else:\n",
    "            label.append(2)\n",
    "    return np.array(label, dtype = int) \n",
    "\n",
    "def optimize_thresh(regressor, X_train, y_train, X_test, y_test, t1_range, top_num):\n",
    "    i = 0\n",
    "    thresh_accuracy = []\n",
    "    model = regressor.fit(X_train, y_train)\n",
    "    pred = model.predict(X_train) \n",
    "    # find optimal thresholds from training set\n",
    "    for t1 in t1_range:\n",
    "        for t2 in np.arange(t1+1, 4.01, 0.05):\n",
    "            y_label_true = to_label(y_train, (t1, t2))\n",
    "            y_label_pred = to_label(pred, (t1, t2))\n",
    "            thresh_accuracy.append(((t1, t2), accuracy_score(y_label_true, y_label_pred)))\n",
    "    thresh_accuracy.sort(key = lambda x:x[1], reverse = True)\n",
    "    # determine average thresholds\n",
    "    thresh = [x[0] for x in thresh_accuracy[:top_num]]\n",
    "    avg_thresh = np.average(thresh, axis = 0) \n",
    "    # find accuracy on test set\n",
    "    pred = model.predict(X_test)\n",
    "    y_label_true = to_label(y_test, avg_thresh)\n",
    "    y_label_pred = to_label(pred, avg_thresh)   \n",
    "    return avg_thresh, accuracy_score(y_label_true, y_label_pred),precision_score(y_label_true, y_label_pred, average = None),recall_score(y_label_true, y_label_pred, average = None), f1_score(y_label_true, y_label_pred, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "t1_range = np.arange(2, 3.01, 0.05)\n",
    "thresh_scores_mse = {}\n",
    "\n",
    "for k, reg in best_regressors_mse.items():\n",
    "    thresh_scores_mse[k] = [optimize_thresh(reg, X_train[i], y_train[i], X_test[i], y_test[i], t1_range, 1) for i in range(num_splits)]\n",
    "\n",
    "thresh_scores_mae = {}\n",
    "for k, reg in best_regressors_mae.items():\n",
    "    thresh_scores_mae[k] = [optimize_thresh(reg, X_train[i], y_train[i], X_test[i], y_test[i], t1_range, 1) for i in range(num_splits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regressors with minimized mean squared error\n",
      "AdaBoost\n",
      "Optimal thresholds: [[ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.05  3.85]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]]\n",
      "Accuracy: [ 0.893  0.867  0.867  0.853  0.827  0.92   0.893  0.813  0.827  0.893\n",
      "  0.853  0.8    0.827  0.92   0.853  0.893  0.84   0.827  0.853  0.84 ]\n",
      "Precision: [[ 1.     0.     0.857]\n",
      " [ 0.917  0.     0.86 ]\n",
      " [ 1.     0.     0.811]\n",
      " [ 0.846  0.     0.894]\n",
      " [ 0.923  0.     0.776]\n",
      " [ 1.     0.     0.944]\n",
      " [ 0.964  0.     0.851]\n",
      " [ 0.913  0.731  0.808]\n",
      " [ 1.     0.     0.75 ]\n",
      " [ 1.     0.5    0.86 ]\n",
      " [ 1.     0.     0.815]\n",
      " [ 0.92   0.     0.755]\n",
      " [ 0.96   0.     0.776]\n",
      " [ 0.964  0.     0.913]\n",
      " [ 0.9    1.     0.833]\n",
      " [ 0.962  0.     0.857]\n",
      " [ 0.962  0.     0.826]\n",
      " [ 0.875  0.     0.804]\n",
      " [ 0.931  0.     0.804]\n",
      " [ 0.909  0.     0.86 ]]\n",
      "Recall: [[ 0.926  0.     1.   ]\n",
      " [ 1.     0.     0.977]\n",
      " [ 0.917  0.     1.   ]\n",
      " [ 0.957  0.     0.933]\n",
      " [ 0.96   0.     1.   ]\n",
      " [ 0.947  0.     0.962]\n",
      " [ 1.     0.     1.   ]\n",
      " [ 0.955  0.76   0.75 ]\n",
      " [ 0.793  0.     1.   ]\n",
      " [ 0.958  0.143  0.977]\n",
      " [ 0.909  0.     0.978]\n",
      " [ 0.92   0.     0.974]\n",
      " [ 0.923  0.     0.974]\n",
      " [ 1.     0.     0.977]\n",
      " [ 0.9    0.111  0.978]\n",
      " [ 1.     0.     1.   ]\n",
      " [ 0.926  0.     0.927]\n",
      " [ 1.     0.     1.   ]\n",
      " [ 0.964  0.     0.949]\n",
      " [ 0.909  0.     0.956]]\n",
      "F1: [[ 0.962  0.     0.923]\n",
      " [ 0.957  0.     0.915]\n",
      " [ 0.957  0.     0.896]\n",
      " [ 0.898  0.     0.913]\n",
      " [ 0.941  0.     0.874]\n",
      " [ 0.973  0.     0.953]\n",
      " [ 0.982  0.     0.92 ]\n",
      " [ 0.933  0.745  0.778]\n",
      " [ 0.885  0.     0.857]\n",
      " [ 0.979  0.222  0.915]\n",
      " [ 0.952  0.     0.889]\n",
      " [ 0.92   0.     0.851]\n",
      " [ 0.941  0.     0.864]\n",
      " [ 0.982  0.     0.944]\n",
      " [ 0.9    0.2    0.9  ]\n",
      " [ 0.98   0.     0.923]\n",
      " [ 0.943  0.     0.874]\n",
      " [ 0.933  0.     0.891]\n",
      " [ 0.947  0.     0.871]\n",
      " [ 0.909  0.     0.905]]\n",
      "#################################\n",
      "MLP\n",
      "Optimal thresholds: [[ 2.15  3.75]\n",
      " [ 2.2   4.  ]\n",
      " [ 2.4   3.45]\n",
      " [ 2.35  3.8 ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.2   3.5 ]\n",
      " [ 2.25  3.5 ]\n",
      " [ 2.3   4.  ]\n",
      " [ 2.25  3.8 ]\n",
      " [ 2.3   3.55]\n",
      " [ 2.35  3.45]\n",
      " [ 2.35  3.4 ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.2   3.75]\n",
      " [ 2.4   3.55]\n",
      " [ 2.3   3.45]\n",
      " [ 2.    3.  ]\n",
      " [ 2.35  3.5 ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]]\n",
      "Accuracy: [ 0.8    0.773  0.813  0.813  0.84   0.867  0.84   0.773  0.8    0.773\n",
      "  0.76   0.773  0.8    0.787  0.827  0.773  0.84   0.76   0.813  0.773]\n",
      "Precision: [[ 1.     0.741  0.667]\n",
      " [ 0.952  0.667  0.778]\n",
      " [ 1.     0.706  0.763]\n",
      " [ 0.885  0.722  0.806]\n",
      " [ 0.957  0.6    0.809]\n",
      " [ 1.     0.923  0.791]\n",
      " [ 0.963  0.8    0.758]\n",
      " [ 0.87   0.636  0.895]\n",
      " [ 0.96   0.68   0.76 ]\n",
      " [ 1.     0.714  0.658]\n",
      " [ 1.     0.769  0.651]\n",
      " [ 0.923  0.786  0.657]\n",
      " [ 0.958  0.143  0.818]\n",
      " [ 0.929  0.571  0.808]\n",
      " [ 0.944  0.75   0.811]\n",
      " [ 0.926  0.714  0.676]\n",
      " [ 1.     0.     0.822]\n",
      " [ 0.909  0.833  0.659]\n",
      " [ 1.     0.273  0.854]\n",
      " [ 0.85   0.125  0.851]]\n",
      "Recall: [[ 0.889  0.714  0.8  ]\n",
      " [ 0.909  0.828  0.583]\n",
      " [ 0.833  0.6    0.935]\n",
      " [ 1.     0.591  0.833]\n",
      " [ 0.88   0.25   1.   ]\n",
      " [ 1.     0.571  0.971]\n",
      " [ 0.963  0.571  0.926]\n",
      " [ 0.909  0.808  0.63 ]\n",
      " [ 0.828  0.739  0.826]\n",
      " [ 0.958  0.435  0.893]\n",
      " [ 0.864  0.435  0.933]\n",
      " [ 0.96   0.44   0.92 ]\n",
      " [ 0.885  0.1    0.923]\n",
      " [ 0.963  0.632  0.724]\n",
      " [ 0.85   0.652  0.938]\n",
      " [ 1.     0.435  0.852]\n",
      " [ 0.963  0.     0.902]\n",
      " [ 0.952  0.385  0.964]\n",
      " [ 0.821  0.375  0.897]\n",
      " [ 0.773  0.125  0.889]]\n",
      "F1: [[ 0.941  0.727  0.727]\n",
      " [ 0.93   0.738  0.667]\n",
      " [ 0.909  0.649  0.841]\n",
      " [ 0.939  0.65   0.82 ]\n",
      " [ 0.917  0.353  0.894]\n",
      " [ 1.     0.706  0.872]\n",
      " [ 0.963  0.667  0.833]\n",
      " [ 0.889  0.712  0.739]\n",
      " [ 0.889  0.708  0.792]\n",
      " [ 0.979  0.541  0.758]\n",
      " [ 0.927  0.556  0.767]\n",
      " [ 0.941  0.564  0.767]\n",
      " [ 0.92   0.118  0.867]\n",
      " [ 0.945  0.6    0.764]\n",
      " [ 0.895  0.698  0.87 ]\n",
      " [ 0.962  0.541  0.754]\n",
      " [ 0.981  0.     0.86 ]\n",
      " [ 0.93   0.526  0.783]\n",
      " [ 0.902  0.316  0.875]\n",
      " [ 0.81   0.125  0.87 ]]\n",
      "#################################\n",
      "Nearest Neighbors\n",
      "Optimal thresholds: [[ 2.    3.  ]\n",
      " [ 2.6   4.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.6   3.9 ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.65  4.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.5   3.55]\n",
      " [ 2.2   3.35]\n",
      " [ 2.05  3.05]\n",
      " [ 2.    3.  ]\n",
      " [ 2.4   3.8 ]\n",
      " [ 2.6   4.  ]\n",
      " [ 2.15  4.  ]\n",
      " [ 2.5   3.5 ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.6   3.9 ]\n",
      " [ 2.25  3.9 ]]\n",
      "Accuracy: [ 0.8    0.747  0.84   0.853  0.8    0.84   0.867  0.693  0.813  0.733\n",
      "  0.733  0.76   0.787  0.773  0.76   0.693  0.733  0.773  0.72   0.653]\n",
      "Precision: [[ 1.     0.125  0.833]\n",
      " [ 0.909  0.679  0.68 ]\n",
      " [ 1.     0.     0.824]\n",
      " [ 0.95   0.2    0.88 ]\n",
      " [ 1.     0.444  0.783]\n",
      " [ 0.95   0.81   0.794]\n",
      " [ 0.962  0.333  0.848]\n",
      " [ 0.9    0.553  0.765]\n",
      " [ 1.     0.167  0.809]\n",
      " [ 0.952  0.611  0.667]\n",
      " [ 1.     0.5    0.674]\n",
      " [ 0.92   0.25   0.762]\n",
      " [ 0.955  0.125  0.822]\n",
      " [ 0.958  0.545  0.793]\n",
      " [ 0.947  0.677  0.72 ]\n",
      " [ 0.952  0.579  0.625]\n",
      " [ 0.958  0.636  0.625]\n",
      " [ 0.944  0.167  0.784]\n",
      " [ 0.96   0.577  0.625]\n",
      " [ 0.944  0.562  0.56 ]]\n",
      "Recall: [[ 0.704  0.167  0.952]\n",
      " [ 0.909  0.655  0.708]\n",
      " [ 0.875  0.     0.977]\n",
      " [ 0.826  0.143  0.978]\n",
      " [ 0.8    0.333  0.947]\n",
      " [ 1.     0.68   0.871]\n",
      " [ 0.926  0.125  0.975]\n",
      " [ 0.818  0.808  0.481]\n",
      " [ 0.759  0.143  0.974]\n",
      " [ 0.833  0.478  0.857]\n",
      " [ 0.864  0.263  0.912]\n",
      " [ 0.92   0.154  0.865]\n",
      " [ 0.808  0.1    0.949]\n",
      " [ 0.852  0.632  0.793]\n",
      " [ 0.9    0.724  0.692]\n",
      " [ 0.8    0.759  0.476]\n",
      " [ 0.852  0.318  0.962]\n",
      " [ 0.81   0.077  0.976]\n",
      " [ 0.857  0.625  0.652]\n",
      " [ 0.773  0.6    0.609]]\n",
      "F1: [[ 0.826  0.143  0.889]\n",
      " [ 0.909  0.667  0.694]\n",
      " [ 0.933  0.     0.894]\n",
      " [ 0.884  0.167  0.926]\n",
      " [ 0.889  0.381  0.857]\n",
      " [ 0.974  0.739  0.831]\n",
      " [ 0.943  0.182  0.907]\n",
      " [ 0.857  0.656  0.591]\n",
      " [ 0.863  0.154  0.884]\n",
      " [ 0.889  0.537  0.75 ]\n",
      " [ 0.927  0.345  0.775]\n",
      " [ 0.92   0.19   0.81 ]\n",
      " [ 0.875  0.111  0.881]\n",
      " [ 0.902  0.585  0.793]\n",
      " [ 0.923  0.7    0.706]\n",
      " [ 0.87   0.657  0.541]\n",
      " [ 0.902  0.424  0.758]\n",
      " [ 0.872  0.105  0.87 ]\n",
      " [ 0.906  0.6    0.638]\n",
      " [ 0.85   0.581  0.583]]\n",
      "#################################\n",
      "Random Forest\n",
      "Optimal thresholds: [[ 2.45  3.85]\n",
      " [ 2.3   3.8 ]\n",
      " [ 2.1   4.  ]\n",
      " [ 2.25  3.8 ]\n",
      " [ 2.1   4.  ]\n",
      " [ 2.05  4.  ]\n",
      " [ 2.2   4.  ]\n",
      " [ 2.3   3.95]\n",
      " [ 2.15  4.  ]\n",
      " [ 2.3   3.8 ]\n",
      " [ 2.    3.75]\n",
      " [ 2.15  3.4 ]\n",
      " [ 2.05  4.  ]\n",
      " [ 2.5   3.75]\n",
      " [ 2.    3.95]\n",
      " [ 2.35  3.5 ]\n",
      " [ 2.1   3.8 ]\n",
      " [ 2.1   3.85]\n",
      " [ 2.1   4.  ]\n",
      " [ 2.25  3.85]]\n",
      "Accuracy: [ 0.867  0.84   0.84   0.8    0.853  0.867  0.907  0.84   0.867  0.813\n",
      "  0.84   0.84   0.853  0.813  0.88   0.787  0.907  0.84   0.827  0.813]\n",
      "Precision: [[ 0.963  0.828  0.789]\n",
      " [ 0.917  0.774  0.85 ]\n",
      " [ 1.     0.767  0.792]\n",
      " [ 0.88   0.684  0.806]\n",
      " [ 0.923  0.839  0.778]\n",
      " [ 1.     0.759  0.893]\n",
      " [ 0.963  0.88   0.87 ]\n",
      " [ 0.913  0.719  0.95 ]\n",
      " [ 1.     0.742  0.9  ]\n",
      " [ 1.     0.783  0.7  ]\n",
      " [ 1.     0.8    0.774]\n",
      " [ 0.96   0.842  0.742]\n",
      " [ 0.96   0.767  0.85 ]\n",
      " [ 0.963  0.6    0.87 ]\n",
      " [ 0.947  0.833  0.885]\n",
      " [ 0.926  0.7    0.714]\n",
      " [ 1.     0.913  0.821]\n",
      " [ 0.947  0.767  0.846]\n",
      " [ 0.963  0.71   0.824]\n",
      " [ 0.95   0.75   0.783]]\n",
      "Recall: [[ 0.963  0.857  0.75 ]\n",
      " [ 1.     0.828  0.708]\n",
      " [ 0.875  0.852  0.792]\n",
      " [ 0.957  0.591  0.833]\n",
      " [ 0.96   0.839  0.737]\n",
      " [ 0.947  0.88   0.806]\n",
      " [ 0.963  0.846  0.909]\n",
      " [ 0.955  0.885  0.704]\n",
      " [ 0.828  0.958  0.818]\n",
      " [ 0.917  0.692  0.84 ]\n",
      " [ 0.864  0.769  0.889]\n",
      " [ 0.96   0.64   0.92 ]\n",
      " [ 0.923  0.885  0.739]\n",
      " [ 0.963  0.789  0.69 ]\n",
      " [ 0.9    0.893  0.852]\n",
      " [ 1.     0.583  0.769]\n",
      " [ 0.889  0.84   1.   ]\n",
      " [ 0.857  0.821  0.846]\n",
      " [ 0.929  0.88   0.636]\n",
      " [ 0.864  0.8    0.783]]\n",
      "F1: [[ 0.963  0.842  0.769]\n",
      " [ 0.957  0.8    0.773]\n",
      " [ 0.933  0.807  0.792]\n",
      " [ 0.917  0.634  0.82 ]\n",
      " [ 0.941  0.839  0.757]\n",
      " [ 0.973  0.815  0.847]\n",
      " [ 0.963  0.863  0.889]\n",
      " [ 0.933  0.793  0.809]\n",
      " [ 0.906  0.836  0.857]\n",
      " [ 0.957  0.735  0.764]\n",
      " [ 0.927  0.784  0.828]\n",
      " [ 0.96   0.727  0.821]\n",
      " [ 0.941  0.821  0.791]\n",
      " [ 0.963  0.682  0.769]\n",
      " [ 0.923  0.862  0.868]\n",
      " [ 0.962  0.636  0.741]\n",
      " [ 0.941  0.875  0.902]\n",
      " [ 0.9    0.793  0.846]\n",
      " [ 0.945  0.786  0.718]\n",
      " [ 0.905  0.774  0.783]]\n",
      "#################################\n",
      "SVM\n",
      "Optimal thresholds: [[ 2.5   3.85]\n",
      " [ 2.5   4.  ]\n",
      " [ 2.05  3.05]\n",
      " [ 2.4   3.95]\n",
      " [ 2.    3.  ]\n",
      " [ 2.3   3.85]\n",
      " [ 2.35  3.95]\n",
      " [ 2.3   3.85]\n",
      " [ 2.    3.  ]\n",
      " [ 2.25  3.9 ]\n",
      " [ 2.35  4.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.25  3.95]\n",
      " [ 2.25  3.85]\n",
      " [ 2.05  3.05]\n",
      " [ 2.55  3.8 ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.4   3.5 ]\n",
      " [ 2.    3.  ]]\n",
      "Accuracy: [ 0.8    0.8    0.787  0.893  0.84   0.84   0.88   0.84   0.8    0.813\n",
      "  0.853  0.787  0.773  0.787  0.827  0.773  0.827  0.813  0.813  0.773]\n",
      "Precision: [[ 0.964  0.842  0.607]\n",
      " [ 0.88   0.792  0.731]\n",
      " [ 1.     0.2    0.755]\n",
      " [ 0.92   0.792  0.962]\n",
      " [ 0.957  0.556  0.837]\n",
      " [ 1.     0.842  0.757]\n",
      " [ 0.963  0.808  0.864]\n",
      " [ 0.952  0.769  0.821]\n",
      " [ 1.     0.182  0.86 ]\n",
      " [ 0.957  0.75   0.75 ]\n",
      " [ 1.     0.815  0.786]\n",
      " [ 0.96   0.25   0.786]\n",
      " [ 0.957  0.645  0.762]\n",
      " [ 0.963  0.56   0.826]\n",
      " [ 0.947  0.286  0.857]\n",
      " [ 0.833  0.739  0.727]\n",
      " [ 1.     0.143  0.844]\n",
      " [ 0.95   0.429  0.812]\n",
      " [ 1.     0.75   0.706]\n",
      " [ 0.944  0.091  0.87 ]]\n",
      "Recall: [[ 1.     0.571  0.85 ]\n",
      " [ 1.     0.655  0.792]\n",
      " [ 0.875  0.083  0.949]\n",
      " [ 1.     0.864  0.833]\n",
      " [ 0.88   0.417  0.947]\n",
      " [ 1.     0.64   0.903]\n",
      " [ 0.963  0.84   0.826]\n",
      " [ 0.909  0.8    0.821]\n",
      " [ 0.724  0.286  0.949]\n",
      " [ 0.917  0.692  0.84 ]\n",
      " [ 0.909  0.815  0.846]\n",
      " [ 0.96   0.167  0.868]\n",
      " [ 0.846  0.769  0.696]\n",
      " [ 0.963  0.737  0.655]\n",
      " [ 0.9    0.2    0.933]\n",
      " [ 1.     0.63   0.696]\n",
      " [ 0.852  0.143  0.927]\n",
      " [ 0.905  0.231  0.951]\n",
      " [ 0.893  0.571  0.923]\n",
      " [ 0.773  0.125  0.889]]\n",
      "F1: [[ 0.982  0.681  0.708]\n",
      " [ 0.936  0.717  0.76 ]\n",
      " [ 0.933  0.118  0.841]\n",
      " [ 0.958  0.826  0.893]\n",
      " [ 0.917  0.476  0.889]\n",
      " [ 1.     0.727  0.824]\n",
      " [ 0.963  0.824  0.844]\n",
      " [ 0.93   0.784  0.821]\n",
      " [ 0.84   0.222  0.902]\n",
      " [ 0.936  0.72   0.792]\n",
      " [ 0.952  0.815  0.815]\n",
      " [ 0.96   0.2    0.825]\n",
      " [ 0.898  0.702  0.727]\n",
      " [ 0.963  0.636  0.731]\n",
      " [ 0.923  0.235  0.894]\n",
      " [ 0.909  0.68   0.711]\n",
      " [ 0.92   0.143  0.884]\n",
      " [ 0.927  0.3    0.876]\n",
      " [ 0.943  0.649  0.8  ]\n",
      " [ 0.85   0.105  0.879]]\n",
      "#################################\n",
      "\n",
      "regressors with minimized mean absolute error\n",
      "AdaBoost\n",
      "Optimal thresholds: [[ 2.5   3.75]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.15  3.75]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    4.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.15  3.9 ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]]\n",
      "Accuracy: [ 0.853  0.867  0.867  0.787  0.84   0.92   0.893  0.893  0.813  0.853\n",
      "  0.88   0.813  0.813  0.773  0.853  0.893  0.84   0.827  0.853  0.787]\n",
      "Precision: [[ 0.962  0.781  0.824]\n",
      " [ 0.917  0.     0.86 ]\n",
      " [ 1.     0.     0.811]\n",
      " [ 0.815  0.636  0.885]\n",
      " [ 0.923  1.     0.792]\n",
      " [ 1.     0.     0.944]\n",
      " [ 0.964  0.     0.851]\n",
      " [ 0.913  0.     0.902]\n",
      " [ 1.     0.     0.745]\n",
      " [ 0.955  0.     0.811]\n",
      " [ 1.     0.812  0.875]\n",
      " [ 0.96   0.     0.755]\n",
      " [ 0.957  0.     0.78 ]\n",
      " [ 0.926  0.536  0.9  ]\n",
      " [ 0.95   0.333  0.846]\n",
      " [ 0.926  0.     0.875]\n",
      " [ 0.96   0.     0.83 ]\n",
      " [ 0.875  0.     0.804]\n",
      " [ 0.931  0.     0.804]\n",
      " [ 0.85   0.     0.808]]\n",
      "Recall: [[ 0.926  0.893  0.7  ]\n",
      " [ 1.     0.     0.977]\n",
      " [ 0.917  0.     1.   ]\n",
      " [ 0.957  0.636  0.767]\n",
      " [ 0.96   0.083  1.   ]\n",
      " [ 0.947  0.     0.962]\n",
      " [ 1.     0.     1.   ]\n",
      " [ 0.955  0.     0.979]\n",
      " [ 0.793  0.     0.974]\n",
      " [ 0.875  0.     0.977]\n",
      " [ 0.864  0.963  0.808]\n",
      " [ 0.96   0.     0.974]\n",
      " [ 0.846  0.     1.   ]\n",
      " [ 0.926  0.789  0.621]\n",
      " [ 0.95   0.111  0.957]\n",
      " [ 1.     0.     1.   ]\n",
      " [ 0.889  0.     0.951]\n",
      " [ 1.     0.     1.   ]\n",
      " [ 0.964  0.     0.949]\n",
      " [ 0.773  0.     0.933]]\n",
      "F1: [[ 0.943  0.833  0.757]\n",
      " [ 0.957  0.     0.915]\n",
      " [ 0.957  0.     0.896]\n",
      " [ 0.88   0.636  0.821]\n",
      " [ 0.941  0.154  0.884]\n",
      " [ 0.973  0.     0.953]\n",
      " [ 0.982  0.     0.92 ]\n",
      " [ 0.933  0.     0.939]\n",
      " [ 0.885  0.     0.844]\n",
      " [ 0.913  0.     0.887]\n",
      " [ 0.927  0.881  0.84 ]\n",
      " [ 0.96   0.     0.851]\n",
      " [ 0.898  0.     0.876]\n",
      " [ 0.926  0.638  0.735]\n",
      " [ 0.95   0.167  0.898]\n",
      " [ 0.962  0.     0.933]\n",
      " [ 0.923  0.     0.886]\n",
      " [ 0.933  0.     0.891]\n",
      " [ 0.947  0.     0.871]\n",
      " [ 0.81   0.     0.866]]\n",
      "#################################\n",
      "MLP\n",
      "Optimal thresholds: [[ 2.15  3.75]\n",
      " [ 2.2   4.  ]\n",
      " [ 2.4   3.45]\n",
      " [ 2.35  3.8 ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.2   3.5 ]\n",
      " [ 2.25  3.5 ]\n",
      " [ 2.3   4.  ]\n",
      " [ 2.25  3.8 ]\n",
      " [ 2.3   3.55]\n",
      " [ 2.35  3.45]\n",
      " [ 2.35  3.4 ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.2   3.75]\n",
      " [ 2.4   3.55]\n",
      " [ 2.3   3.45]\n",
      " [ 2.    3.  ]\n",
      " [ 2.35  3.5 ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]]\n",
      "Accuracy: [ 0.8    0.773  0.813  0.813  0.84   0.867  0.84   0.773  0.8    0.773\n",
      "  0.76   0.773  0.8    0.787  0.827  0.773  0.84   0.76   0.813  0.773]\n",
      "Precision: [[ 1.     0.741  0.667]\n",
      " [ 0.952  0.667  0.778]\n",
      " [ 1.     0.706  0.763]\n",
      " [ 0.885  0.722  0.806]\n",
      " [ 0.957  0.6    0.809]\n",
      " [ 1.     0.923  0.791]\n",
      " [ 0.963  0.8    0.758]\n",
      " [ 0.87   0.636  0.895]\n",
      " [ 0.96   0.68   0.76 ]\n",
      " [ 1.     0.714  0.658]\n",
      " [ 1.     0.769  0.651]\n",
      " [ 0.923  0.786  0.657]\n",
      " [ 0.958  0.143  0.818]\n",
      " [ 0.929  0.571  0.808]\n",
      " [ 0.944  0.75   0.811]\n",
      " [ 0.926  0.714  0.676]\n",
      " [ 1.     0.     0.822]\n",
      " [ 0.909  0.833  0.659]\n",
      " [ 1.     0.273  0.854]\n",
      " [ 0.85   0.125  0.851]]\n",
      "Recall: [[ 0.889  0.714  0.8  ]\n",
      " [ 0.909  0.828  0.583]\n",
      " [ 0.833  0.6    0.935]\n",
      " [ 1.     0.591  0.833]\n",
      " [ 0.88   0.25   1.   ]\n",
      " [ 1.     0.571  0.971]\n",
      " [ 0.963  0.571  0.926]\n",
      " [ 0.909  0.808  0.63 ]\n",
      " [ 0.828  0.739  0.826]\n",
      " [ 0.958  0.435  0.893]\n",
      " [ 0.864  0.435  0.933]\n",
      " [ 0.96   0.44   0.92 ]\n",
      " [ 0.885  0.1    0.923]\n",
      " [ 0.963  0.632  0.724]\n",
      " [ 0.85   0.652  0.938]\n",
      " [ 1.     0.435  0.852]\n",
      " [ 0.963  0.     0.902]\n",
      " [ 0.952  0.385  0.964]\n",
      " [ 0.821  0.375  0.897]\n",
      " [ 0.773  0.125  0.889]]\n",
      "F1: [[ 0.941  0.727  0.727]\n",
      " [ 0.93   0.738  0.667]\n",
      " [ 0.909  0.649  0.841]\n",
      " [ 0.939  0.65   0.82 ]\n",
      " [ 0.917  0.353  0.894]\n",
      " [ 1.     0.706  0.872]\n",
      " [ 0.963  0.667  0.833]\n",
      " [ 0.889  0.712  0.739]\n",
      " [ 0.889  0.708  0.792]\n",
      " [ 0.979  0.541  0.758]\n",
      " [ 0.927  0.556  0.767]\n",
      " [ 0.941  0.564  0.767]\n",
      " [ 0.92   0.118  0.867]\n",
      " [ 0.945  0.6    0.764]\n",
      " [ 0.895  0.698  0.87 ]\n",
      " [ 0.962  0.541  0.754]\n",
      " [ 0.981  0.     0.86 ]\n",
      " [ 0.93   0.526  0.783]\n",
      " [ 0.902  0.316  0.875]\n",
      " [ 0.81   0.125  0.87 ]]\n",
      "#################################\n",
      "Nearest Neighbors\n",
      "Optimal thresholds: [[ 2.    3.  ]\n",
      " [ 2.6   4.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.6   3.9 ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.65  4.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.5   3.55]\n",
      " [ 2.2   3.35]\n",
      " [ 2.05  3.05]\n",
      " [ 2.    3.  ]\n",
      " [ 2.4   3.8 ]\n",
      " [ 2.6   4.  ]\n",
      " [ 2.15  4.  ]\n",
      " [ 2.5   3.5 ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.6   3.9 ]\n",
      " [ 2.25  3.9 ]]\n",
      "Accuracy: [ 0.8    0.747  0.84   0.853  0.8    0.84   0.867  0.693  0.813  0.733\n",
      "  0.733  0.76   0.787  0.773  0.76   0.693  0.733  0.773  0.72   0.653]\n",
      "Precision: [[ 1.     0.125  0.833]\n",
      " [ 0.909  0.679  0.68 ]\n",
      " [ 1.     0.     0.824]\n",
      " [ 0.95   0.2    0.88 ]\n",
      " [ 1.     0.444  0.783]\n",
      " [ 0.95   0.81   0.794]\n",
      " [ 0.962  0.333  0.848]\n",
      " [ 0.9    0.553  0.765]\n",
      " [ 1.     0.167  0.809]\n",
      " [ 0.952  0.611  0.667]\n",
      " [ 1.     0.5    0.674]\n",
      " [ 0.92   0.25   0.762]\n",
      " [ 0.955  0.125  0.822]\n",
      " [ 0.958  0.545  0.793]\n",
      " [ 0.947  0.677  0.72 ]\n",
      " [ 0.952  0.579  0.625]\n",
      " [ 0.958  0.636  0.625]\n",
      " [ 0.944  0.167  0.784]\n",
      " [ 0.96   0.577  0.625]\n",
      " [ 0.944  0.562  0.56 ]]\n",
      "Recall: [[ 0.704  0.167  0.952]\n",
      " [ 0.909  0.655  0.708]\n",
      " [ 0.875  0.     0.977]\n",
      " [ 0.826  0.143  0.978]\n",
      " [ 0.8    0.333  0.947]\n",
      " [ 1.     0.68   0.871]\n",
      " [ 0.926  0.125  0.975]\n",
      " [ 0.818  0.808  0.481]\n",
      " [ 0.759  0.143  0.974]\n",
      " [ 0.833  0.478  0.857]\n",
      " [ 0.864  0.263  0.912]\n",
      " [ 0.92   0.154  0.865]\n",
      " [ 0.808  0.1    0.949]\n",
      " [ 0.852  0.632  0.793]\n",
      " [ 0.9    0.724  0.692]\n",
      " [ 0.8    0.759  0.476]\n",
      " [ 0.852  0.318  0.962]\n",
      " [ 0.81   0.077  0.976]\n",
      " [ 0.857  0.625  0.652]\n",
      " [ 0.773  0.6    0.609]]\n",
      "F1: [[ 0.826  0.143  0.889]\n",
      " [ 0.909  0.667  0.694]\n",
      " [ 0.933  0.     0.894]\n",
      " [ 0.884  0.167  0.926]\n",
      " [ 0.889  0.381  0.857]\n",
      " [ 0.974  0.739  0.831]\n",
      " [ 0.943  0.182  0.907]\n",
      " [ 0.857  0.656  0.591]\n",
      " [ 0.863  0.154  0.884]\n",
      " [ 0.889  0.537  0.75 ]\n",
      " [ 0.927  0.345  0.775]\n",
      " [ 0.92   0.19   0.81 ]\n",
      " [ 0.875  0.111  0.881]\n",
      " [ 0.902  0.585  0.793]\n",
      " [ 0.923  0.7    0.706]\n",
      " [ 0.87   0.657  0.541]\n",
      " [ 0.902  0.424  0.758]\n",
      " [ 0.872  0.105  0.87 ]\n",
      " [ 0.906  0.6    0.638]\n",
      " [ 0.85   0.581  0.583]]\n",
      "#################################\n",
      "Random Forest\n",
      "Optimal thresholds: [[ 2.45  3.85]\n",
      " [ 2.3   3.8 ]\n",
      " [ 2.1   4.  ]\n",
      " [ 2.25  3.8 ]\n",
      " [ 2.1   4.  ]\n",
      " [ 2.05  4.  ]\n",
      " [ 2.2   4.  ]\n",
      " [ 2.3   3.95]\n",
      " [ 2.15  4.  ]\n",
      " [ 2.3   3.8 ]\n",
      " [ 2.    3.75]\n",
      " [ 2.15  3.4 ]\n",
      " [ 2.05  4.  ]\n",
      " [ 2.5   3.75]\n",
      " [ 2.    3.95]\n",
      " [ 2.35  3.5 ]\n",
      " [ 2.1   3.8 ]\n",
      " [ 2.1   3.85]\n",
      " [ 2.1   4.  ]\n",
      " [ 2.25  3.85]]\n",
      "Accuracy: [ 0.867  0.84   0.84   0.8    0.853  0.867  0.907  0.84   0.867  0.813\n",
      "  0.84   0.84   0.853  0.813  0.88   0.787  0.907  0.84   0.827  0.813]\n",
      "Precision: [[ 0.963  0.828  0.789]\n",
      " [ 0.917  0.774  0.85 ]\n",
      " [ 1.     0.767  0.792]\n",
      " [ 0.88   0.684  0.806]\n",
      " [ 0.923  0.839  0.778]\n",
      " [ 1.     0.759  0.893]\n",
      " [ 0.963  0.88   0.87 ]\n",
      " [ 0.913  0.719  0.95 ]\n",
      " [ 1.     0.742  0.9  ]\n",
      " [ 1.     0.783  0.7  ]\n",
      " [ 1.     0.8    0.774]\n",
      " [ 0.96   0.842  0.742]\n",
      " [ 0.96   0.767  0.85 ]\n",
      " [ 0.963  0.6    0.87 ]\n",
      " [ 0.947  0.833  0.885]\n",
      " [ 0.926  0.7    0.714]\n",
      " [ 1.     0.913  0.821]\n",
      " [ 0.947  0.767  0.846]\n",
      " [ 0.963  0.71   0.824]\n",
      " [ 0.95   0.75   0.783]]\n",
      "Recall: [[ 0.963  0.857  0.75 ]\n",
      " [ 1.     0.828  0.708]\n",
      " [ 0.875  0.852  0.792]\n",
      " [ 0.957  0.591  0.833]\n",
      " [ 0.96   0.839  0.737]\n",
      " [ 0.947  0.88   0.806]\n",
      " [ 0.963  0.846  0.909]\n",
      " [ 0.955  0.885  0.704]\n",
      " [ 0.828  0.958  0.818]\n",
      " [ 0.917  0.692  0.84 ]\n",
      " [ 0.864  0.769  0.889]\n",
      " [ 0.96   0.64   0.92 ]\n",
      " [ 0.923  0.885  0.739]\n",
      " [ 0.963  0.789  0.69 ]\n",
      " [ 0.9    0.893  0.852]\n",
      " [ 1.     0.583  0.769]\n",
      " [ 0.889  0.84   1.   ]\n",
      " [ 0.857  0.821  0.846]\n",
      " [ 0.929  0.88   0.636]\n",
      " [ 0.864  0.8    0.783]]\n",
      "F1: [[ 0.963  0.842  0.769]\n",
      " [ 0.957  0.8    0.773]\n",
      " [ 0.933  0.807  0.792]\n",
      " [ 0.917  0.634  0.82 ]\n",
      " [ 0.941  0.839  0.757]\n",
      " [ 0.973  0.815  0.847]\n",
      " [ 0.963  0.863  0.889]\n",
      " [ 0.933  0.793  0.809]\n",
      " [ 0.906  0.836  0.857]\n",
      " [ 0.957  0.735  0.764]\n",
      " [ 0.927  0.784  0.828]\n",
      " [ 0.96   0.727  0.821]\n",
      " [ 0.941  0.821  0.791]\n",
      " [ 0.963  0.682  0.769]\n",
      " [ 0.923  0.862  0.868]\n",
      " [ 0.962  0.636  0.741]\n",
      " [ 0.941  0.875  0.902]\n",
      " [ 0.9    0.793  0.846]\n",
      " [ 0.945  0.786  0.718]\n",
      " [ 0.905  0.774  0.783]]\n",
      "#################################\n",
      "SVM\n",
      "Optimal thresholds: [[ 2.5   3.85]\n",
      " [ 2.5   4.  ]\n",
      " [ 2.05  3.05]\n",
      " [ 2.4   3.95]\n",
      " [ 2.    3.  ]\n",
      " [ 2.3   3.85]\n",
      " [ 2.35  3.95]\n",
      " [ 2.3   3.85]\n",
      " [ 2.    3.  ]\n",
      " [ 2.25  3.9 ]\n",
      " [ 2.35  4.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.25  3.95]\n",
      " [ 2.25  3.85]\n",
      " [ 2.05  3.05]\n",
      " [ 2.55  3.8 ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.4   3.5 ]\n",
      " [ 2.    3.  ]]\n",
      "Accuracy: [ 0.8    0.8    0.787  0.893  0.84   0.84   0.88   0.84   0.8    0.813\n",
      "  0.853  0.787  0.773  0.787  0.827  0.773  0.827  0.813  0.813  0.773]\n",
      "Precision: [[ 0.964  0.842  0.607]\n",
      " [ 0.88   0.792  0.731]\n",
      " [ 1.     0.2    0.755]\n",
      " [ 0.92   0.792  0.962]\n",
      " [ 0.957  0.556  0.837]\n",
      " [ 1.     0.842  0.757]\n",
      " [ 0.963  0.808  0.864]\n",
      " [ 0.952  0.769  0.821]\n",
      " [ 1.     0.182  0.86 ]\n",
      " [ 0.957  0.75   0.75 ]\n",
      " [ 1.     0.815  0.786]\n",
      " [ 0.96   0.25   0.786]\n",
      " [ 0.957  0.645  0.762]\n",
      " [ 0.963  0.56   0.826]\n",
      " [ 0.947  0.286  0.857]\n",
      " [ 0.833  0.739  0.727]\n",
      " [ 1.     0.143  0.844]\n",
      " [ 0.95   0.429  0.812]\n",
      " [ 1.     0.75   0.706]\n",
      " [ 0.944  0.091  0.87 ]]\n",
      "Recall: [[ 1.     0.571  0.85 ]\n",
      " [ 1.     0.655  0.792]\n",
      " [ 0.875  0.083  0.949]\n",
      " [ 1.     0.864  0.833]\n",
      " [ 0.88   0.417  0.947]\n",
      " [ 1.     0.64   0.903]\n",
      " [ 0.963  0.84   0.826]\n",
      " [ 0.909  0.8    0.821]\n",
      " [ 0.724  0.286  0.949]\n",
      " [ 0.917  0.692  0.84 ]\n",
      " [ 0.909  0.815  0.846]\n",
      " [ 0.96   0.167  0.868]\n",
      " [ 0.846  0.769  0.696]\n",
      " [ 0.963  0.737  0.655]\n",
      " [ 0.9    0.2    0.933]\n",
      " [ 1.     0.63   0.696]\n",
      " [ 0.852  0.143  0.927]\n",
      " [ 0.905  0.231  0.951]\n",
      " [ 0.893  0.571  0.923]\n",
      " [ 0.773  0.125  0.889]]\n",
      "F1: [[ 0.982  0.681  0.708]\n",
      " [ 0.936  0.717  0.76 ]\n",
      " [ 0.933  0.118  0.841]\n",
      " [ 0.958  0.826  0.893]\n",
      " [ 0.917  0.476  0.889]\n",
      " [ 1.     0.727  0.824]\n",
      " [ 0.963  0.824  0.844]\n",
      " [ 0.93   0.784  0.821]\n",
      " [ 0.84   0.222  0.902]\n",
      " [ 0.936  0.72   0.792]\n",
      " [ 0.952  0.815  0.815]\n",
      " [ 0.96   0.2    0.825]\n",
      " [ 0.898  0.702  0.727]\n",
      " [ 0.963  0.636  0.731]\n",
      " [ 0.923  0.235  0.894]\n",
      " [ 0.909  0.68   0.711]\n",
      " [ 0.92   0.143  0.884]\n",
      " [ 0.927  0.3    0.876]\n",
      " [ 0.943  0.649  0.8  ]\n",
      " [ 0.85   0.105  0.879]]\n",
      "#################################\n"
     ]
    }
   ],
   "source": [
    "print('regressors with minimized mean squared error')\n",
    "for k, v in thresh_scores_mse.items():\n",
    "    print(k)\n",
    "    print(\"Optimal thresholds: {}\".format(np.around([x[0] for x in v], decimals = 2)))\n",
    "    print(\"Accuracy: {}\".format(np.around([x[1] for x in v], decimals = 3)))\n",
    "    print(\"Precision: {}\".format(np.around([x[2] for x in v], decimals = 3)))\n",
    "    print(\"Recall: {}\".format(np.around([x[3] for x in v], decimals = 3)))\n",
    "    print(\"F1: {}\".format(np.around([x[4] for x in v], decimals = 3)))\n",
    "    print(\"#################################\")    \n",
    "    \n",
    "print()\n",
    "print('regressors with minimized mean absolute error')\n",
    "for k, v in thresh_scores_mae.items():\n",
    "    print(k)\n",
    "    print(\"Optimal thresholds: {}\".format(np.around([x[0] for x in v], decimals = 2)))\n",
    "    print(\"Accuracy: {}\".format(np.around([x[1] for x in v], decimals = 3)))\n",
    "    print(\"Precision: {}\".format(np.around([x[2] for x in v], decimals = 3)))\n",
    "    print(\"Recall: {}\".format(np.around([x[3] for x in v], decimals = 3)))\n",
    "    print(\"F1: {}\".format(np.around([x[4] for x in v], decimals = 3)))\n",
    "    print(\"#################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaging\n",
    "avg_thresh_scores_mse = {}\n",
    "avg_thresh_scores_mae = {}\n",
    "metrics = ['thresholds', 'accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "for k, v in thresh_scores_mse.items():\n",
    "    avg_thresh_scores_mse[k] = {}\n",
    "    for i, m in enumerate(metrics):\n",
    "        avg_thresh_scores_mse[k][m] = np.average([x[i] for x in v], axis = 0)\n",
    "        \n",
    "for k, v in thresh_scores_mae.items():\n",
    "    avg_thresh_scores_mae[k] = {}\n",
    "    for i, m in enumerate(metrics):\n",
    "        avg_thresh_scores_mae[k][m] = np.average([x[i] for x in v], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AdaBoost': {'accuracy': 0.85799999999999998,\n",
       "  'f1': array([ 0.94370688,  0.05836601,  0.89268761]),\n",
       "  'precision': array([ 0.94728573,  0.11153846,  0.83270472]),\n",
       "  'recall': array([ 0.94319677,  0.05069841,  0.96560359]),\n",
       "  'thresholds': array([ 2.0025,  3.0425])},\n",
       " 'MLP': {'accuracy': 0.79999999999999993,\n",
       "  'f1': array([ 0.92839955,  0.52466184,  0.80590044]),\n",
       "  'precision': array([ 0.95127446,  0.60769077,  0.7645206 ]),\n",
       "  'recall': array([ 0.91000005,  0.48425885,  0.86705142]),\n",
       "  'thresholds': array([ 2.2175,  3.4725])},\n",
       " 'Nearest Neighbors': {'accuracy': 0.76866666666666661,\n",
       "  'f1': array([ 0.89567506,  0.39617104,  0.77882978]),\n",
       "  'precision': array([ 0.95814304,  0.42702785,  0.74358778]),\n",
       "  'recall': array([ 0.84421848,  0.38916432,  0.83032613]),\n",
       "  'thresholds': array([ 2.255 ,  3.4475])},\n",
       " 'Random Forest': {'accuracy': 0.84466666666666668,\n",
       "  'f1': array([ 0.94045448,  0.78524884,  0.80709853]),\n",
       "  'precision': array([ 0.95876508,  0.77273872,  0.8218054 ]),\n",
       "  'recall': array([ 0.92557651,  0.80642744,  0.80107434]),\n",
       "  'thresholds': array([ 2.19  ,  3.8525])},\n",
       " 'SVM': {'accuracy': 0.81599999999999984,\n",
       "  'f1': array([ 0.93206919,  0.52800453,  0.8208557 ]),\n",
       "  'precision': array([ 0.9573652 ,  0.56194996,  0.79601383]),\n",
       "  'recall': array([ 0.91341322,  0.51177491,  0.85474726]),\n",
       "  'thresholds': array([ 2.225 ,  3.5275])}}"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_thresh_scores_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S2, S6 and Pixel Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = {}\n",
    "df['s2'] = pd.read_table(dr + 's2.txt', delim_whitespace=True, dtype = dtype)\n",
    "df['s6'] = pd.read_table(dr + 's6.txt', delim_whitespace=True, dtype = dtype)\n",
    "df['px'] = pd.read_table(dr + 'pixel.txt', delim_whitespace=True, dtype = dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "for d in df.values():\n",
    "    d['BitRate'] /= 100     # transforming BitRate to percentages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "X = {}\n",
    "y = {}\n",
    "# y_bin = {}\n",
    "for k, d in df.items():\n",
    "    X[k], y[k] = np.array(d[features]), np.array(d['Quality'])\n",
    "    # y_bin[k] = label_binarize(y[k], classes = classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#mae = {}\n",
    "\n",
    "thresh = {}\n",
    "accuracy = {}\n",
    "'''\n",
    "acc = {}\n",
    "prec = {}\n",
    "recl = {}\n",
    "f1 = {}\n",
    "'''\n",
    "for r, reg in best_regressors_mae.items():\n",
    "    #mae[r] = {}\n",
    "    thresh[r] = {}\n",
    "    '''\n",
    "    acc[r] = {}\n",
    "    prec[r] = {}\n",
    "    recl[r] = {} \n",
    "    f1[r] = {}    \n",
    "    '''\n",
    "    for k in X.keys():\n",
    "        #mae[r][k] = {}\n",
    "        thresh[r][k] = {}\n",
    "        '''\n",
    "        acc[r][k] = {}\n",
    "        prec[r][k] = {}\n",
    "        recl[r][k] = {} \n",
    "        f1[r][k] = {}\n",
    "        '''\n",
    "        for k1 in X.keys():\n",
    "            if k1 != k: # train and test on other datasets\n",
    "                #pred = reg.fit(X[k], y[k]).predict(X[k1])\n",
    "                #mae[r][k][k1] = mean_absolute_error(y[k1], pred)\n",
    "                thresh[r][k][k1] = optimize_thresh(reg, X[k], y[k], X[k1], y[k1], t1_range, 10)\n",
    "                #y_label_true = to_label(y[k1], thresh_accuracy_mae[r][0])\n",
    "                #y_label_pred = to_label(pred, thresh_accuracy_mae[r][0])\n",
    "                #acc[r][k][k1] = accuracy_score(y_label_true, y_label_pred)\n",
    "                #prec[r][k][k1] = precision_score(y_label_true, y_label_pred, average = None) \n",
    "                #recl[r][k][k1] = recall_score(y_label_true, y_label_pred, average = None) \n",
    "                #f1[r][k][k1] = f1_score(y_label_true, y_label_pred, average = None)  \n",
    "            else:    # train and test on itself\n",
    "                X_tr, X_te, y_tr, y_te = train_test_split(X[k], y[k], test_size = 0.25, random_state = 1)\n",
    "                thresh[r][k][k] = optimize_thresh(reg, X_tr, y_tr, X_te, y_te, t1_range, 10)\n",
    "                #pred = reg.fit(X_tr, y_tr).predict(X_te)\n",
    "                #mae[r][k][k1] = mean_absolute_error(y_te, pred)\n",
    "                #y_label_true = to_label(y_te, thresh_accuracy_mae[r][0])\n",
    "                #y_label_pred = to_label(pred, thresh_accuracy_mae[r][0])\n",
    "                #acc[r][k][k] = accuracy_score(y_label_true, y_label_pred)\n",
    "                #prec[r][k][k] = precision_score(y_label_true, y_label_pred, average = None) \n",
    "                #recl[r][k][k] = recall_score(y_label_true, y_label_pred, average = None) \n",
    "                #f1[r][k][k] = f1_score(y_label_true, y_label_pred, average = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def print_results(dic, title):\n",
    "    print('#################################')\n",
    "    print('{} results:'.format(title))\n",
    "    for k, v in dic.items():\n",
    "        print(k)\n",
    "        for k1, v1 in v.items():\n",
    "            print(\"training set: {}\".format(k1))\n",
    "            for k2, v2 in v1.items():\n",
    "                print(\"optimal thresholds on {}: {}, {}\".format(k2, np.around(v2[0][0], decimals = 3), np.around(v2[0][1], decimals = 3)))\n",
    "                print(\"optimal accuracy on {}: {}\".format(k2, np.around(v2[1], decimals = 3)))\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "acc = {}\n",
    "prec = {}\n",
    "recl = {}\n",
    "f1 = {}\n",
    "for r, reg in best_regressors_mae.items():\n",
    "    acc[r] = {}\n",
    "    prec[r] = {}\n",
    "    recl[r] = {} \n",
    "    f1[r] = {}    \n",
    "    for k in X.keys():\n",
    "        acc[r][k] = {}\n",
    "        prec[r][k] = {}\n",
    "        recl[r][k] = {} \n",
    "        f1[r][k] = {}\n",
    "        for k1 in X.keys():\n",
    "            if k1 != k: # train and test on other datasets\n",
    "                pred = reg.fit(X[k], y[k]).predict(X[k1])\n",
    "                y_label_true = to_label(y[k1], thresh_accuracy_mse[r][0])\n",
    "                y_label_pred = to_label(pred, thresh_accuracy_mse[r][0])\n",
    "                acc[r][k][k1] = accuracy_score(y_label_true, y_label_pred)\n",
    "                prec[r][k][k1] = precision_score(y_label_true, y_label_pred, average = None) \n",
    "                recl[r][k][k1] = recall_score(y_label_true, y_label_pred, average = None) \n",
    "                f1[r][k][k1] = f1_score(y_label_true, y_label_pred, average = None)  \n",
    "            else:    # train and test on itself\n",
    "                X_tr, X_te, y_tr, y_te = train_test_split(X[k], y[k], test_size = 0.25, random_state = 1)\n",
    "                pred = reg.fit(X_tr, y_tr).predict(X_te)\n",
    "                y_label_true = to_label(y_te, thresh_accuracy_mse[r][0])\n",
    "                y_label_pred = to_label(pred, thresh_accuracy_mse[r][0])\n",
    "                acc[r][k][k] = accuracy_score(y_label_true, y_label_pred)\n",
    "                prec[r][k][k] = precision_score(y_label_true, y_label_pred, average = None) \n",
    "                recl[r][k][k] = recall_score(y_label_true, y_label_pred, average = None) \n",
    "                f1[r][k][k] = f1_score(y_label_true, y_label_pred, average = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def print_results(dic, title):\n",
    "    print('#################################')\n",
    "    print('{} results:'.format(title))\n",
    "    for k, v in dic.items():\n",
    "        print(k)\n",
    "        for k1, v1 in v.items():\n",
    "            print(\"training set: {}\".format(k1))\n",
    "            for k2, v2 in v1.items():\n",
    "                print(\"{} on {}: {}\".format(title, k2, np.around(v2, decimals = 3)))\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print_results(acc, 'accuracy')\n",
    "print_results(prec, 'precision')\n",
    "print_results(recl, 'recall')\n",
    "print_results(f1, 'f1_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: object of type <class 'float'> cannot be safely interpreted as an integer.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0f6b7fe630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(np.linspace(1, 5, 0.025), np.linspace(1, 5, 0.05))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCiIi0kxJQUREmikpiIhIs/8PcKJ+2GskMvsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0f6b480198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = best_regressors_mae['Random Forest'].fit(X_train[6], y_train[6]).predict(X_test[6])\n",
    "plt.scatter(y_test[6], y_pred, color = 'r')\n",
    "plt.plot(np.linspace(1, 5, 10), np.linspace(1, 5, 10), color='b', linestyle='dashed')\n",
    "plt.xlabel('True Score')\n",
    "plt.ylabel('Predicted Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD8CAYAAACYebj1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZmaW+h/0qLKSxoAxkgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0f71185550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p1 = plt.bar(np.arange(len(features)), best_regressors_mse['AdaBoost'].feature_importances_, width = -0.4, align = 'edge')\n",
    "p2 = plt.bar(np.arange(len(features)), best_regressors_mse['Random Forest'].feature_importances_, width = 0.4, align = 'edge')\n",
    "plt.xticks(np.arange(len(features)), tuple(features))\n",
    "plt.ylabel('Feature Importance')\n",
    "plt.legend((p1, p2), ('AdaBoost', 'Random Forest'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_roc(fpr, tpr, roc_auc, reg_name, lb):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = {0:.2f})'.format(roc_auc))\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.05])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic: {}, Class {}'.format(reg_name, lb))\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "        \n",
    "def get_roc(y_label_true, y_score_pred, class_name):\n",
    "    for x in np.nditer(y_label_true, op_flags=['readwrite']):\n",
    "        if class_name == 'Bad':\n",
    "            x[...] = 1 if x > 0 else 0\n",
    "        elif class_name == 'Good':\n",
    "            x[...] = 0 if x < 2 else 1\n",
    "        elif class_name == 'Average':\n",
    "            x[...] = 1 if x == 1 else 0\n",
    "        else:\n",
    "            print(\"invalid class name\")\n",
    "    fpr, tpr, _ = roc_curve(y_label_true, y_score_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    return (fpr, tpr, roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Good', 'Bad', 'Average']\n",
    "roc_auc = {}\n",
    "for cn in class_names:\n",
    "    roc_auc[cn] = {}\n",
    "    for k, v in best_regressors_mse.items():\n",
    "        roc_auc[cn][k] = []\n",
    "        for i in range(num_splits):\n",
    "            y_score_pred = v.fit(X_train[i], y_train[i]).predict(X_test[i])\n",
    "            y_label_true = to_label(y_test[i], thresh_scores_mse[k][i][0])  \n",
    "            roc_auc[cn][k].append(get_roc(y_label_true, y_score_pred, cn)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROC AUC for 'Good'\n",
      "AdaBoost\n",
      "0.928\n",
      "MLP\n",
      "0.931\n",
      "Nearest Neighbors\n",
      "0.9\n",
      "Random Forest\n",
      "0.943\n",
      "SVM\n",
      "0.931\n",
      "##################\n",
      "Average ROC AUC for 'Bad'\n",
      "AdaBoost\n",
      "0.974\n",
      "MLP\n",
      "0.982\n",
      "Nearest Neighbors\n",
      "0.972\n",
      "Random Forest\n",
      "0.975\n",
      "SVM\n",
      "0.983\n",
      "##################\n",
      "Average ROC AUC for 'Average'\n",
      "AdaBoost\n",
      "0.487\n",
      "MLP\n",
      "0.514\n",
      "Nearest Neighbors\n",
      "0.542\n",
      "Random Forest\n",
      "0.527\n",
      "SVM\n",
      "0.519\n",
      "##################\n"
     ]
    }
   ],
   "source": [
    "for cn, v in roc_auc.items():\n",
    "    print(\"Average ROC AUC for '{}'\".format(cn))\n",
    "    for k, v1 in v.items():\n",
    "        print(k)\n",
    "        print(np.around(np.average(v1), decimals = 3))\n",
    "    print(\"##################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def make_meshgrid(x, y, h=.02):\n",
    "    x_min, x_max = x.min() - 1, x.max() + 1\n",
    "    y_min, y_max = y.min() - 1, y.max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "\n",
    "def plot_contours(reg_name, xx, yy, **params):\n",
    "    Z = best_regressors_mae[reg_name].predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = to_label(Z, thresh_accuracy_mae[reg_name][0])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = plt.contourf(xx, yy, Z, **params)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "colors = ['red', 'green', 'blue']\n",
    "cmap = mpl.colors.ListedColormap(colors)\n",
    "rg = np.arange(0, 1.01, 0.01)\n",
    "x1, x2, lb = np.array(df_reg['BitRate']), np.array(df_reg['FreezeRatio']), np.array(df_reg['Quality'])\n",
    "xx1, xx2 = make_meshgrid(rg, rg)\n",
    "for reg, name in zip(list(best_regressors_mae.values()), list(best_regressors_mae.keys())):\n",
    "    plot_contours(name, xx1, xx2, cmap=cmap, alpha=0.8)\n",
    "    plt.scatter(x1, x2, c = lb, cmap=cmap, s=20, edgecolors='k')\n",
    "    plt.xlim(rg.min(), rg.max())\n",
    "    plt.ylim(rg.min(), rg.max())\n",
    "    plt.xlabel('Bit Rate')\n",
    "    plt.ylabel('Freeze Ratio')\n",
    "    plt.xticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.title(name)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
