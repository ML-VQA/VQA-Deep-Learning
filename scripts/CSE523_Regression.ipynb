{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "from decimal import Decimal\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier as ovr\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, auc, precision_score, recall_score, f1_score \n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dr = '~/Projects/video-qoe-labeling/new-data/Skype/'\n",
    "dtype = {'BitRate': np.float64, 'FreezeRatio': np.float64, 'Freezes': np.int32, 'Freezelength': np.float64, 'Quality': np.float64}\n",
    "df_reg = pd.read_table(dr + 'all-data.txt', delim_whitespace=True, dtype = dtype)\n",
    "df_reg['BitRate'] /= 100  # transforming BitRate to percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get (X, y) and set fold\n",
    "features = ['BitRate', 'FreezeRatio', 'Freezes', 'Freezelength']\n",
    "X, y = np.array(df_reg[features]), np.array(df_reg['Quality'])\n",
    "mse = {}\n",
    "mae = {}\n",
    "fold = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regressors = {'Random Forest': RandomForestRegressor(random_state = 1), \n",
    "               'Nearest Neighbors': KNeighborsRegressor(),\n",
    "               'SVM': SVR(),\n",
    "               'MLP': MLPRegressor(random_state = 1, max_iter = 10000),\n",
    "               'AdaBoost': AdaBoostRegressor(random_state = 1)\n",
    "              }\n",
    "\n",
    "params = {'Random Forest': {'n_estimators': range(1, 21), 'criterion': ('mse', 'mae')},\n",
    "          'Nearest Neighbors': {'n_neighbors':range(1, 11)},\n",
    "          'SVM': {'kernel':('poly', 'rbf', 'sigmoid'), 'C':[0.1, 1, 10]},\n",
    "          'MLP': {'hidden_layer_sizes': [(10,), (20,), (40,), (80,), (10,10), (20, 20), (40, 40), (80, 80)], \n",
    "                  'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "                  'activation': ('logistic', 'tanh', 'relu'), \n",
    "                  'solver': ('lbfgs', 'sgd', 'adam')},\n",
    "          'AdaBoost': {'n_estimators': [10, 20, 40, 80], 'learning_rate': [0.01, 0.1, 1, 10]}\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# function for obtaining best estimator using grid search\n",
    "def grid_search_reg(estimator, params, scoring):\n",
    "    reg = GridSearchCV(estimator, params, scoring = scoring)\n",
    "    reg.fit(X, y)\n",
    "    return (reg.best_estimator_, reg.best_score_)\n",
    "\n",
    "# function for performing k-fold cross validation on the regressors\n",
    "def k_Fold_CV_reg(estimator, n):\n",
    "    mse = []\n",
    "    kf = KFold(n_splits = n)\n",
    "    for train, test in kf.split(X):\n",
    "        pred = estimator.fit(X[train], y[train]).predict(X[test])\n",
    "        mse.append(mean_squared_error(y[test], pred))\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best_regressors_mse = {}\n",
    "best_regressors_mae = {}\n",
    "for k in regressors:\n",
    "    best_regressors_mse[k], _ = grid_search_reg(regressors[k], params[k], 'neg_mean_squared_error')\n",
    "    best_regressors_mae[k], _ = grid_search_reg(regressors[k], params[k], 'neg_mean_absolute_error')\n",
    "    mse[k] = k_Fold_CV_reg(best_regressors_mse[k], fold)\n",
    "    mae[k] = k_Fold_CV_reg(best_regressors_mae[k], fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for k, v in mse.items():\n",
    "    print(k)\n",
    "    rmse = np.sqrt(v)\n",
    "    print(\"{}_fold RMSE: \".format(fold), np.around(rmse, decimals = 3))\n",
    "    print(\"Average RMSE: {0:0.3f}\".format(np.mean(rmse)))\n",
    "    print(\"#################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for k, v in mae.items():\n",
    "    print(k)\n",
    "    print(\"{}_fold MAE: \".format(fold), np.around(v, decimals = 3))\n",
    "    print(\"Average MAE: {0:0.3f}\".format(np.mean(v)))\n",
    "    print(\"#################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_regressors_mse = {'AdaBoost': AdaBoostRegressor(base_estimator=None, learning_rate=0.1, loss='linear',\n",
    "          n_estimators=10, random_state=1),\n",
    " 'MLP': MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "        hidden_layer_sizes=(10,), learning_rate='constant',\n",
    "        learning_rate_init=0.001, max_iter=10000, momentum=0.9,\n",
    "        nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
    "        solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
    "        warm_start=False),\n",
    " 'Nearest Neighbors': KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
    "           weights='uniform'),\n",
    " 'Random Forest': RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=None,\n",
    "            max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
    "            oob_score=False, random_state=1, verbose=0, warm_start=False),\n",
    " 'SVM': SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
    "   kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)}\n",
    "\n",
    "best_regressors_mae = {'AdaBoost': AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='linear',\n",
    "          n_estimators=10, random_state=1),\n",
    " 'MLP': MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "        hidden_layer_sizes=(10,), learning_rate='constant',\n",
    "        learning_rate_init=0.001, max_iter=10000, momentum=0.9,\n",
    "        nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
    "        solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
    "        warm_start=False),\n",
    " 'Nearest Neighbors': KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
    "           weights='uniform'),\n",
    " 'Random Forest': RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=None,\n",
    "            max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
    "            oob_score=False, random_state=1, verbose=0, warm_start=False),\n",
    " 'SVM': SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
    "   kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mserr = {}\n",
    "for k, v in best_regressors_mse.items():\n",
    "    pred = v.fit(X_train, y_train).predict(X_test)\n",
    "    mserr[k] = mean_squared_error(y_test, pred)\n",
    "\n",
    "maerr = {}\n",
    "for k, v in best_regressors_mae.items():\n",
    "    pred = v.fit(X_train, y_train).predict(X_test)\n",
    "    maerr[k] = mean_absolute_error(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for k, v in mserr.items():\n",
    "    print(k)\n",
    "    print(\"MSE: \", np.around(v, decimals = 3))\n",
    "    print(\"#################################\")\n",
    "    \n",
    "for k, v in maerr.items():\n",
    "    print(k)\n",
    "    print(\"MAE: \", np.around(v, decimals = 3))\n",
    "    print(\"#################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_label(score, thresh):\n",
    "    label = []\n",
    "    for s in np.nditer(score):\n",
    "        if s < thresh[0]:\n",
    "            label.append(0)\n",
    "        elif s < thresh[1]:\n",
    "            label.append(1)\n",
    "        else:\n",
    "            label.append(2)\n",
    "    return np.array(label, dtype = int) \n",
    "\n",
    "def optimize_thresh(regressor, X_train, y_train, X_test, y_test, t1_range, top_num):\n",
    "    i = 0\n",
    "    thresh_accuracy = []\n",
    "    model = regressor.fit(X_train, y_train)\n",
    "    pred = model.predict(X_train) \n",
    "    # find optimal thresholds from training set\n",
    "    for t1 in t1_range:\n",
    "        for t2 in np.arange(t1+1, 4.01, 0.05):\n",
    "            y_label_true = to_label(y_train, (t1, t2))\n",
    "            y_label_pred = to_label(pred, (t1, t2))\n",
    "            thresh_accuracy.append(((t1, t2), accuracy_score(y_label_true, y_label_pred)))\n",
    "    thresh_accuracy.sort(key = lambda x:x[1], reverse = True)\n",
    "    # determine average thresholds\n",
    "    thresh = [x[0] for x in thresh_accuracy[:top_num]]\n",
    "    avg_thresh = np.average(thresh, axis = 0) \n",
    "    # find accuracy on test set\n",
    "    pred = model.predict(X_test)\n",
    "    y_label_true = to_label(y_test, avg_thresh)\n",
    "    y_label_pred = to_label(pred, avg_thresh)   \n",
    "    return avg_thresh, accuracy_score(y_label_true, y_label_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t1_range = np.arange(2, 3.01, 0.05)\n",
    "thresh_accuracy_mse = {}\n",
    "\n",
    "for k, reg in best_regressors_mse.items():\n",
    "    thresh_accuracy_mse[k] = optimize_thresh(reg, X_train, y_train, X_test, y_test, t1_range, 1)\n",
    "\n",
    "thresh_accuracy_mae = {}\n",
    "for k, reg in best_regressors_mae.items():\n",
    "    thresh_accuracy_mae[k] = optimize_thresh(reg, X_train, y_train, X_test, y_test, t1_range, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AdaBoost': (array([ 2.,  4.]), 0.82666666666666666),\n",
       " 'MLP': (array([ 2.35,  3.85]), 0.82666666666666666),\n",
       " 'Nearest Neighbors': (array([ 2.3,  4. ]), 0.76000000000000001),\n",
       " 'Random Forest': (array([ 2.,  4.]), 0.88),\n",
       " 'SVM': (array([ 2.,  3.]), 0.89333333333333331)}"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh_accuracy_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regressors with minimized mean squared error\n",
      "AdaBoost\n",
      "Optimal thresholds: [ 2.  4.], Test accuracy: 0.827\n",
      "#################################\n",
      "MLP\n",
      "Optimal thresholds: [ 2.35  3.85], Test accuracy: 0.827\n",
      "#################################\n",
      "Nearest Neighbors\n",
      "Optimal thresholds: [ 2.3  4. ], Test accuracy: 0.76\n",
      "#################################\n",
      "Random Forest\n",
      "Optimal thresholds: [ 2.  4.], Test accuracy: 0.88\n",
      "#################################\n",
      "SVM\n",
      "Optimal thresholds: [ 2.  3.], Test accuracy: 0.893\n",
      "#################################\n",
      "\n",
      "regressors with minimized mean absolute error\n",
      "AdaBoost\n",
      "Optimal thresholds: [ 2.  4.], Test accuracy: 0.827\n",
      "#################################\n",
      "MLP\n",
      "Optimal thresholds: [ 2.35  3.85], Test accuracy: 0.827\n",
      "#################################\n",
      "Nearest Neighbors\n",
      "Optimal thresholds: [ 2.3  4. ], Test accuracy: 0.76\n",
      "#################################\n",
      "Random Forest\n",
      "Optimal thresholds: [ 2.  4.], Test accuracy: 0.88\n",
      "#################################\n",
      "SVM\n",
      "Optimal thresholds: [ 2.  3.], Test accuracy: 0.893\n",
      "#################################\n"
     ]
    }
   ],
   "source": [
    "print('regressors with minimized mean squared error')\n",
    "for k, v in thresh_accuracy_mse.items():\n",
    "    print(k)\n",
    "    print(\"Optimal thresholds: {}, Test accuracy: {}\".format(np.around(v[0], decimals = 2), np.around(v[1], decimals = 3)))\n",
    "    print(\"#################################\")\n",
    "    \n",
    "print()\n",
    "print('regressors with minimized mean absolute error')\n",
    "for k, v in thresh_accuracy_mae.items():\n",
    "    print(k)\n",
    "    print(\"Optimal thresholds: {}, Test accuracy: {}\".format(np.around(v[0], decimals = 2), np.around(v[1], decimals = 3)))\n",
    "    print(\"#################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S2, S6 and Pixel Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {}\n",
    "df['s2'] = pd.read_table(dr + 's2.txt', delim_whitespace=True, dtype = dtype)\n",
    "df['s6'] = pd.read_table(dr + 's6.txt', delim_whitespace=True, dtype = dtype)\n",
    "df['px'] = pd.read_table(dr + 'pixel.txt', delim_whitespace=True, dtype = dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for d in df.values():\n",
    "    d['BitRate'] /= 100     # transforming BitRate to percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = {}\n",
    "y = {}\n",
    "# y_bin = {}\n",
    "for k, d in df.items():\n",
    "    X[k], y[k] = np.array(d[features]), np.array(d['Quality'])\n",
    "    # y_bin[k] = label_binarize(y[k], classes = classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#mae = {}\n",
    "\n",
    "thresh = {}\n",
    "accuracy = {}\n",
    "'''\n",
    "acc = {}\n",
    "prec = {}\n",
    "recl = {}\n",
    "f1 = {}\n",
    "'''\n",
    "for r, reg in best_regressors_mae.items():\n",
    "    #mae[r] = {}\n",
    "    thresh[r] = {}\n",
    "    '''\n",
    "    acc[r] = {}\n",
    "    prec[r] = {}\n",
    "    recl[r] = {} \n",
    "    f1[r] = {}    \n",
    "    '''\n",
    "    for k in X.keys():\n",
    "        #mae[r][k] = {}\n",
    "        thresh[r][k] = {}\n",
    "        '''\n",
    "        acc[r][k] = {}\n",
    "        prec[r][k] = {}\n",
    "        recl[r][k] = {} \n",
    "        f1[r][k] = {}\n",
    "        '''\n",
    "        for k1 in X.keys():\n",
    "            if k1 != k: # train and test on other datasets\n",
    "                #pred = reg.fit(X[k], y[k]).predict(X[k1])\n",
    "                #mae[r][k][k1] = mean_absolute_error(y[k1], pred)\n",
    "                thresh[r][k][k1] = optimize_thresh(reg, X[k], y[k], X[k1], y[k1], t1_range, 10)\n",
    "                #y_label_true = to_label(y[k1], thresh_accuracy_mae[r][0])\n",
    "                #y_label_pred = to_label(pred, thresh_accuracy_mae[r][0])\n",
    "                #acc[r][k][k1] = accuracy_score(y_label_true, y_label_pred)\n",
    "                #prec[r][k][k1] = precision_score(y_label_true, y_label_pred, average = None) \n",
    "                #recl[r][k][k1] = recall_score(y_label_true, y_label_pred, average = None) \n",
    "                #f1[r][k][k1] = f1_score(y_label_true, y_label_pred, average = None)  \n",
    "            else:    # train and test on itself\n",
    "                X_tr, X_te, y_tr, y_te = train_test_split(X[k], y[k], test_size = 0.25, random_state = 1)\n",
    "                thresh[r][k][k] = optimize_thresh(reg, X_tr, y_tr, X_te, y_te, t1_range, 10)\n",
    "                #pred = reg.fit(X_tr, y_tr).predict(X_te)\n",
    "                #mae[r][k][k1] = mean_absolute_error(y_te, pred)\n",
    "                #y_label_true = to_label(y_te, thresh_accuracy_mae[r][0])\n",
    "                #y_label_pred = to_label(pred, thresh_accuracy_mae[r][0])\n",
    "                #acc[r][k][k] = accuracy_score(y_label_true, y_label_pred)\n",
    "                #prec[r][k][k] = precision_score(y_label_true, y_label_pred, average = None) \n",
    "                #recl[r][k][k] = recall_score(y_label_true, y_label_pred, average = None) \n",
    "                #f1[r][k][k] = f1_score(y_label_true, y_label_pred, average = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def print_results(dic, title):\n",
    "    print('#################################')\n",
    "    print('{} results:'.format(title))\n",
    "    for k, v in dic.items():\n",
    "        print(k)\n",
    "        for k1, v1 in v.items():\n",
    "            print(\"training set: {}\".format(k1))\n",
    "            for k2, v2 in v1.items():\n",
    "                print(\"optimal thresholds on {}: {}, {}\".format(k2, np.around(v2[0][0], decimals = 3), np.around(v2[0][1], decimals = 3)))\n",
    "                print(\"optimal accuracy on {}: {}\".format(k2, np.around(v2[1], decimals = 3)))\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "acc = {}\n",
    "prec = {}\n",
    "recl = {}\n",
    "f1 = {}\n",
    "for r, reg in best_regressors_mae.items():\n",
    "    acc[r] = {}\n",
    "    prec[r] = {}\n",
    "    recl[r] = {} \n",
    "    f1[r] = {}    \n",
    "    for k in X.keys():\n",
    "        acc[r][k] = {}\n",
    "        prec[r][k] = {}\n",
    "        recl[r][k] = {} \n",
    "        f1[r][k] = {}\n",
    "        for k1 in X.keys():\n",
    "            if k1 != k: # train and test on other datasets\n",
    "                pred = reg.fit(X[k], y[k]).predict(X[k1])\n",
    "                y_label_true = to_label(y[k1], thresh_accuracy_mse[r][0])\n",
    "                y_label_pred = to_label(pred, thresh_accuracy_mse[r][0])\n",
    "                acc[r][k][k1] = accuracy_score(y_label_true, y_label_pred)\n",
    "                prec[r][k][k1] = precision_score(y_label_true, y_label_pred, average = None) \n",
    "                recl[r][k][k1] = recall_score(y_label_true, y_label_pred, average = None) \n",
    "                f1[r][k][k1] = f1_score(y_label_true, y_label_pred, average = None)  \n",
    "            else:    # train and test on itself\n",
    "                X_tr, X_te, y_tr, y_te = train_test_split(X[k], y[k], test_size = 0.25, random_state = 1)\n",
    "                pred = reg.fit(X_tr, y_tr).predict(X_te)\n",
    "                y_label_true = to_label(y_te, thresh_accuracy_mse[r][0])\n",
    "                y_label_pred = to_label(pred, thresh_accuracy_mse[r][0])\n",
    "                acc[r][k][k] = accuracy_score(y_label_true, y_label_pred)\n",
    "                prec[r][k][k] = precision_score(y_label_true, y_label_pred, average = None) \n",
    "                recl[r][k][k] = recall_score(y_label_true, y_label_pred, average = None) \n",
    "                f1[r][k][k] = f1_score(y_label_true, y_label_pred, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_results(dic, title):\n",
    "    print('#################################')\n",
    "    print('{} results:'.format(title))\n",
    "    for k, v in dic.items():\n",
    "        print(k)\n",
    "        for k1, v1 in v.items():\n",
    "            print(\"training set: {}\".format(k1))\n",
    "            for k2, v2 in v1.items():\n",
    "                print(\"{} on {}: {}\".format(title, k2, np.around(v2, decimals = 3)))\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################\n",
      "accuracy results:\n",
      "AdaBoost\n",
      "training set: s2\n",
      "accuracy on s2: 0.84\n",
      "accuracy on s6: 0.86\n",
      "accuracy on px: 0.77\n",
      "training set: s6\n",
      "accuracy on s2: 0.9\n",
      "accuracy on s6: 0.84\n",
      "accuracy on px: 0.71\n",
      "training set: px\n",
      "accuracy on s2: 0.83\n",
      "accuracy on s6: 0.72\n",
      "accuracy on px: 0.92\n",
      "\n",
      "MLP\n",
      "training set: s2\n",
      "accuracy on s2: 0.72\n",
      "accuracy on s6: 0.76\n",
      "accuracy on px: 0.8\n",
      "training set: s6\n",
      "accuracy on s2: 0.8\n",
      "accuracy on s6: 0.84\n",
      "accuracy on px: 0.79\n",
      "training set: px\n",
      "accuracy on s2: 0.78\n",
      "accuracy on s6: 0.7\n",
      "accuracy on px: 0.84\n",
      "\n",
      "Nearest Neighbors\n",
      "training set: s2\n",
      "accuracy on s2: 0.76\n",
      "accuracy on s6: 0.76\n",
      "accuracy on px: 0.79\n",
      "training set: s6\n",
      "accuracy on s2: 0.81\n",
      "accuracy on s6: 0.64\n",
      "accuracy on px: 0.82\n",
      "training set: px\n",
      "accuracy on s2: 0.81\n",
      "accuracy on s6: 0.73\n",
      "accuracy on px: 0.84\n",
      "\n",
      "Random Forest\n",
      "training set: s2\n",
      "accuracy on s2: 0.76\n",
      "accuracy on s6: 0.81\n",
      "accuracy on px: 0.74\n",
      "training set: s6\n",
      "accuracy on s2: 0.84\n",
      "accuracy on s6: 0.88\n",
      "accuracy on px: 0.69\n",
      "training set: px\n",
      "accuracy on s2: 0.79\n",
      "accuracy on s6: 0.73\n",
      "accuracy on px: 0.88\n",
      "\n",
      "SVM\n",
      "training set: s2\n",
      "accuracy on s2: 0.76\n",
      "accuracy on s6: 0.84\n",
      "accuracy on px: 0.79\n",
      "training set: s6\n",
      "accuracy on s2: 0.88\n",
      "accuracy on s6: 0.76\n",
      "accuracy on px: 0.74\n",
      "training set: px\n",
      "accuracy on s2: 0.85\n",
      "accuracy on s6: 0.76\n",
      "accuracy on px: 0.84\n",
      "\n",
      "\n",
      "#################################\n",
      "precision results:\n",
      "AdaBoost\n",
      "training set: s2\n",
      "precision on s2: [ 1.     0.     0.733]\n",
      "precision on s6: [ 0.905  0.     0.828]\n",
      "precision on px: [ 0.643  0.     0.819]\n",
      "training set: s6\n",
      "precision on s2: [ 1.     0.333  0.875]\n",
      "precision on s6: [ 1.    0.    0.75]\n",
      "precision on px: [ 0.548  0.2    0.828]\n",
      "training set: px\n",
      "precision on s2: [ 1.     0.     0.841]\n",
      "precision on s6: [ 1.     0.     0.797]\n",
      "precision on px: [ 1.     0.5    0.944]\n",
      "\n",
      "MLP\n",
      "training set: s2\n",
      "precision on s2: [ 1.     0.8    0.455]\n",
      "precision on s6: [ 0.925  0.556  0.69 ]\n",
      "precision on px: [ 0.9    0.625  0.875]\n",
      "training set: s6\n",
      "precision on s2: [ 1.     0.727  0.696]\n",
      "precision on s6: [ 1.     1.     0.667]\n",
      "precision on px: [ 0.81   0.613  0.896]\n",
      "training set: px\n",
      "precision on s2: [ 1.     0.579  0.741]\n",
      "precision on s6: [ 0.935  0.423  0.698]\n",
      "precision on px: [ 1.     0.6    0.875]\n",
      "\n",
      "Nearest Neighbors\n",
      "training set: s2\n",
      "precision on s2: [ 1.     0.     0.688]\n",
      "precision on s6: [ 1.     0.143  0.8  ]\n",
      "precision on px: [ 0.944  0.2    0.833]\n",
      "training set: s6\n",
      "precision on s2: [ 1.     0.     0.857]\n",
      "precision on s6: [ 1.     0.286  0.75 ]\n",
      "precision on px: [ 0.833  0.333  0.857]\n",
      "training set: px\n",
      "precision on s2: [ 1.     0.     0.829]\n",
      "precision on s6: [ 1.     0.     0.718]\n",
      "precision on px: [ 1.     0.     0.895]\n",
      "\n",
      "Random Forest\n",
      "training set: s2\n",
      "precision on s2: [ 1.     1.     0.333]\n",
      "precision on s6: [ 0.905  0.72   0.758]\n",
      "precision on px: [ 0.643  0.71   0.829]\n",
      "training set: s6\n",
      "precision on s2: [ 0.971  0.87   0.721]\n",
      "precision on s6: [ 1.   1.   0.7]\n",
      "precision on px: [ 0.567  0.645  0.821]\n",
      "training set: px\n",
      "precision on s2: [ 1.     0.676  0.744]\n",
      "precision on s6: [ 1.     0.556  0.625]\n",
      "precision on px: [ 1.     0.833  0.857]\n",
      "\n",
      "SVM\n",
      "training set: s2\n",
      "precision on s2: [ 1.     0.     0.733]\n",
      "precision on s6: [ 1.     0.231  0.887]\n",
      "precision on px: [ 0.9    0.3    0.917]\n",
      "training set: s6\n",
      "precision on s2: [ 1.     0.     0.862]\n",
      "precision on s6: [ 1.     0.333  0.857]\n",
      "precision on px: [ 0.864  0.15   0.897]\n",
      "training set: px\n",
      "precision on s2: [ 1.     0.     0.866]\n",
      "precision on s6: [ 1.     0.     0.831]\n",
      "precision on px: [ 1.     0.25   0.944]\n",
      "\n",
      "\n",
      "#################################\n",
      "recall results:\n",
      "AdaBoost\n",
      "training set: s2\n",
      "recall on s2: [ 1.  0.  1.]\n",
      "recall on s6: [ 0.95   0.     0.941]\n",
      "recall on px: [ 0.72   0.     0.922]\n",
      "training set: s6\n",
      "recall on s2: [ 1.     0.111  0.966]\n",
      "recall on s6: [ 1.  0.  1.]\n",
      "recall on px: [ 0.68   0.091  0.828]\n",
      "training set: px\n",
      "recall on s2: [ 0.758  0.     1.   ]\n",
      "recall on s6: [ 0.525  0.     1.   ]\n",
      "recall on px: [ 0.833  0.5    1.   ]\n",
      "\n",
      "MLP\n",
      "training set: s2\n",
      "recall on s2: [ 0.9  0.4  1. ]\n",
      "recall on s6: [ 0.925  0.385  0.853]\n",
      "recall on px: [ 0.72   0.769  0.857]\n",
      "training set: s6\n",
      "recall on s2: [ 1.     0.32   0.929]\n",
      "recall on s6: [ 1.   0.5  1. ]\n",
      "recall on px: [ 0.68   0.731  0.878]\n",
      "training set: px\n",
      "recall on s2: [ 0.818  0.44   0.952]\n",
      "recall on s6: [ 0.725  0.423  0.882]\n",
      "recall on px: [ 0.667  0.6    1.   ]\n",
      "\n",
      "Nearest Neighbors\n",
      "training set: s2\n",
      "recall on s2: [ 0.8  0.   1. ]\n",
      "recall on s6: [ 0.65   0.222  0.941]\n",
      "recall on px: [ 0.68   0.182  0.938]\n",
      "training set: s6\n",
      "recall on s2: [ 0.818  0.     0.931]\n",
      "recall on s6: [ 0.222  0.5    1.   ]\n",
      "recall on px: [ 0.8    0.182  0.938]\n",
      "training set: px\n",
      "recall on s2: [ 0.697  0.     1.   ]\n",
      "recall on s6: [ 0.55  0.    1.  ]\n",
      "recall on px: [ 0.667  0.     1.   ]\n",
      "\n",
      "Random Forest\n",
      "training set: s2\n",
      "recall on s2: [ 1.   0.5  1. ]\n",
      "recall on s6: [ 0.95   0.6    0.833]\n",
      "recall on px: [ 0.72   0.611  0.872]\n",
      "training set: s6\n",
      "recall on s2: [ 1.     0.606  0.912]\n",
      "recall on s6: [ 1.     0.667  1.   ]\n",
      "recall on px: [ 0.68   0.556  0.821]\n",
      "training set: px\n",
      "recall on s2: [ 0.818  0.697  0.853]\n",
      "recall on s6: [ 0.825  0.5    0.833]\n",
      "recall on px: [ 0.833  0.714  1.   ]\n",
      "\n",
      "SVM\n",
      "training set: s2\n",
      "recall on s2: [ 0.8  0.   1. ]\n",
      "recall on s6: [ 0.85   0.333  0.922]\n",
      "recall on px: [ 0.72   0.545  0.859]\n",
      "training set: s6\n",
      "recall on s2: [ 0.97   0.     0.966]\n",
      "recall on s6: [ 0.556  0.5    1.   ]\n",
      "recall on px: [ 0.76   0.273  0.812]\n",
      "training set: px\n",
      "recall on s2: [ 0.818  0.     1.   ]\n",
      "recall on s6: [ 0.675  0.     0.961]\n",
      "recall on px: [ 0.5  0.5  1. ]\n",
      "\n",
      "\n",
      "#################################\n",
      "f1_score results:\n",
      "AdaBoost\n",
      "training set: s2\n",
      "f1_score on s2: [ 1.     0.     0.846]\n",
      "f1_score on s6: [ 0.927  0.     0.881]\n",
      "f1_score on px: [ 0.679  0.     0.868]\n",
      "training set: s6\n",
      "f1_score on s2: [ 1.     0.167  0.918]\n",
      "f1_score on s6: [ 1.     0.     0.857]\n",
      "f1_score on px: [ 0.607  0.125  0.828]\n",
      "training set: px\n",
      "f1_score on s2: [ 0.862  0.     0.913]\n",
      "f1_score on s6: [ 0.689  0.     0.887]\n",
      "f1_score on px: [ 0.909  0.5    0.971]\n",
      "\n",
      "MLP\n",
      "training set: s2\n",
      "f1_score on s2: [ 0.947  0.533  0.625]\n",
      "f1_score on s6: [ 0.925  0.455  0.763]\n",
      "f1_score on px: [ 0.8    0.69   0.866]\n",
      "training set: s6\n",
      "f1_score on s2: [ 1.     0.444  0.796]\n",
      "f1_score on s6: [ 1.     0.667  0.8  ]\n",
      "f1_score on px: [ 0.739  0.667  0.887]\n",
      "training set: px\n",
      "f1_score on s2: [ 0.9    0.5    0.833]\n",
      "f1_score on s6: [ 0.817  0.423  0.779]\n",
      "f1_score on px: [ 0.8    0.6    0.933]\n",
      "\n",
      "Nearest Neighbors\n",
      "training set: s2\n",
      "f1_score on s2: [ 0.889  0.     0.815]\n",
      "f1_score on s6: [ 0.788  0.174  0.865]\n",
      "f1_score on px: [ 0.791  0.19   0.882]\n",
      "training set: s6\n",
      "f1_score on s2: [ 0.9    0.     0.893]\n",
      "f1_score on s6: [ 0.364  0.364  0.857]\n",
      "f1_score on px: [ 0.816  0.235  0.896]\n",
      "training set: px\n",
      "f1_score on s2: [ 0.821  0.     0.906]\n",
      "f1_score on s6: [ 0.71   0.     0.836]\n",
      "f1_score on px: [ 0.8    0.     0.944]\n",
      "\n",
      "Random Forest\n",
      "training set: s2\n",
      "f1_score on s2: [ 1.     0.667  0.5  ]\n",
      "f1_score on s6: [ 0.927  0.655  0.794]\n",
      "f1_score on px: [ 0.679  0.657  0.85 ]\n",
      "training set: s6\n",
      "f1_score on s2: [ 0.985  0.714  0.805]\n",
      "f1_score on s6: [ 1.     0.8    0.824]\n",
      "f1_score on px: [ 0.618  0.597  0.821]\n",
      "training set: px\n",
      "f1_score on s2: [ 0.9    0.687  0.795]\n",
      "f1_score on s6: [ 0.904  0.526  0.714]\n",
      "f1_score on px: [ 0.909  0.769  0.923]\n",
      "\n",
      "SVM\n",
      "training set: s2\n",
      "f1_score on s2: [ 0.889  0.     0.846]\n",
      "f1_score on s6: [ 0.919  0.273  0.904]\n",
      "f1_score on px: [ 0.8    0.387  0.887]\n",
      "training set: s6\n",
      "f1_score on s2: [ 0.985  0.     0.911]\n",
      "f1_score on s6: [ 0.714  0.4    0.923]\n",
      "f1_score on px: [ 0.809  0.194  0.852]\n",
      "training set: px\n",
      "f1_score on s2: [ 0.9    0.     0.928]\n",
      "f1_score on s6: [ 0.806  0.     0.891]\n",
      "f1_score on px: [ 0.667  0.333  0.971]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_results(acc, 'accuracy')\n",
    "print_results(prec, 'precision')\n",
    "print_results(recl, 'recall')\n",
    "print_results(f1, 'f1_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD8CAYAAACYebj1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZmaW+h/0qLKSxoAxkgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0f71185550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p1 = plt.bar(np.arange(len(features)), best_regressors_mse['AdaBoost'].feature_importances_, width = -0.4, align = 'edge')\n",
    "p2 = plt.bar(np.arange(len(features)), best_regressors_mse['Random Forest'].feature_importances_, width = 0.4, align = 'edge')\n",
    "plt.xticks(np.arange(len(features)), tuple(features))\n",
    "plt.ylabel('Feature Importance')\n",
    "plt.legend((p1, p2), ('AdaBoost', 'Random Forest'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_classes = 3\n",
    "\n",
    "def plot_roc(fpr, tpr, roc_auc, clf_name, lb):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = {0:.2f})'.format(roc_auc))\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.05])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic: {}, Class {}'.format(clf_name, lb))\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "        \n",
    "def get_roc(X_tr, y_tr, X_te, y_te, clf):\n",
    "    fpr = {}\n",
    "    tpr = {}\n",
    "    roc_auc = {}\n",
    "    y_score = ovr(clf).fit(X_tr, y_tr).predict_proba(X_te)\n",
    "    for i in range(len(num_classes)):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_te[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    return (fpr, tpr, roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for k, v in best_regressors.items():\n",
    "    fpr, tpr, roc_auc = get_roc(X_train, y_train, X_test, y_test, v)\n",
    "    for i in classes:\n",
    "        plot_roc(fpr[i], tpr[i], roc_auc[i], k, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def make_meshgrid(x, y, h=.02):\n",
    "    x_min, x_max = x.min() - 1, x.max() + 1\n",
    "    y_min, y_max = y.min() - 1, y.max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "\n",
    "def plot_contours(reg_name, xx, yy, **params):\n",
    "    Z = best_regressors_mae[reg_name].predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = to_label(Z, thresh_accuracy_mae[reg_name][0])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = plt.contourf(xx, yy, Z, **params)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "colors = ['red', 'green', 'blue']\n",
    "cmap = mpl.colors.ListedColormap(colors)\n",
    "rg = np.arange(0, 1.01, 0.01)\n",
    "x1, x2, lb = np.array(df_reg['BitRate']), np.array(df_reg['FreezeRatio']), np.array(df_reg['Quality'])\n",
    "xx1, xx2 = make_meshgrid(rg, rg)\n",
    "for reg, name in zip(list(best_regressors_mae.values()), list(best_regressors_mae.keys())):\n",
    "    plot_contours(name, xx1, xx2, cmap=cmap, alpha=0.8)\n",
    "    plt.scatter(x1, x2, c = lb, cmap=cmap, s=20, edgecolors='k')\n",
    "    plt.xlim(rg.min(), rg.max())\n",
    "    plt.ylim(rg.min(), rg.max())\n",
    "    plt.xlabel('Bit Rate')\n",
    "    plt.ylabel('Freeze Ratio')\n",
    "    plt.xticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.title(name)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
