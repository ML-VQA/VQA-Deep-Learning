{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "from decimal import Decimal\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier as ovr\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, auc, precision_score, recall_score, f1_score \n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dr = '~/Projects/video-qoe-labeling/new-data/Skype/'\n",
    "dtype = {'BitRate': np.float64, 'FreezeRatio': np.float64, 'Freezes': np.int32, 'Freezelength': np.float64, 'Quality': np.float64}\n",
    "df_reg = pd.read_table(dr + 'all-data.txt', delim_whitespace=True, dtype = dtype)\n",
    "df_reg['BitRate'] /= 100  # transforming BitRate to percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get (X, y) and set fold\n",
    "features = ['BitRate', 'FreezeRatio', 'Freezes', 'Freezelength']\n",
    "X, y = np.array(df_reg[features]), np.array(df_reg['Quality'])\n",
    "mse = {}\n",
    "mae = {}\n",
    "fold = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regressors = {'Random Forest': RandomForestRegressor(random_state = 1), \n",
    "               'Nearest Neighbors': KNeighborsRegressor(),\n",
    "               'SVM': SVR(),\n",
    "               'MLP': MLPRegressor(random_state = 1, max_iter = 10000),\n",
    "               'AdaBoost': AdaBoostRegressor(random_state = 1)\n",
    "              }\n",
    "\n",
    "params = {'Random Forest': {'n_estimators': range(1, 21), 'criterion': ('mse', 'mae')},\n",
    "          'Nearest Neighbors': {'n_neighbors':range(1, 11)},\n",
    "          'SVM': {'kernel':('poly', 'rbf', 'sigmoid'), 'C':[0.1, 1, 10]},\n",
    "          'MLP': {'hidden_layer_sizes': [(10,), (20,), (40,), (80,), (10,10), (20, 20), (40, 40), (80, 80)], \n",
    "                  'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "                  'activation': ('logistic', 'tanh', 'relu'), \n",
    "                  'solver': ('lbfgs', 'sgd', 'adam')},\n",
    "          'AdaBoost': {'n_estimators': [10, 20, 40, 80], 'learning_rate': [0.01, 0.1, 1, 10]}\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# function for obtaining best estimator using grid search\n",
    "def grid_search_reg(estimator, params, scoring):\n",
    "    reg = GridSearchCV(estimator, params, scoring = scoring)\n",
    "    reg.fit(X, y)\n",
    "    return (reg.best_estimator_, reg.best_score_)\n",
    "\n",
    "# function for performing k-fold cross validation on the regressors\n",
    "def k_Fold_CV_reg(estimator, n):\n",
    "    mse = []\n",
    "    kf = KFold(n_splits = n)\n",
    "    for train, test in kf.split(X):\n",
    "        pred = estimator.fit(X[train], y[train]).predict(X[test])\n",
    "        mse.append(mean_squared_error(y[test], pred))\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best_regressors_mse = {}\n",
    "best_regressors_mae = {}\n",
    "for k in regressors:\n",
    "    best_regressors_mse[k], _ = grid_search_reg(regressors[k], params[k], 'neg_mean_squared_error')\n",
    "    best_regressors_mae[k], _ = grid_search_reg(regressors[k], params[k], 'neg_mean_absolute_error')\n",
    "    mse[k] = k_Fold_CV_reg(best_regressors_mse[k], fold)\n",
    "    mae[k] = k_Fold_CV_reg(best_regressors_mae[k], fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for k, v in mse.items():\n",
    "    print(k)\n",
    "    rmse = np.sqrt(v)\n",
    "    print(\"{}_fold RMSE: \".format(fold), np.around(rmse, decimals = 3))\n",
    "    print(\"Average RMSE: {0:0.3f}\".format(np.mean(rmse)))\n",
    "    print(\"#################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for k, v in mae.items():\n",
    "    print(k)\n",
    "    print(\"{}_fold MAE: \".format(fold), np.around(v, decimals = 3))\n",
    "    print(\"Average MAE: {0:0.3f}\".format(np.mean(v)))\n",
    "    print(\"#################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_regressors_mse = {'AdaBoost': AdaBoostRegressor(base_estimator=None, learning_rate=0.1, loss='linear',\n",
    "          n_estimators=10, random_state=1),\n",
    " 'MLP': MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "        hidden_layer_sizes=(10,), learning_rate='constant',\n",
    "        learning_rate_init=0.001, max_iter=10000, momentum=0.9,\n",
    "        nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
    "        solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
    "        warm_start=False),\n",
    " 'Nearest Neighbors': KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
    "           weights='uniform'),\n",
    " 'Random Forest': RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=None,\n",
    "            max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
    "            oob_score=False, random_state=1, verbose=0, warm_start=False),\n",
    " 'SVM': SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
    "   kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)}\n",
    "\n",
    "best_regressors_mae = {'AdaBoost': AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='linear',\n",
    "          n_estimators=10, random_state=1),\n",
    " 'MLP': MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "        hidden_layer_sizes=(10,), learning_rate='constant',\n",
    "        learning_rate_init=0.001, max_iter=10000, momentum=0.9,\n",
    "        nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
    "        solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
    "        warm_start=False),\n",
    " 'Nearest Neighbors': KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
    "           weights='uniform'),\n",
    " 'Random Forest': RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=None,\n",
    "            max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
    "            oob_score=False, random_state=1, verbose=0, warm_start=False),\n",
    " 'SVM': SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
    "   kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mserr = {}\n",
    "for k, v in best_regressors_mse.items():\n",
    "    pred = v.fit(X_train, y_train).predict(X_test)\n",
    "    mserr[k] = mean_squared_error(y_test, pred)\n",
    "\n",
    "maerr = {}\n",
    "for k, v in best_regressors_mae.items():\n",
    "    pred = v.fit(X_train, y_train).predict(X_test)\n",
    "    maerr[k] = mean_absolute_error(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for k, v in mserr.items():\n",
    "    print(k)\n",
    "    print(\"MSE: \", np.around(v, decimals = 3))\n",
    "    print(\"#################################\")\n",
    "    \n",
    "for k, v in maerr.items():\n",
    "    print(k)\n",
    "    print(\"MAE: \", np.around(v, decimals = 3))\n",
    "    print(\"#################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_label(score, thresh):\n",
    "    label = []\n",
    "    for s in np.nditer(score):\n",
    "        if s < thresh[0]:\n",
    "            label.append(0)\n",
    "        elif s < thresh[1]:\n",
    "            label.append(1)\n",
    "        else:\n",
    "            label.append(2)\n",
    "    return np.array(label, dtype = int) \n",
    "\n",
    "def optimize_thresh(regressor, X_train, y_train, X_test, y_test, t1_range, top_num):\n",
    "    i = 0\n",
    "    thresh_accuracy = []\n",
    "    model = regressor.fit(X_train, y_train)\n",
    "    pred = model.predict(X_train) \n",
    "    # find optimal thresholds from training set\n",
    "    for t1 in t1_range:\n",
    "        for t2 in np.arange(t1+1, 4.01, 0.05):\n",
    "            y_label_true = to_label(y_train, (t1, t2))\n",
    "            y_label_pred = to_label(pred, (t1, t2))\n",
    "            thresh_accuracy.append(((t1, t2), accuracy_score(y_label_true, y_label_pred)))\n",
    "    thresh_accuracy.sort(key = lambda x:x[1], reverse = True)\n",
    "    # determine average thresholds\n",
    "    thresh = [x[0] for x in thresh_accuracy[:top_num]]\n",
    "    avg_thresh = np.average(thresh, axis = 0) \n",
    "    # find accuracy on test set\n",
    "    pred = model.predict(X_test)\n",
    "    y_label_true = to_label(y_test, avg_thresh)\n",
    "    y_label_pred = to_label(pred, avg_thresh)   \n",
    "    return avg_thresh, accuracy_score(y_label_true, y_label_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t1_range = np.arange(2, 3.01, 0.05)\n",
    "thresh_accuracy_mse = {}\n",
    "\n",
    "for k, reg in best_regressors_mse.items():\n",
    "    thresh_accuracy_mse[k] = optimize_thresh(reg, X_train, y_train, X_test, y_test, t1_range, 1)\n",
    "\n",
    "thresh_accuracy_mae = {}\n",
    "for k, reg in best_regressors_mae.items():\n",
    "    thresh_accuracy_mae[k] = optimize_thresh(reg, X_train, y_train, X_test, y_test, t1_range, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AdaBoost': (array([ 2.,  3.]), 0.91919191919191923),\n",
       " 'MLP': (array([ 2.2 ,  3.45]), 0.83838383838383834),\n",
       " 'Nearest Neighbors': (array([ 2.,  3.]), 0.87878787878787878),\n",
       " 'Random Forest': (array([ 2.35,  3.75]), 0.88888888888888884),\n",
       " 'SVM': (array([ 2.,  3.]), 0.86868686868686873)}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh_accuracy_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regressors with minimized mean squared error\n",
      "AdaBoost\n",
      "Optimal thresholds: [ 2.  3.], Test accuracy: 0.919\n",
      "#################################\n",
      "MLP\n",
      "Optimal thresholds: [ 2.2   3.45], Test accuracy: 0.838\n",
      "#################################\n",
      "Nearest Neighbors\n",
      "Optimal thresholds: [ 2.  3.], Test accuracy: 0.879\n",
      "#################################\n",
      "Random Forest\n",
      "Optimal thresholds: [ 2.35  3.75], Test accuracy: 0.889\n",
      "#################################\n",
      "SVM\n",
      "Optimal thresholds: [ 2.  3.], Test accuracy: 0.869\n",
      "#################################\n",
      "\n",
      "regressors with minimized mean absolute error\n",
      "AdaBoost\n",
      "Optimal thresholds: [ 2.05  4.  ], Test accuracy: 0.889\n",
      "#################################\n",
      "MLP\n",
      "Optimal thresholds: [ 2.2   3.45], Test accuracy: 0.838\n",
      "#################################\n",
      "Nearest Neighbors\n",
      "Optimal thresholds: [ 2.  3.], Test accuracy: 0.879\n",
      "#################################\n",
      "Random Forest\n",
      "Optimal thresholds: [ 2.35  3.75], Test accuracy: 0.889\n",
      "#################################\n",
      "SVM\n",
      "Optimal thresholds: [ 2.  3.], Test accuracy: 0.869\n",
      "#################################\n"
     ]
    }
   ],
   "source": [
    "print('regressors with minimized mean squared error')\n",
    "for k, v in thresh_accuracy_mse.items():\n",
    "    print(k)\n",
    "    print(\"Optimal thresholds: {}, Test accuracy: {}\".format(np.around(v[0], decimals = 2), np.around(v[1], decimals = 3)))\n",
    "    print(\"#################################\")\n",
    "    \n",
    "print()\n",
    "print('regressors with minimized mean absolute error')\n",
    "for k, v in thresh_accuracy_mae.items():\n",
    "    print(k)\n",
    "    print(\"Optimal thresholds: {}, Test accuracy: {}\".format(np.around(v[0], decimals = 2), np.around(v[1], decimals = 3)))\n",
    "    print(\"#################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S2, S6 and Pixel Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {}\n",
    "df['s2'] = pd.read_table(dr + 's2.txt', delim_whitespace=True, dtype = dtype)\n",
    "df['s6'] = pd.read_table(dr + 's6.txt', delim_whitespace=True, dtype = dtype)\n",
    "df['px'] = pd.read_table(dr + 'pixel.txt', delim_whitespace=True, dtype = dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for d in df.values():\n",
    "    d['BitRate'] /= 100     # transforming BitRate to percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = {}\n",
    "y = {}\n",
    "# y_bin = {}\n",
    "for k, d in df.items():\n",
    "    X[k], y[k] = np.array(d[features]), np.array(d['Quality'])\n",
    "    # y_bin[k] = label_binarize(y[k], classes = classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#mae = {}\n",
    "\n",
    "thresh = {}\n",
    "accuracy = {}\n",
    "'''\n",
    "acc = {}\n",
    "prec = {}\n",
    "recl = {}\n",
    "f1 = {}\n",
    "'''\n",
    "for r, reg in best_regressors_mae.items():\n",
    "    #mae[r] = {}\n",
    "    thresh[r] = {}\n",
    "    '''\n",
    "    acc[r] = {}\n",
    "    prec[r] = {}\n",
    "    recl[r] = {} \n",
    "    f1[r] = {}    \n",
    "    '''\n",
    "    for k in X.keys():\n",
    "        #mae[r][k] = {}\n",
    "        thresh[r][k] = {}\n",
    "        '''\n",
    "        acc[r][k] = {}\n",
    "        prec[r][k] = {}\n",
    "        recl[r][k] = {} \n",
    "        f1[r][k] = {}\n",
    "        '''\n",
    "        for k1 in X.keys():\n",
    "            if k1 != k: # train and test on other datasets\n",
    "                #pred = reg.fit(X[k], y[k]).predict(X[k1])\n",
    "                #mae[r][k][k1] = mean_absolute_error(y[k1], pred)\n",
    "                thresh[r][k][k1] = optimize_thresh(reg, X[k], y[k], X[k1], y[k1], t1_range, 10)\n",
    "                #y_label_true = to_label(y[k1], thresh_accuracy_mae[r][0])\n",
    "                #y_label_pred = to_label(pred, thresh_accuracy_mae[r][0])\n",
    "                #acc[r][k][k1] = accuracy_score(y_label_true, y_label_pred)\n",
    "                #prec[r][k][k1] = precision_score(y_label_true, y_label_pred, average = None) \n",
    "                #recl[r][k][k1] = recall_score(y_label_true, y_label_pred, average = None) \n",
    "                #f1[r][k][k1] = f1_score(y_label_true, y_label_pred, average = None)  \n",
    "            else:    # train and test on itself\n",
    "                X_tr, X_te, y_tr, y_te = train_test_split(X[k], y[k], test_size = 0.25, random_state = 1)\n",
    "                thresh[r][k][k] = optimize_thresh(reg, X_tr, y_tr, X_te, y_te, t1_range, 10)\n",
    "                #pred = reg.fit(X_tr, y_tr).predict(X_te)\n",
    "                #mae[r][k][k1] = mean_absolute_error(y_te, pred)\n",
    "                #y_label_true = to_label(y_te, thresh_accuracy_mae[r][0])\n",
    "                #y_label_pred = to_label(pred, thresh_accuracy_mae[r][0])\n",
    "                #acc[r][k][k] = accuracy_score(y_label_true, y_label_pred)\n",
    "                #prec[r][k][k] = precision_score(y_label_true, y_label_pred, average = None) \n",
    "                #recl[r][k][k] = recall_score(y_label_true, y_label_pred, average = None) \n",
    "                #f1[r][k][k] = f1_score(y_label_true, y_label_pred, average = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def print_results(dic, title):\n",
    "    print('#################################')\n",
    "    print('{} results:'.format(title))\n",
    "    for k, v in dic.items():\n",
    "        print(k)\n",
    "        for k1, v1 in v.items():\n",
    "            print(\"training set: {}\".format(k1))\n",
    "            for k2, v2 in v1.items():\n",
    "                print(\"optimal thresholds on {}: {}, {}\".format(k2, np.around(v2[0][0], decimals = 3), np.around(v2[0][1], decimals = 3)))\n",
    "                print(\"optimal accuracy on {}: {}\".format(k2, np.around(v2[1], decimals = 3)))\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = {}\n",
    "prec = {}\n",
    "recl = {}\n",
    "f1 = {}\n",
    "for r, reg in best_regressors_mae.items():\n",
    "    acc[r] = {}\n",
    "    prec[r] = {}\n",
    "    recl[r] = {} \n",
    "    f1[r] = {}    \n",
    "    for k in X.keys():\n",
    "        acc[r][k] = {}\n",
    "        prec[r][k] = {}\n",
    "        recl[r][k] = {} \n",
    "        f1[r][k] = {}\n",
    "        for k1 in X.keys():\n",
    "            if k1 != k: # train and test on other datasets\n",
    "                pred = reg.fit(X[k], y[k]).predict(X[k1])\n",
    "                y_label_true = to_label(y[k1], thresh_accuracy_mse[r][0])\n",
    "                y_label_pred = to_label(pred, thresh_accuracy_mse[r][0])\n",
    "                acc[r][k][k1] = accuracy_score(y_label_true, y_label_pred)\n",
    "                prec[r][k][k1] = precision_score(y_label_true, y_label_pred, average = None) \n",
    "                recl[r][k][k1] = recall_score(y_label_true, y_label_pred, average = None) \n",
    "                f1[r][k][k1] = f1_score(y_label_true, y_label_pred, average = None)  \n",
    "            else:    # train and test on itself\n",
    "                X_tr, X_te, y_tr, y_te = train_test_split(X[k], y[k], test_size = 0.25, random_state = 1)\n",
    "                pred = reg.fit(X_tr, y_tr).predict(X_te)\n",
    "                y_label_true = to_label(y_te, thresh_accuracy_mse[r][0])\n",
    "                y_label_pred = to_label(pred, thresh_accuracy_mse[r][0])\n",
    "                acc[r][k][k] = accuracy_score(y_label_true, y_label_pred)\n",
    "                prec[r][k][k] = precision_score(y_label_true, y_label_pred, average = None) \n",
    "                recl[r][k][k] = recall_score(y_label_true, y_label_pred, average = None) \n",
    "                f1[r][k][k] = f1_score(y_label_true, y_label_pred, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_results(dic, title):\n",
    "    print('#################################')\n",
    "    print('{} results:'.format(title))\n",
    "    for k, v in dic.items():\n",
    "        print(k)\n",
    "        for k1, v1 in v.items():\n",
    "            print(\"training set: {}\".format(k1))\n",
    "            for k2, v2 in v1.items():\n",
    "                print(\"{} on {}: {}\".format(title, k2, np.around(v2, decimals = 3)))\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################\n",
      "accuracy results:\n",
      "AdaBoost\n",
      "training set: s2\n",
      "accuracy on s2: 0.88\n",
      "accuracy on s6: 0.81\n",
      "accuracy on px: 0.71\n",
      "training set: s6\n",
      "accuracy on s2: 0.86\n",
      "accuracy on s6: 0.88\n",
      "accuracy on px: 0.69\n",
      "training set: px\n",
      "accuracy on s2: 0.79\n",
      "accuracy on s6: 0.67\n",
      "accuracy on px: 0.84\n",
      "\n",
      "MLP\n",
      "training set: s2\n",
      "accuracy on s2: 0.72\n",
      "accuracy on s6: 0.76\n",
      "accuracy on px: 0.8\n",
      "training set: s6\n",
      "accuracy on s2: 0.8\n",
      "accuracy on s6: 0.84\n",
      "accuracy on px: 0.79\n",
      "training set: px\n",
      "accuracy on s2: 0.78\n",
      "accuracy on s6: 0.7\n",
      "accuracy on px: 0.84\n",
      "\n",
      "Nearest Neighbors\n",
      "training set: s2\n",
      "accuracy on s2: 0.76\n",
      "accuracy on s6: 0.76\n",
      "accuracy on px: 0.79\n",
      "training set: s6\n",
      "accuracy on s2: 0.81\n",
      "accuracy on s6: 0.64\n",
      "accuracy on px: 0.82\n",
      "training set: px\n",
      "accuracy on s2: 0.81\n",
      "accuracy on s6: 0.73\n",
      "accuracy on px: 0.84\n",
      "\n",
      "Random Forest\n",
      "training set: s2\n",
      "accuracy on s2: 0.76\n",
      "accuracy on s6: 0.81\n",
      "accuracy on px: 0.74\n",
      "training set: s6\n",
      "accuracy on s2: 0.84\n",
      "accuracy on s6: 0.88\n",
      "accuracy on px: 0.69\n",
      "training set: px\n",
      "accuracy on s2: 0.79\n",
      "accuracy on s6: 0.73\n",
      "accuracy on px: 0.88\n",
      "\n",
      "SVM\n",
      "training set: s2\n",
      "accuracy on s2: 0.76\n",
      "accuracy on s6: 0.84\n",
      "accuracy on px: 0.79\n",
      "training set: s6\n",
      "accuracy on s2: 0.88\n",
      "accuracy on s6: 0.76\n",
      "accuracy on px: 0.74\n",
      "training set: px\n",
      "accuracy on s2: 0.85\n",
      "accuracy on s6: 0.76\n",
      "accuracy on px: 0.84\n",
      "\n",
      "\n",
      "#################################\n",
      "precision results:\n",
      "AdaBoost\n",
      "training set: s2\n",
      "precision on s2: [ 1.   1.   0.5]\n",
      "precision on s6: [ 0.905  0.667  0.895]\n",
      "precision on px: [ 0.643  0.617  0.96 ]\n",
      "training set: s6\n",
      "precision on s2: [ 1.     0.757  0.833]\n",
      "precision on s6: [ 1.     0.8    0.833]\n",
      "precision on px: [ 0.548  0.639  0.879]\n",
      "training set: px\n",
      "precision on s2: [ 1.     0.643  0.818]\n",
      "precision on s6: [ 1.     0.489  0.719]\n",
      "precision on px: [ 1.   0.8  0.8]\n",
      "\n",
      "MLP\n",
      "training set: s2\n",
      "precision on s2: [ 1.     0.8    0.455]\n",
      "precision on s6: [ 0.925  0.556  0.69 ]\n",
      "precision on px: [ 0.9    0.625  0.875]\n",
      "training set: s6\n",
      "precision on s2: [ 1.     0.727  0.696]\n",
      "precision on s6: [ 1.     1.     0.667]\n",
      "precision on px: [ 0.81   0.613  0.896]\n",
      "training set: px\n",
      "precision on s2: [ 1.     0.579  0.741]\n",
      "precision on s6: [ 0.935  0.423  0.698]\n",
      "precision on px: [ 1.     0.6    0.875]\n",
      "\n",
      "Nearest Neighbors\n",
      "training set: s2\n",
      "precision on s2: [ 1.     0.     0.688]\n",
      "precision on s6: [ 1.     0.143  0.8  ]\n",
      "precision on px: [ 0.944  0.2    0.833]\n",
      "training set: s6\n",
      "precision on s2: [ 1.     0.     0.857]\n",
      "precision on s6: [ 1.     0.286  0.75 ]\n",
      "precision on px: [ 0.833  0.333  0.857]\n",
      "training set: px\n",
      "precision on s2: [ 1.     0.     0.829]\n",
      "precision on s6: [ 1.     0.     0.718]\n",
      "precision on px: [ 1.     0.     0.895]\n",
      "\n",
      "Random Forest\n",
      "training set: s2\n",
      "precision on s2: [ 1.     1.     0.333]\n",
      "precision on s6: [ 0.905  0.72   0.758]\n",
      "precision on px: [ 0.643  0.71   0.829]\n",
      "training set: s6\n",
      "precision on s2: [ 0.971  0.87   0.721]\n",
      "precision on s6: [ 1.   1.   0.7]\n",
      "precision on px: [ 0.567  0.645  0.821]\n",
      "training set: px\n",
      "precision on s2: [ 1.     0.676  0.744]\n",
      "precision on s6: [ 1.     0.556  0.625]\n",
      "precision on px: [ 1.     0.833  0.857]\n",
      "\n",
      "SVM\n",
      "training set: s2\n",
      "precision on s2: [ 1.     0.     0.733]\n",
      "precision on s6: [ 1.     0.231  0.887]\n",
      "precision on px: [ 0.9    0.3    0.917]\n",
      "training set: s6\n",
      "precision on s2: [ 1.     0.     0.862]\n",
      "precision on s6: [ 1.     0.333  0.857]\n",
      "precision on px: [ 0.864  0.15   0.897]\n",
      "training set: px\n",
      "precision on s2: [ 1.     0.     0.866]\n",
      "precision on s6: [ 1.     0.     0.831]\n",
      "precision on px: [ 1.     0.25   0.944]\n",
      "\n",
      "\n",
      "#################################\n",
      "recall results:\n",
      "AdaBoost\n",
      "training set: s2\n",
      "recall on s2: [ 1.    0.75  1.  ]\n",
      "recall on s6: [ 0.95   0.812  0.607]\n",
      "recall on px: [ 0.72   0.763  0.649]\n",
      "training set: s6\n",
      "recall on s2: [ 1.     0.848  0.735]\n",
      "recall on s6: [ 1.     0.889  0.714]\n",
      "recall on px: [ 0.68   0.605  0.784]\n",
      "training set: px\n",
      "recall on s2: [ 0.758  0.818  0.794]\n",
      "recall on s6: [ 0.525  0.719  0.821]\n",
      "recall on px: [ 0.833  0.571  1.   ]\n",
      "\n",
      "MLP\n",
      "training set: s2\n",
      "recall on s2: [ 0.9  0.4  1. ]\n",
      "recall on s6: [ 0.925  0.385  0.853]\n",
      "recall on px: [ 0.72   0.769  0.857]\n",
      "training set: s6\n",
      "recall on s2: [ 1.     0.32   0.929]\n",
      "recall on s6: [ 1.   0.5  1. ]\n",
      "recall on px: [ 0.68   0.731  0.878]\n",
      "training set: px\n",
      "recall on s2: [ 0.818  0.44   0.952]\n",
      "recall on s6: [ 0.725  0.423  0.882]\n",
      "recall on px: [ 0.667  0.6    1.   ]\n",
      "\n",
      "Nearest Neighbors\n",
      "training set: s2\n",
      "recall on s2: [ 0.8  0.   1. ]\n",
      "recall on s6: [ 0.65   0.222  0.941]\n",
      "recall on px: [ 0.68   0.182  0.938]\n",
      "training set: s6\n",
      "recall on s2: [ 0.818  0.     0.931]\n",
      "recall on s6: [ 0.222  0.5    1.   ]\n",
      "recall on px: [ 0.8    0.182  0.938]\n",
      "training set: px\n",
      "recall on s2: [ 0.697  0.     1.   ]\n",
      "recall on s6: [ 0.55  0.    1.  ]\n",
      "recall on px: [ 0.667  0.     1.   ]\n",
      "\n",
      "Random Forest\n",
      "training set: s2\n",
      "recall on s2: [ 1.   0.5  1. ]\n",
      "recall on s6: [ 0.95   0.6    0.833]\n",
      "recall on px: [ 0.72   0.611  0.872]\n",
      "training set: s6\n",
      "recall on s2: [ 1.     0.606  0.912]\n",
      "recall on s6: [ 1.     0.667  1.   ]\n",
      "recall on px: [ 0.68   0.556  0.821]\n",
      "training set: px\n",
      "recall on s2: [ 0.818  0.697  0.853]\n",
      "recall on s6: [ 0.825  0.5    0.833]\n",
      "recall on px: [ 0.833  0.714  1.   ]\n",
      "\n",
      "SVM\n",
      "training set: s2\n",
      "recall on s2: [ 0.8  0.   1. ]\n",
      "recall on s6: [ 0.85   0.333  0.922]\n",
      "recall on px: [ 0.72   0.545  0.859]\n",
      "training set: s6\n",
      "recall on s2: [ 0.97   0.     0.966]\n",
      "recall on s6: [ 0.556  0.5    1.   ]\n",
      "recall on px: [ 0.76   0.273  0.812]\n",
      "training set: px\n",
      "recall on s2: [ 0.818  0.     1.   ]\n",
      "recall on s6: [ 0.675  0.     0.961]\n",
      "recall on px: [ 0.5  0.5  1. ]\n",
      "\n",
      "\n",
      "#################################\n",
      "f1_score results:\n",
      "AdaBoost\n",
      "training set: s2\n",
      "f1_score on s2: [ 1.     0.857  0.667]\n",
      "f1_score on s6: [ 0.927  0.732  0.723]\n",
      "f1_score on px: [ 0.679  0.682  0.774]\n",
      "training set: s6\n",
      "f1_score on s2: [ 1.     0.8    0.781]\n",
      "f1_score on s6: [ 1.     0.842  0.769]\n",
      "f1_score on px: [ 0.607  0.622  0.829]\n",
      "training set: px\n",
      "f1_score on s2: [ 0.862  0.72   0.806]\n",
      "f1_score on s6: [ 0.689  0.582  0.767]\n",
      "f1_score on px: [ 0.909  0.667  0.889]\n",
      "\n",
      "MLP\n",
      "training set: s2\n",
      "f1_score on s2: [ 0.947  0.533  0.625]\n",
      "f1_score on s6: [ 0.925  0.455  0.763]\n",
      "f1_score on px: [ 0.8    0.69   0.866]\n",
      "training set: s6\n",
      "f1_score on s2: [ 1.     0.444  0.796]\n",
      "f1_score on s6: [ 1.     0.667  0.8  ]\n",
      "f1_score on px: [ 0.739  0.667  0.887]\n",
      "training set: px\n",
      "f1_score on s2: [ 0.9    0.5    0.833]\n",
      "f1_score on s6: [ 0.817  0.423  0.779]\n",
      "f1_score on px: [ 0.8    0.6    0.933]\n",
      "\n",
      "Nearest Neighbors\n",
      "training set: s2\n",
      "f1_score on s2: [ 0.889  0.     0.815]\n",
      "f1_score on s6: [ 0.788  0.174  0.865]\n",
      "f1_score on px: [ 0.791  0.19   0.882]\n",
      "training set: s6\n",
      "f1_score on s2: [ 0.9    0.     0.893]\n",
      "f1_score on s6: [ 0.364  0.364  0.857]\n",
      "f1_score on px: [ 0.816  0.235  0.896]\n",
      "training set: px\n",
      "f1_score on s2: [ 0.821  0.     0.906]\n",
      "f1_score on s6: [ 0.71   0.     0.836]\n",
      "f1_score on px: [ 0.8    0.     0.944]\n",
      "\n",
      "Random Forest\n",
      "training set: s2\n",
      "f1_score on s2: [ 1.     0.667  0.5  ]\n",
      "f1_score on s6: [ 0.927  0.655  0.794]\n",
      "f1_score on px: [ 0.679  0.657  0.85 ]\n",
      "training set: s6\n",
      "f1_score on s2: [ 0.985  0.714  0.805]\n",
      "f1_score on s6: [ 1.     0.8    0.824]\n",
      "f1_score on px: [ 0.618  0.597  0.821]\n",
      "training set: px\n",
      "f1_score on s2: [ 0.9    0.687  0.795]\n",
      "f1_score on s6: [ 0.904  0.526  0.714]\n",
      "f1_score on px: [ 0.909  0.769  0.923]\n",
      "\n",
      "SVM\n",
      "training set: s2\n",
      "f1_score on s2: [ 0.889  0.     0.846]\n",
      "f1_score on s6: [ 0.919  0.273  0.904]\n",
      "f1_score on px: [ 0.8    0.387  0.887]\n",
      "training set: s6\n",
      "f1_score on s2: [ 0.985  0.     0.911]\n",
      "f1_score on s6: [ 0.714  0.4    0.923]\n",
      "f1_score on px: [ 0.809  0.194  0.852]\n",
      "training set: px\n",
      "f1_score on s2: [ 0.9    0.     0.928]\n",
      "f1_score on s6: [ 0.806  0.     0.891]\n",
      "f1_score on px: [ 0.667  0.333  0.971]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_results(acc, 'accuracy')\n",
    "print_results(prec, 'precision')\n",
    "print_results(recl, 'recall')\n",
    "print_results(f1, 'f1_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def make_meshgrid(x, y, h=.02):\n",
    "    x_min, x_max = x.min() - 1, x.max() + 1\n",
    "    y_min, y_max = y.min() - 1, y.max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "\n",
    "def plot_contours(reg_name, xx, yy, **params):\n",
    "    Z = best_regressors_mae[reg_name].predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = to_label(Z, thresh_accuracy_mae[reg_name][0])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = plt.contourf(xx, yy, Z, **params)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "colors = ['red', 'green', 'blue']\n",
    "cmap = mpl.colors.ListedColormap(colors)\n",
    "rg = np.arange(0, 1.01, 0.01)\n",
    "x1, x2, lb = np.array(df_reg['BitRate']), np.array(df_reg['FreezeRatio']), np.array(df_reg['Quality'])\n",
    "xx1, xx2 = make_meshgrid(rg, rg)\n",
    "for reg, name in zip(list(best_regressors_mae.values()), list(best_regressors_mae.keys())):\n",
    "    plot_contours(name, xx1, xx2, cmap=cmap, alpha=0.8)\n",
    "    plt.scatter(x1, x2, c = lb, cmap=cmap, s=20, edgecolors='k')\n",
    "    plt.xlim(rg.min(), rg.max())\n",
    "    plt.ylim(rg.min(), rg.max())\n",
    "    plt.xlabel('Bit Rate')\n",
    "    plt.ylabel('Freeze Ratio')\n",
    "    plt.xticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.title(name)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
