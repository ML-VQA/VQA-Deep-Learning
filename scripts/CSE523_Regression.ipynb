{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "from decimal import Decimal\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier as ovr\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, auc, precision_score, recall_score, f1_score \n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dr = '~/Projects/video-qoe-labeling/new-data/Skype/'\n",
    "dtype = {'BitRate': np.float64, 'FreezeRatio': np.float64, 'Freezes': np.int32, 'Freezelength': np.float64, 'Quality': np.float64}\n",
    "df_reg = pd.read_table(dr + 'all-data.txt', delim_whitespace=True, dtype = dtype)\n",
    "df_reg['BitRate'] /= 100  # transforming BitRate to percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get (X, y) and set fold\n",
    "features = ['BitRate', 'FreezeRatio', 'Freezes', 'Freezelength']\n",
    "X, y = np.array(df_reg[features]), np.array(df_reg['Quality'])\n",
    "mse = {}\n",
    "mae = {}\n",
    "fold = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regressors = {'Random Forest': RandomForestRegressor(random_state = 1), \n",
    "               'Nearest Neighbors': KNeighborsRegressor(),\n",
    "               'SVM': SVR(),\n",
    "               'MLP': MLPRegressor(random_state = 1, max_iter = 10000),\n",
    "               'AdaBoost': AdaBoostRegressor(random_state = 1)\n",
    "              }\n",
    "\n",
    "params = {'Random Forest': {'n_estimators': range(1, 21), 'criterion': ('mse', 'mae')},\n",
    "          'Nearest Neighbors': {'n_neighbors':range(1, 11)},\n",
    "          'SVM': {'kernel':('poly', 'rbf', 'sigmoid'), 'C':[0.1, 1, 10]},\n",
    "          'MLP': {'hidden_layer_sizes': [(10,), (20,), (40,), (80,), (10,10), (20, 20), (40, 40), (80, 80)], \n",
    "                  'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "                  'activation': ('logistic', 'tanh', 'relu'), \n",
    "                  'solver': ('lbfgs', 'sgd', 'adam')},\n",
    "          'AdaBoost': {'n_estimators': [10, 20, 40, 80], 'learning_rate': [0.01, 0.1, 1, 10]}\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# function for obtaining best estimator using grid search\n",
    "def grid_search_reg(estimator, params, scoring):\n",
    "    reg = GridSearchCV(estimator, params, scoring = scoring)\n",
    "    reg.fit(X, y)\n",
    "    return (reg.best_estimator_, reg.best_score_)\n",
    "\n",
    "# function for performing k-fold cross validation on the regressors\n",
    "def k_Fold_CV_reg(estimator, n):\n",
    "    mse = []\n",
    "    kf = KFold(n_splits = n)\n",
    "    for train, test in kf.split(X):\n",
    "        pred = estimator.fit(X[train], y[train]).predict(X[test])\n",
    "        mse.append(mean_squared_error(y[test], pred))\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best_regressors_mse = {}\n",
    "best_regressors_mae = {}\n",
    "for k in regressors:\n",
    "    best_regressors_mse[k], _ = grid_search_reg(regressors[k], params[k], 'neg_mean_squared_error')\n",
    "    best_regressors_mae[k], _ = grid_search_reg(regressors[k], params[k], 'neg_mean_absolute_error')\n",
    "    mse[k] = k_Fold_CV_reg(best_regressors_mse[k], fold)\n",
    "    mae[k] = k_Fold_CV_reg(best_regressors_mae[k], fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for k, v in mse.items():\n",
    "    print(k)\n",
    "    rmse = np.sqrt(v)\n",
    "    print(\"{}_fold RMSE: \".format(fold), np.around(rmse, decimals = 3))\n",
    "    print(\"Average RMSE: {0:0.3f}\".format(np.mean(rmse)))\n",
    "    print(\"#################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for k, v in mae.items():\n",
    "    print(k)\n",
    "    print(\"{}_fold MAE: \".format(fold), np.around(v, decimals = 3))\n",
    "    print(\"Average MAE: {0:0.3f}\".format(np.mean(v)))\n",
    "    print(\"#################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_regressors_mse = {'AdaBoost': AdaBoostRegressor(base_estimator=None, learning_rate=0.1, loss='linear',\n",
    "          n_estimators=10, random_state=1),\n",
    " 'MLP': MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "        hidden_layer_sizes=(10,), learning_rate='constant',\n",
    "        learning_rate_init=0.001, max_iter=10000, momentum=0.9,\n",
    "        nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
    "        solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
    "        warm_start=False),\n",
    " 'Nearest Neighbors': KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
    "           weights='uniform'),\n",
    " 'Random Forest': RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=None,\n",
    "            max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
    "            oob_score=False, random_state=1, verbose=0, warm_start=False),\n",
    " 'SVM': SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
    "   kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)}\n",
    "\n",
    "best_regressors_mae = {'AdaBoost': AdaBoostRegressor(base_estimator=None, learning_rate=0.01, loss='linear',\n",
    "          n_estimators=10, random_state=1),\n",
    " 'MLP': MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "        hidden_layer_sizes=(10,), learning_rate='constant',\n",
    "        learning_rate_init=0.001, max_iter=10000, momentum=0.9,\n",
    "        nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
    "        solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
    "        warm_start=False),\n",
    " 'Nearest Neighbors': KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
    "           weights='uniform'),\n",
    " 'Random Forest': RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=None,\n",
    "            max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
    "            oob_score=False, random_state=1, verbose=0, warm_start=False),\n",
    " 'SVM': SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
    "   kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_splits = 20\n",
    "X_train, X_test, y_train, y_test = [], [], [], []\n",
    "for i in range(num_splits): \n",
    "    split = train_test_split(X, y, test_size = 0.25)\n",
    "    X_train.append(split[0])\n",
    "    X_test.append(split[1])\n",
    "    y_train.append(split[2])\n",
    "    y_test.append(split[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mserr = {}\n",
    "for k, v in best_regressors_mse.items():\n",
    "    pred = v.fit(X_train, y_train).predict(X_test)\n",
    "    mserr[k] = mean_squared_error(y_test, pred)\n",
    "\n",
    "maerr = {}\n",
    "for k, v in best_regressors_mae.items():\n",
    "    pred = v.fit(X_train, y_train).predict(X_test)\n",
    "    maerr[k] = mean_absolute_error(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for k, v in mserr.items():\n",
    "    print(k)\n",
    "    print(\"MSE: \", np.around(v, decimals = 3))\n",
    "    print(\"#################################\")\n",
    "    \n",
    "for k, v in maerr.items():\n",
    "    print(k)\n",
    "    print(\"MAE: \", np.around(v, decimals = 3))\n",
    "    print(\"#################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_label(score, thresh):\n",
    "    label = []\n",
    "    for s in np.nditer(score):\n",
    "        if s < thresh[0]:\n",
    "            label.append(0)\n",
    "        elif s < thresh[1]:\n",
    "            label.append(1)\n",
    "        else:\n",
    "            label.append(2)\n",
    "    return np.array(label, dtype = int) \n",
    "\n",
    "def optimize_thresh(regressor, X_train, y_train, X_test, y_test, t1_range, top_num):\n",
    "    i = 0\n",
    "    thresh_accuracy = []\n",
    "    model = regressor.fit(X_train, y_train)\n",
    "    pred = model.predict(X_train) \n",
    "    # find optimal thresholds from training set\n",
    "    for t1 in t1_range:\n",
    "        for t2 in np.arange(t1+1, 4.01, 0.05):\n",
    "            y_label_true = to_label(y_train, (t1, t2))\n",
    "            y_label_pred = to_label(pred, (t1, t2))\n",
    "            thresh_accuracy.append(((t1, t2), accuracy_score(y_label_true, y_label_pred)))\n",
    "    thresh_accuracy.sort(key = lambda x:x[1], reverse = True)\n",
    "    # determine average thresholds\n",
    "    thresh = [x[0] for x in thresh_accuracy[:top_num]]\n",
    "    avg_thresh = np.average(thresh, axis = 0) \n",
    "    # find accuracy on test set\n",
    "    pred = model.predict(X_test)\n",
    "    y_label_true = to_label(y_test, avg_thresh)\n",
    "    y_label_pred = to_label(pred, avg_thresh)   \n",
    "    return avg_thresh, accuracy_score(y_label_true, y_label_pred),precision_score(y_label_true, y_label_pred, average = None),recall_score(y_label_true, y_label_pred, average = None), f1_score(y_label_true, y_label_pred, average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ysqyang/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "t1_range = np.arange(2, 3.01, 0.05)\n",
    "thresh_scores_mse = {}\n",
    "\n",
    "for k, reg in best_regressors_mse.items():\n",
    "    thresh_scores_mse[k] = [optimize_thresh(reg, X_train[i], y_train[i], X_test[i], y_test[i], t1_range, 1) for i in range(num_splits)]\n",
    "\n",
    "thresh_scores_mae = {}\n",
    "for k, reg in best_regressors_mae.items():\n",
    "    thresh_scores_mae[k] = [optimize_thresh(reg, X_train[i], y_train[i], X_test[i], y_test[i], t1_range, 1) for i in range(num_splits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regressors with minimized mean squared error\n",
      "AdaBoost\n",
      "Optimal thresholds: [[ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.05  3.85]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]]\n",
      "Accuracy: [ 0.893  0.867  0.867  0.853  0.827  0.92   0.893  0.813  0.827  0.893\n",
      "  0.853  0.8    0.827  0.92   0.853  0.893  0.84   0.827  0.853  0.84 ]\n",
      "Precision: [[ 1.     0.     0.857]\n",
      " [ 0.917  0.     0.86 ]\n",
      " [ 1.     0.     0.811]\n",
      " [ 0.846  0.     0.894]\n",
      " [ 0.923  0.     0.776]\n",
      " [ 1.     0.     0.944]\n",
      " [ 0.964  0.     0.851]\n",
      " [ 0.913  0.731  0.808]\n",
      " [ 1.     0.     0.75 ]\n",
      " [ 1.     0.5    0.86 ]\n",
      " [ 1.     0.     0.815]\n",
      " [ 0.92   0.     0.755]\n",
      " [ 0.96   0.     0.776]\n",
      " [ 0.964  0.     0.913]\n",
      " [ 0.9    1.     0.833]\n",
      " [ 0.962  0.     0.857]\n",
      " [ 0.962  0.     0.826]\n",
      " [ 0.875  0.     0.804]\n",
      " [ 0.931  0.     0.804]\n",
      " [ 0.909  0.     0.86 ]]\n",
      "Recall: [[ 0.926  0.     1.   ]\n",
      " [ 1.     0.     0.977]\n",
      " [ 0.917  0.     1.   ]\n",
      " [ 0.957  0.     0.933]\n",
      " [ 0.96   0.     1.   ]\n",
      " [ 0.947  0.     0.962]\n",
      " [ 1.     0.     1.   ]\n",
      " [ 0.955  0.76   0.75 ]\n",
      " [ 0.793  0.     1.   ]\n",
      " [ 0.958  0.143  0.977]\n",
      " [ 0.909  0.     0.978]\n",
      " [ 0.92   0.     0.974]\n",
      " [ 0.923  0.     0.974]\n",
      " [ 1.     0.     0.977]\n",
      " [ 0.9    0.111  0.978]\n",
      " [ 1.     0.     1.   ]\n",
      " [ 0.926  0.     0.927]\n",
      " [ 1.     0.     1.   ]\n",
      " [ 0.964  0.     0.949]\n",
      " [ 0.909  0.     0.956]]\n",
      "F1: [[ 0.962  0.     0.923]\n",
      " [ 0.957  0.     0.915]\n",
      " [ 0.957  0.     0.896]\n",
      " [ 0.898  0.     0.913]\n",
      " [ 0.941  0.     0.874]\n",
      " [ 0.973  0.     0.953]\n",
      " [ 0.982  0.     0.92 ]\n",
      " [ 0.933  0.745  0.778]\n",
      " [ 0.885  0.     0.857]\n",
      " [ 0.979  0.222  0.915]\n",
      " [ 0.952  0.     0.889]\n",
      " [ 0.92   0.     0.851]\n",
      " [ 0.941  0.     0.864]\n",
      " [ 0.982  0.     0.944]\n",
      " [ 0.9    0.2    0.9  ]\n",
      " [ 0.98   0.     0.923]\n",
      " [ 0.943  0.     0.874]\n",
      " [ 0.933  0.     0.891]\n",
      " [ 0.947  0.     0.871]\n",
      " [ 0.909  0.     0.905]]\n",
      "#################################\n",
      "MLP\n",
      "Optimal thresholds: [[ 2.15  3.75]\n",
      " [ 2.2   4.  ]\n",
      " [ 2.4   3.45]\n",
      " [ 2.35  3.8 ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.2   3.5 ]\n",
      " [ 2.25  3.5 ]\n",
      " [ 2.3   4.  ]\n",
      " [ 2.25  3.8 ]\n",
      " [ 2.3   3.55]\n",
      " [ 2.35  3.45]\n",
      " [ 2.35  3.4 ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.2   3.75]\n",
      " [ 2.4   3.55]\n",
      " [ 2.3   3.45]\n",
      " [ 2.    3.  ]\n",
      " [ 2.35  3.5 ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]]\n",
      "Accuracy: [ 0.8    0.773  0.813  0.813  0.84   0.867  0.84   0.773  0.8    0.773\n",
      "  0.76   0.773  0.8    0.787  0.827  0.773  0.84   0.76   0.813  0.773]\n",
      "Precision: [[ 1.     0.741  0.667]\n",
      " [ 0.952  0.667  0.778]\n",
      " [ 1.     0.706  0.763]\n",
      " [ 0.885  0.722  0.806]\n",
      " [ 0.957  0.6    0.809]\n",
      " [ 1.     0.923  0.791]\n",
      " [ 0.963  0.8    0.758]\n",
      " [ 0.87   0.636  0.895]\n",
      " [ 0.96   0.68   0.76 ]\n",
      " [ 1.     0.714  0.658]\n",
      " [ 1.     0.769  0.651]\n",
      " [ 0.923  0.786  0.657]\n",
      " [ 0.958  0.143  0.818]\n",
      " [ 0.929  0.571  0.808]\n",
      " [ 0.944  0.75   0.811]\n",
      " [ 0.926  0.714  0.676]\n",
      " [ 1.     0.     0.822]\n",
      " [ 0.909  0.833  0.659]\n",
      " [ 1.     0.273  0.854]\n",
      " [ 0.85   0.125  0.851]]\n",
      "Recall: [[ 0.889  0.714  0.8  ]\n",
      " [ 0.909  0.828  0.583]\n",
      " [ 0.833  0.6    0.935]\n",
      " [ 1.     0.591  0.833]\n",
      " [ 0.88   0.25   1.   ]\n",
      " [ 1.     0.571  0.971]\n",
      " [ 0.963  0.571  0.926]\n",
      " [ 0.909  0.808  0.63 ]\n",
      " [ 0.828  0.739  0.826]\n",
      " [ 0.958  0.435  0.893]\n",
      " [ 0.864  0.435  0.933]\n",
      " [ 0.96   0.44   0.92 ]\n",
      " [ 0.885  0.1    0.923]\n",
      " [ 0.963  0.632  0.724]\n",
      " [ 0.85   0.652  0.938]\n",
      " [ 1.     0.435  0.852]\n",
      " [ 0.963  0.     0.902]\n",
      " [ 0.952  0.385  0.964]\n",
      " [ 0.821  0.375  0.897]\n",
      " [ 0.773  0.125  0.889]]\n",
      "F1: [[ 0.941  0.727  0.727]\n",
      " [ 0.93   0.738  0.667]\n",
      " [ 0.909  0.649  0.841]\n",
      " [ 0.939  0.65   0.82 ]\n",
      " [ 0.917  0.353  0.894]\n",
      " [ 1.     0.706  0.872]\n",
      " [ 0.963  0.667  0.833]\n",
      " [ 0.889  0.712  0.739]\n",
      " [ 0.889  0.708  0.792]\n",
      " [ 0.979  0.541  0.758]\n",
      " [ 0.927  0.556  0.767]\n",
      " [ 0.941  0.564  0.767]\n",
      " [ 0.92   0.118  0.867]\n",
      " [ 0.945  0.6    0.764]\n",
      " [ 0.895  0.698  0.87 ]\n",
      " [ 0.962  0.541  0.754]\n",
      " [ 0.981  0.     0.86 ]\n",
      " [ 0.93   0.526  0.783]\n",
      " [ 0.902  0.316  0.875]\n",
      " [ 0.81   0.125  0.87 ]]\n",
      "#################################\n",
      "Nearest Neighbors\n",
      "Optimal thresholds: [[ 2.    3.  ]\n",
      " [ 2.6   4.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.6   3.9 ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.65  4.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.5   3.55]\n",
      " [ 2.2   3.35]\n",
      " [ 2.05  3.05]\n",
      " [ 2.    3.  ]\n",
      " [ 2.4   3.8 ]\n",
      " [ 2.6   4.  ]\n",
      " [ 2.15  4.  ]\n",
      " [ 2.5   3.5 ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.6   3.9 ]\n",
      " [ 2.25  3.9 ]]\n",
      "Accuracy: [ 0.8    0.747  0.84   0.853  0.8    0.84   0.867  0.693  0.813  0.733\n",
      "  0.733  0.76   0.787  0.773  0.76   0.693  0.733  0.773  0.72   0.653]\n",
      "Precision: [[ 1.     0.125  0.833]\n",
      " [ 0.909  0.679  0.68 ]\n",
      " [ 1.     0.     0.824]\n",
      " [ 0.95   0.2    0.88 ]\n",
      " [ 1.     0.444  0.783]\n",
      " [ 0.95   0.81   0.794]\n",
      " [ 0.962  0.333  0.848]\n",
      " [ 0.9    0.553  0.765]\n",
      " [ 1.     0.167  0.809]\n",
      " [ 0.952  0.611  0.667]\n",
      " [ 1.     0.5    0.674]\n",
      " [ 0.92   0.25   0.762]\n",
      " [ 0.955  0.125  0.822]\n",
      " [ 0.958  0.545  0.793]\n",
      " [ 0.947  0.677  0.72 ]\n",
      " [ 0.952  0.579  0.625]\n",
      " [ 0.958  0.636  0.625]\n",
      " [ 0.944  0.167  0.784]\n",
      " [ 0.96   0.577  0.625]\n",
      " [ 0.944  0.562  0.56 ]]\n",
      "Recall: [[ 0.704  0.167  0.952]\n",
      " [ 0.909  0.655  0.708]\n",
      " [ 0.875  0.     0.977]\n",
      " [ 0.826  0.143  0.978]\n",
      " [ 0.8    0.333  0.947]\n",
      " [ 1.     0.68   0.871]\n",
      " [ 0.926  0.125  0.975]\n",
      " [ 0.818  0.808  0.481]\n",
      " [ 0.759  0.143  0.974]\n",
      " [ 0.833  0.478  0.857]\n",
      " [ 0.864  0.263  0.912]\n",
      " [ 0.92   0.154  0.865]\n",
      " [ 0.808  0.1    0.949]\n",
      " [ 0.852  0.632  0.793]\n",
      " [ 0.9    0.724  0.692]\n",
      " [ 0.8    0.759  0.476]\n",
      " [ 0.852  0.318  0.962]\n",
      " [ 0.81   0.077  0.976]\n",
      " [ 0.857  0.625  0.652]\n",
      " [ 0.773  0.6    0.609]]\n",
      "F1: [[ 0.826  0.143  0.889]\n",
      " [ 0.909  0.667  0.694]\n",
      " [ 0.933  0.     0.894]\n",
      " [ 0.884  0.167  0.926]\n",
      " [ 0.889  0.381  0.857]\n",
      " [ 0.974  0.739  0.831]\n",
      " [ 0.943  0.182  0.907]\n",
      " [ 0.857  0.656  0.591]\n",
      " [ 0.863  0.154  0.884]\n",
      " [ 0.889  0.537  0.75 ]\n",
      " [ 0.927  0.345  0.775]\n",
      " [ 0.92   0.19   0.81 ]\n",
      " [ 0.875  0.111  0.881]\n",
      " [ 0.902  0.585  0.793]\n",
      " [ 0.923  0.7    0.706]\n",
      " [ 0.87   0.657  0.541]\n",
      " [ 0.902  0.424  0.758]\n",
      " [ 0.872  0.105  0.87 ]\n",
      " [ 0.906  0.6    0.638]\n",
      " [ 0.85   0.581  0.583]]\n",
      "#################################\n",
      "Random Forest\n",
      "Optimal thresholds: [[ 2.45  3.85]\n",
      " [ 2.3   3.8 ]\n",
      " [ 2.1   4.  ]\n",
      " [ 2.25  3.8 ]\n",
      " [ 2.1   4.  ]\n",
      " [ 2.05  4.  ]\n",
      " [ 2.2   4.  ]\n",
      " [ 2.3   3.95]\n",
      " [ 2.15  4.  ]\n",
      " [ 2.3   3.8 ]\n",
      " [ 2.    3.75]\n",
      " [ 2.15  3.4 ]\n",
      " [ 2.05  4.  ]\n",
      " [ 2.5   3.75]\n",
      " [ 2.    3.95]\n",
      " [ 2.35  3.5 ]\n",
      " [ 2.1   3.8 ]\n",
      " [ 2.1   3.85]\n",
      " [ 2.1   4.  ]\n",
      " [ 2.25  3.85]]\n",
      "Accuracy: [ 0.867  0.84   0.84   0.8    0.853  0.867  0.907  0.84   0.867  0.813\n",
      "  0.84   0.84   0.853  0.813  0.88   0.787  0.907  0.84   0.827  0.813]\n",
      "Precision: [[ 0.963  0.828  0.789]\n",
      " [ 0.917  0.774  0.85 ]\n",
      " [ 1.     0.767  0.792]\n",
      " [ 0.88   0.684  0.806]\n",
      " [ 0.923  0.839  0.778]\n",
      " [ 1.     0.759  0.893]\n",
      " [ 0.963  0.88   0.87 ]\n",
      " [ 0.913  0.719  0.95 ]\n",
      " [ 1.     0.742  0.9  ]\n",
      " [ 1.     0.783  0.7  ]\n",
      " [ 1.     0.8    0.774]\n",
      " [ 0.96   0.842  0.742]\n",
      " [ 0.96   0.767  0.85 ]\n",
      " [ 0.963  0.6    0.87 ]\n",
      " [ 0.947  0.833  0.885]\n",
      " [ 0.926  0.7    0.714]\n",
      " [ 1.     0.913  0.821]\n",
      " [ 0.947  0.767  0.846]\n",
      " [ 0.963  0.71   0.824]\n",
      " [ 0.95   0.75   0.783]]\n",
      "Recall: [[ 0.963  0.857  0.75 ]\n",
      " [ 1.     0.828  0.708]\n",
      " [ 0.875  0.852  0.792]\n",
      " [ 0.957  0.591  0.833]\n",
      " [ 0.96   0.839  0.737]\n",
      " [ 0.947  0.88   0.806]\n",
      " [ 0.963  0.846  0.909]\n",
      " [ 0.955  0.885  0.704]\n",
      " [ 0.828  0.958  0.818]\n",
      " [ 0.917  0.692  0.84 ]\n",
      " [ 0.864  0.769  0.889]\n",
      " [ 0.96   0.64   0.92 ]\n",
      " [ 0.923  0.885  0.739]\n",
      " [ 0.963  0.789  0.69 ]\n",
      " [ 0.9    0.893  0.852]\n",
      " [ 1.     0.583  0.769]\n",
      " [ 0.889  0.84   1.   ]\n",
      " [ 0.857  0.821  0.846]\n",
      " [ 0.929  0.88   0.636]\n",
      " [ 0.864  0.8    0.783]]\n",
      "F1: [[ 0.963  0.842  0.769]\n",
      " [ 0.957  0.8    0.773]\n",
      " [ 0.933  0.807  0.792]\n",
      " [ 0.917  0.634  0.82 ]\n",
      " [ 0.941  0.839  0.757]\n",
      " [ 0.973  0.815  0.847]\n",
      " [ 0.963  0.863  0.889]\n",
      " [ 0.933  0.793  0.809]\n",
      " [ 0.906  0.836  0.857]\n",
      " [ 0.957  0.735  0.764]\n",
      " [ 0.927  0.784  0.828]\n",
      " [ 0.96   0.727  0.821]\n",
      " [ 0.941  0.821  0.791]\n",
      " [ 0.963  0.682  0.769]\n",
      " [ 0.923  0.862  0.868]\n",
      " [ 0.962  0.636  0.741]\n",
      " [ 0.941  0.875  0.902]\n",
      " [ 0.9    0.793  0.846]\n",
      " [ 0.945  0.786  0.718]\n",
      " [ 0.905  0.774  0.783]]\n",
      "#################################\n",
      "SVM\n",
      "Optimal thresholds: [[ 2.5   3.85]\n",
      " [ 2.5   4.  ]\n",
      " [ 2.05  3.05]\n",
      " [ 2.4   3.95]\n",
      " [ 2.    3.  ]\n",
      " [ 2.3   3.85]\n",
      " [ 2.35  3.95]\n",
      " [ 2.3   3.85]\n",
      " [ 2.    3.  ]\n",
      " [ 2.25  3.9 ]\n",
      " [ 2.35  4.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.25  3.95]\n",
      " [ 2.25  3.85]\n",
      " [ 2.05  3.05]\n",
      " [ 2.55  3.8 ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.4   3.5 ]\n",
      " [ 2.    3.  ]]\n",
      "Accuracy: [ 0.8    0.8    0.787  0.893  0.84   0.84   0.88   0.84   0.8    0.813\n",
      "  0.853  0.787  0.773  0.787  0.827  0.773  0.827  0.813  0.813  0.773]\n",
      "Precision: [[ 0.964  0.842  0.607]\n",
      " [ 0.88   0.792  0.731]\n",
      " [ 1.     0.2    0.755]\n",
      " [ 0.92   0.792  0.962]\n",
      " [ 0.957  0.556  0.837]\n",
      " [ 1.     0.842  0.757]\n",
      " [ 0.963  0.808  0.864]\n",
      " [ 0.952  0.769  0.821]\n",
      " [ 1.     0.182  0.86 ]\n",
      " [ 0.957  0.75   0.75 ]\n",
      " [ 1.     0.815  0.786]\n",
      " [ 0.96   0.25   0.786]\n",
      " [ 0.957  0.645  0.762]\n",
      " [ 0.963  0.56   0.826]\n",
      " [ 0.947  0.286  0.857]\n",
      " [ 0.833  0.739  0.727]\n",
      " [ 1.     0.143  0.844]\n",
      " [ 0.95   0.429  0.812]\n",
      " [ 1.     0.75   0.706]\n",
      " [ 0.944  0.091  0.87 ]]\n",
      "Recall: [[ 1.     0.571  0.85 ]\n",
      " [ 1.     0.655  0.792]\n",
      " [ 0.875  0.083  0.949]\n",
      " [ 1.     0.864  0.833]\n",
      " [ 0.88   0.417  0.947]\n",
      " [ 1.     0.64   0.903]\n",
      " [ 0.963  0.84   0.826]\n",
      " [ 0.909  0.8    0.821]\n",
      " [ 0.724  0.286  0.949]\n",
      " [ 0.917  0.692  0.84 ]\n",
      " [ 0.909  0.815  0.846]\n",
      " [ 0.96   0.167  0.868]\n",
      " [ 0.846  0.769  0.696]\n",
      " [ 0.963  0.737  0.655]\n",
      " [ 0.9    0.2    0.933]\n",
      " [ 1.     0.63   0.696]\n",
      " [ 0.852  0.143  0.927]\n",
      " [ 0.905  0.231  0.951]\n",
      " [ 0.893  0.571  0.923]\n",
      " [ 0.773  0.125  0.889]]\n",
      "F1: [[ 0.982  0.681  0.708]\n",
      " [ 0.936  0.717  0.76 ]\n",
      " [ 0.933  0.118  0.841]\n",
      " [ 0.958  0.826  0.893]\n",
      " [ 0.917  0.476  0.889]\n",
      " [ 1.     0.727  0.824]\n",
      " [ 0.963  0.824  0.844]\n",
      " [ 0.93   0.784  0.821]\n",
      " [ 0.84   0.222  0.902]\n",
      " [ 0.936  0.72   0.792]\n",
      " [ 0.952  0.815  0.815]\n",
      " [ 0.96   0.2    0.825]\n",
      " [ 0.898  0.702  0.727]\n",
      " [ 0.963  0.636  0.731]\n",
      " [ 0.923  0.235  0.894]\n",
      " [ 0.909  0.68   0.711]\n",
      " [ 0.92   0.143  0.884]\n",
      " [ 0.927  0.3    0.876]\n",
      " [ 0.943  0.649  0.8  ]\n",
      " [ 0.85   0.105  0.879]]\n",
      "#################################\n",
      "\n",
      "regressors with minimized mean absolute error\n",
      "AdaBoost\n",
      "Optimal thresholds: [[ 2.5   3.75]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.15  3.75]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    4.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.15  3.9 ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]]\n",
      "Accuracy: [ 0.853  0.867  0.867  0.787  0.84   0.92   0.893  0.893  0.813  0.853\n",
      "  0.88   0.813  0.813  0.773  0.853  0.893  0.84   0.827  0.853  0.787]\n",
      "Precision: [[ 0.962  0.781  0.824]\n",
      " [ 0.917  0.     0.86 ]\n",
      " [ 1.     0.     0.811]\n",
      " [ 0.815  0.636  0.885]\n",
      " [ 0.923  1.     0.792]\n",
      " [ 1.     0.     0.944]\n",
      " [ 0.964  0.     0.851]\n",
      " [ 0.913  0.     0.902]\n",
      " [ 1.     0.     0.745]\n",
      " [ 0.955  0.     0.811]\n",
      " [ 1.     0.812  0.875]\n",
      " [ 0.96   0.     0.755]\n",
      " [ 0.957  0.     0.78 ]\n",
      " [ 0.926  0.536  0.9  ]\n",
      " [ 0.95   0.333  0.846]\n",
      " [ 0.926  0.     0.875]\n",
      " [ 0.96   0.     0.83 ]\n",
      " [ 0.875  0.     0.804]\n",
      " [ 0.931  0.     0.804]\n",
      " [ 0.85   0.     0.808]]\n",
      "Recall: [[ 0.926  0.893  0.7  ]\n",
      " [ 1.     0.     0.977]\n",
      " [ 0.917  0.     1.   ]\n",
      " [ 0.957  0.636  0.767]\n",
      " [ 0.96   0.083  1.   ]\n",
      " [ 0.947  0.     0.962]\n",
      " [ 1.     0.     1.   ]\n",
      " [ 0.955  0.     0.979]\n",
      " [ 0.793  0.     0.974]\n",
      " [ 0.875  0.     0.977]\n",
      " [ 0.864  0.963  0.808]\n",
      " [ 0.96   0.     0.974]\n",
      " [ 0.846  0.     1.   ]\n",
      " [ 0.926  0.789  0.621]\n",
      " [ 0.95   0.111  0.957]\n",
      " [ 1.     0.     1.   ]\n",
      " [ 0.889  0.     0.951]\n",
      " [ 1.     0.     1.   ]\n",
      " [ 0.964  0.     0.949]\n",
      " [ 0.773  0.     0.933]]\n",
      "F1: [[ 0.943  0.833  0.757]\n",
      " [ 0.957  0.     0.915]\n",
      " [ 0.957  0.     0.896]\n",
      " [ 0.88   0.636  0.821]\n",
      " [ 0.941  0.154  0.884]\n",
      " [ 0.973  0.     0.953]\n",
      " [ 0.982  0.     0.92 ]\n",
      " [ 0.933  0.     0.939]\n",
      " [ 0.885  0.     0.844]\n",
      " [ 0.913  0.     0.887]\n",
      " [ 0.927  0.881  0.84 ]\n",
      " [ 0.96   0.     0.851]\n",
      " [ 0.898  0.     0.876]\n",
      " [ 0.926  0.638  0.735]\n",
      " [ 0.95   0.167  0.898]\n",
      " [ 0.962  0.     0.933]\n",
      " [ 0.923  0.     0.886]\n",
      " [ 0.933  0.     0.891]\n",
      " [ 0.947  0.     0.871]\n",
      " [ 0.81   0.     0.866]]\n",
      "#################################\n",
      "MLP\n",
      "Optimal thresholds: [[ 2.15  3.75]\n",
      " [ 2.2   4.  ]\n",
      " [ 2.4   3.45]\n",
      " [ 2.35  3.8 ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.2   3.5 ]\n",
      " [ 2.25  3.5 ]\n",
      " [ 2.3   4.  ]\n",
      " [ 2.25  3.8 ]\n",
      " [ 2.3   3.55]\n",
      " [ 2.35  3.45]\n",
      " [ 2.35  3.4 ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.2   3.75]\n",
      " [ 2.4   3.55]\n",
      " [ 2.3   3.45]\n",
      " [ 2.    3.  ]\n",
      " [ 2.35  3.5 ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]]\n",
      "Accuracy: [ 0.8    0.773  0.813  0.813  0.84   0.867  0.84   0.773  0.8    0.773\n",
      "  0.76   0.773  0.8    0.787  0.827  0.773  0.84   0.76   0.813  0.773]\n",
      "Precision: [[ 1.     0.741  0.667]\n",
      " [ 0.952  0.667  0.778]\n",
      " [ 1.     0.706  0.763]\n",
      " [ 0.885  0.722  0.806]\n",
      " [ 0.957  0.6    0.809]\n",
      " [ 1.     0.923  0.791]\n",
      " [ 0.963  0.8    0.758]\n",
      " [ 0.87   0.636  0.895]\n",
      " [ 0.96   0.68   0.76 ]\n",
      " [ 1.     0.714  0.658]\n",
      " [ 1.     0.769  0.651]\n",
      " [ 0.923  0.786  0.657]\n",
      " [ 0.958  0.143  0.818]\n",
      " [ 0.929  0.571  0.808]\n",
      " [ 0.944  0.75   0.811]\n",
      " [ 0.926  0.714  0.676]\n",
      " [ 1.     0.     0.822]\n",
      " [ 0.909  0.833  0.659]\n",
      " [ 1.     0.273  0.854]\n",
      " [ 0.85   0.125  0.851]]\n",
      "Recall: [[ 0.889  0.714  0.8  ]\n",
      " [ 0.909  0.828  0.583]\n",
      " [ 0.833  0.6    0.935]\n",
      " [ 1.     0.591  0.833]\n",
      " [ 0.88   0.25   1.   ]\n",
      " [ 1.     0.571  0.971]\n",
      " [ 0.963  0.571  0.926]\n",
      " [ 0.909  0.808  0.63 ]\n",
      " [ 0.828  0.739  0.826]\n",
      " [ 0.958  0.435  0.893]\n",
      " [ 0.864  0.435  0.933]\n",
      " [ 0.96   0.44   0.92 ]\n",
      " [ 0.885  0.1    0.923]\n",
      " [ 0.963  0.632  0.724]\n",
      " [ 0.85   0.652  0.938]\n",
      " [ 1.     0.435  0.852]\n",
      " [ 0.963  0.     0.902]\n",
      " [ 0.952  0.385  0.964]\n",
      " [ 0.821  0.375  0.897]\n",
      " [ 0.773  0.125  0.889]]\n",
      "F1: [[ 0.941  0.727  0.727]\n",
      " [ 0.93   0.738  0.667]\n",
      " [ 0.909  0.649  0.841]\n",
      " [ 0.939  0.65   0.82 ]\n",
      " [ 0.917  0.353  0.894]\n",
      " [ 1.     0.706  0.872]\n",
      " [ 0.963  0.667  0.833]\n",
      " [ 0.889  0.712  0.739]\n",
      " [ 0.889  0.708  0.792]\n",
      " [ 0.979  0.541  0.758]\n",
      " [ 0.927  0.556  0.767]\n",
      " [ 0.941  0.564  0.767]\n",
      " [ 0.92   0.118  0.867]\n",
      " [ 0.945  0.6    0.764]\n",
      " [ 0.895  0.698  0.87 ]\n",
      " [ 0.962  0.541  0.754]\n",
      " [ 0.981  0.     0.86 ]\n",
      " [ 0.93   0.526  0.783]\n",
      " [ 0.902  0.316  0.875]\n",
      " [ 0.81   0.125  0.87 ]]\n",
      "#################################\n",
      "Nearest Neighbors\n",
      "Optimal thresholds: [[ 2.    3.  ]\n",
      " [ 2.6   4.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.6   3.9 ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.65  4.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.5   3.55]\n",
      " [ 2.2   3.35]\n",
      " [ 2.05  3.05]\n",
      " [ 2.    3.  ]\n",
      " [ 2.4   3.8 ]\n",
      " [ 2.6   4.  ]\n",
      " [ 2.15  4.  ]\n",
      " [ 2.5   3.5 ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.6   3.9 ]\n",
      " [ 2.25  3.9 ]]\n",
      "Accuracy: [ 0.8    0.747  0.84   0.853  0.8    0.84   0.867  0.693  0.813  0.733\n",
      "  0.733  0.76   0.787  0.773  0.76   0.693  0.733  0.773  0.72   0.653]\n",
      "Precision: [[ 1.     0.125  0.833]\n",
      " [ 0.909  0.679  0.68 ]\n",
      " [ 1.     0.     0.824]\n",
      " [ 0.95   0.2    0.88 ]\n",
      " [ 1.     0.444  0.783]\n",
      " [ 0.95   0.81   0.794]\n",
      " [ 0.962  0.333  0.848]\n",
      " [ 0.9    0.553  0.765]\n",
      " [ 1.     0.167  0.809]\n",
      " [ 0.952  0.611  0.667]\n",
      " [ 1.     0.5    0.674]\n",
      " [ 0.92   0.25   0.762]\n",
      " [ 0.955  0.125  0.822]\n",
      " [ 0.958  0.545  0.793]\n",
      " [ 0.947  0.677  0.72 ]\n",
      " [ 0.952  0.579  0.625]\n",
      " [ 0.958  0.636  0.625]\n",
      " [ 0.944  0.167  0.784]\n",
      " [ 0.96   0.577  0.625]\n",
      " [ 0.944  0.562  0.56 ]]\n",
      "Recall: [[ 0.704  0.167  0.952]\n",
      " [ 0.909  0.655  0.708]\n",
      " [ 0.875  0.     0.977]\n",
      " [ 0.826  0.143  0.978]\n",
      " [ 0.8    0.333  0.947]\n",
      " [ 1.     0.68   0.871]\n",
      " [ 0.926  0.125  0.975]\n",
      " [ 0.818  0.808  0.481]\n",
      " [ 0.759  0.143  0.974]\n",
      " [ 0.833  0.478  0.857]\n",
      " [ 0.864  0.263  0.912]\n",
      " [ 0.92   0.154  0.865]\n",
      " [ 0.808  0.1    0.949]\n",
      " [ 0.852  0.632  0.793]\n",
      " [ 0.9    0.724  0.692]\n",
      " [ 0.8    0.759  0.476]\n",
      " [ 0.852  0.318  0.962]\n",
      " [ 0.81   0.077  0.976]\n",
      " [ 0.857  0.625  0.652]\n",
      " [ 0.773  0.6    0.609]]\n",
      "F1: [[ 0.826  0.143  0.889]\n",
      " [ 0.909  0.667  0.694]\n",
      " [ 0.933  0.     0.894]\n",
      " [ 0.884  0.167  0.926]\n",
      " [ 0.889  0.381  0.857]\n",
      " [ 0.974  0.739  0.831]\n",
      " [ 0.943  0.182  0.907]\n",
      " [ 0.857  0.656  0.591]\n",
      " [ 0.863  0.154  0.884]\n",
      " [ 0.889  0.537  0.75 ]\n",
      " [ 0.927  0.345  0.775]\n",
      " [ 0.92   0.19   0.81 ]\n",
      " [ 0.875  0.111  0.881]\n",
      " [ 0.902  0.585  0.793]\n",
      " [ 0.923  0.7    0.706]\n",
      " [ 0.87   0.657  0.541]\n",
      " [ 0.902  0.424  0.758]\n",
      " [ 0.872  0.105  0.87 ]\n",
      " [ 0.906  0.6    0.638]\n",
      " [ 0.85   0.581  0.583]]\n",
      "#################################\n",
      "Random Forest\n",
      "Optimal thresholds: [[ 2.45  3.85]\n",
      " [ 2.3   3.8 ]\n",
      " [ 2.1   4.  ]\n",
      " [ 2.25  3.8 ]\n",
      " [ 2.1   4.  ]\n",
      " [ 2.05  4.  ]\n",
      " [ 2.2   4.  ]\n",
      " [ 2.3   3.95]\n",
      " [ 2.15  4.  ]\n",
      " [ 2.3   3.8 ]\n",
      " [ 2.    3.75]\n",
      " [ 2.15  3.4 ]\n",
      " [ 2.05  4.  ]\n",
      " [ 2.5   3.75]\n",
      " [ 2.    3.95]\n",
      " [ 2.35  3.5 ]\n",
      " [ 2.1   3.8 ]\n",
      " [ 2.1   3.85]\n",
      " [ 2.1   4.  ]\n",
      " [ 2.25  3.85]]\n",
      "Accuracy: [ 0.867  0.84   0.84   0.8    0.853  0.867  0.907  0.84   0.867  0.813\n",
      "  0.84   0.84   0.853  0.813  0.88   0.787  0.907  0.84   0.827  0.813]\n",
      "Precision: [[ 0.963  0.828  0.789]\n",
      " [ 0.917  0.774  0.85 ]\n",
      " [ 1.     0.767  0.792]\n",
      " [ 0.88   0.684  0.806]\n",
      " [ 0.923  0.839  0.778]\n",
      " [ 1.     0.759  0.893]\n",
      " [ 0.963  0.88   0.87 ]\n",
      " [ 0.913  0.719  0.95 ]\n",
      " [ 1.     0.742  0.9  ]\n",
      " [ 1.     0.783  0.7  ]\n",
      " [ 1.     0.8    0.774]\n",
      " [ 0.96   0.842  0.742]\n",
      " [ 0.96   0.767  0.85 ]\n",
      " [ 0.963  0.6    0.87 ]\n",
      " [ 0.947  0.833  0.885]\n",
      " [ 0.926  0.7    0.714]\n",
      " [ 1.     0.913  0.821]\n",
      " [ 0.947  0.767  0.846]\n",
      " [ 0.963  0.71   0.824]\n",
      " [ 0.95   0.75   0.783]]\n",
      "Recall: [[ 0.963  0.857  0.75 ]\n",
      " [ 1.     0.828  0.708]\n",
      " [ 0.875  0.852  0.792]\n",
      " [ 0.957  0.591  0.833]\n",
      " [ 0.96   0.839  0.737]\n",
      " [ 0.947  0.88   0.806]\n",
      " [ 0.963  0.846  0.909]\n",
      " [ 0.955  0.885  0.704]\n",
      " [ 0.828  0.958  0.818]\n",
      " [ 0.917  0.692  0.84 ]\n",
      " [ 0.864  0.769  0.889]\n",
      " [ 0.96   0.64   0.92 ]\n",
      " [ 0.923  0.885  0.739]\n",
      " [ 0.963  0.789  0.69 ]\n",
      " [ 0.9    0.893  0.852]\n",
      " [ 1.     0.583  0.769]\n",
      " [ 0.889  0.84   1.   ]\n",
      " [ 0.857  0.821  0.846]\n",
      " [ 0.929  0.88   0.636]\n",
      " [ 0.864  0.8    0.783]]\n",
      "F1: [[ 0.963  0.842  0.769]\n",
      " [ 0.957  0.8    0.773]\n",
      " [ 0.933  0.807  0.792]\n",
      " [ 0.917  0.634  0.82 ]\n",
      " [ 0.941  0.839  0.757]\n",
      " [ 0.973  0.815  0.847]\n",
      " [ 0.963  0.863  0.889]\n",
      " [ 0.933  0.793  0.809]\n",
      " [ 0.906  0.836  0.857]\n",
      " [ 0.957  0.735  0.764]\n",
      " [ 0.927  0.784  0.828]\n",
      " [ 0.96   0.727  0.821]\n",
      " [ 0.941  0.821  0.791]\n",
      " [ 0.963  0.682  0.769]\n",
      " [ 0.923  0.862  0.868]\n",
      " [ 0.962  0.636  0.741]\n",
      " [ 0.941  0.875  0.902]\n",
      " [ 0.9    0.793  0.846]\n",
      " [ 0.945  0.786  0.718]\n",
      " [ 0.905  0.774  0.783]]\n",
      "#################################\n",
      "SVM\n",
      "Optimal thresholds: [[ 2.5   3.85]\n",
      " [ 2.5   4.  ]\n",
      " [ 2.05  3.05]\n",
      " [ 2.4   3.95]\n",
      " [ 2.    3.  ]\n",
      " [ 2.3   3.85]\n",
      " [ 2.35  3.95]\n",
      " [ 2.3   3.85]\n",
      " [ 2.    3.  ]\n",
      " [ 2.25  3.9 ]\n",
      " [ 2.35  4.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.25  3.95]\n",
      " [ 2.25  3.85]\n",
      " [ 2.05  3.05]\n",
      " [ 2.55  3.8 ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.    3.  ]\n",
      " [ 2.4   3.5 ]\n",
      " [ 2.    3.  ]]\n",
      "Accuracy: [ 0.8    0.8    0.787  0.893  0.84   0.84   0.88   0.84   0.8    0.813\n",
      "  0.853  0.787  0.773  0.787  0.827  0.773  0.827  0.813  0.813  0.773]\n",
      "Precision: [[ 0.964  0.842  0.607]\n",
      " [ 0.88   0.792  0.731]\n",
      " [ 1.     0.2    0.755]\n",
      " [ 0.92   0.792  0.962]\n",
      " [ 0.957  0.556  0.837]\n",
      " [ 1.     0.842  0.757]\n",
      " [ 0.963  0.808  0.864]\n",
      " [ 0.952  0.769  0.821]\n",
      " [ 1.     0.182  0.86 ]\n",
      " [ 0.957  0.75   0.75 ]\n",
      " [ 1.     0.815  0.786]\n",
      " [ 0.96   0.25   0.786]\n",
      " [ 0.957  0.645  0.762]\n",
      " [ 0.963  0.56   0.826]\n",
      " [ 0.947  0.286  0.857]\n",
      " [ 0.833  0.739  0.727]\n",
      " [ 1.     0.143  0.844]\n",
      " [ 0.95   0.429  0.812]\n",
      " [ 1.     0.75   0.706]\n",
      " [ 0.944  0.091  0.87 ]]\n",
      "Recall: [[ 1.     0.571  0.85 ]\n",
      " [ 1.     0.655  0.792]\n",
      " [ 0.875  0.083  0.949]\n",
      " [ 1.     0.864  0.833]\n",
      " [ 0.88   0.417  0.947]\n",
      " [ 1.     0.64   0.903]\n",
      " [ 0.963  0.84   0.826]\n",
      " [ 0.909  0.8    0.821]\n",
      " [ 0.724  0.286  0.949]\n",
      " [ 0.917  0.692  0.84 ]\n",
      " [ 0.909  0.815  0.846]\n",
      " [ 0.96   0.167  0.868]\n",
      " [ 0.846  0.769  0.696]\n",
      " [ 0.963  0.737  0.655]\n",
      " [ 0.9    0.2    0.933]\n",
      " [ 1.     0.63   0.696]\n",
      " [ 0.852  0.143  0.927]\n",
      " [ 0.905  0.231  0.951]\n",
      " [ 0.893  0.571  0.923]\n",
      " [ 0.773  0.125  0.889]]\n",
      "F1: [[ 0.982  0.681  0.708]\n",
      " [ 0.936  0.717  0.76 ]\n",
      " [ 0.933  0.118  0.841]\n",
      " [ 0.958  0.826  0.893]\n",
      " [ 0.917  0.476  0.889]\n",
      " [ 1.     0.727  0.824]\n",
      " [ 0.963  0.824  0.844]\n",
      " [ 0.93   0.784  0.821]\n",
      " [ 0.84   0.222  0.902]\n",
      " [ 0.936  0.72   0.792]\n",
      " [ 0.952  0.815  0.815]\n",
      " [ 0.96   0.2    0.825]\n",
      " [ 0.898  0.702  0.727]\n",
      " [ 0.963  0.636  0.731]\n",
      " [ 0.923  0.235  0.894]\n",
      " [ 0.909  0.68   0.711]\n",
      " [ 0.92   0.143  0.884]\n",
      " [ 0.927  0.3    0.876]\n",
      " [ 0.943  0.649  0.8  ]\n",
      " [ 0.85   0.105  0.879]]\n",
      "#################################\n"
     ]
    }
   ],
   "source": [
    "print('regressors with minimized mean squared error')\n",
    "for k, v in thresh_scores_mse.items():\n",
    "    print(k)\n",
    "    print(\"Optimal thresholds: {}\".format(np.around([x[0] for x in v], decimals = 2)))\n",
    "    print(\"Accuracy: {}\".format(np.around([x[1] for x in v], decimals = 3)))\n",
    "    print(\"Precision: {}\".format(np.around([x[2] for x in v], decimals = 3)))\n",
    "    print(\"Recall: {}\".format(np.around([x[3] for x in v], decimals = 3)))\n",
    "    print(\"F1: {}\".format(np.around([x[4] for x in v], decimals = 3)))\n",
    "    print(\"#################################\")    \n",
    "    \n",
    "print()\n",
    "print('regressors with minimized mean absolute error')\n",
    "for k, v in thresh_scores_mae.items():\n",
    "    print(k)\n",
    "    print(\"Optimal thresholds: {}\".format(np.around([x[0] for x in v], decimals = 2)))\n",
    "    print(\"Accuracy: {}\".format(np.around([x[1] for x in v], decimals = 3)))\n",
    "    print(\"Precision: {}\".format(np.around([x[2] for x in v], decimals = 3)))\n",
    "    print(\"Recall: {}\".format(np.around([x[3] for x in v], decimals = 3)))\n",
    "    print(\"F1: {}\".format(np.around([x[4] for x in v], decimals = 3)))\n",
    "    print(\"#################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaging\n",
    "avg_thresh_scores_mse = {}\n",
    "avg_thresh_scores_mae = {}\n",
    "metrics = ['thresholds', 'accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "for k, v in thresh_scores_mse.items():\n",
    "    avg_thresh_scores_mse[k] = {}\n",
    "    for i, m in enumerate(metrics):\n",
    "        avg_thresh_scores_mse[k][m] = np.average([x[i] for x in v], axis = 0)\n",
    "        \n",
    "for k, v in thresh_scores_mae.items():\n",
    "    avg_thresh_scores_mae[k] = {}\n",
    "    for i, m in enumerate(metrics):\n",
    "        avg_thresh_scores_mae[k][m] = np.average([x[i] for x in v], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AdaBoost': {'accuracy': 0.85799999999999998,\n",
       "  'f1': array([ 0.94370688,  0.05836601,  0.89268761]),\n",
       "  'precision': array([ 0.94728573,  0.11153846,  0.83270472]),\n",
       "  'recall': array([ 0.94319677,  0.05069841,  0.96560359]),\n",
       "  'thresholds': array([ 2.0025,  3.0425])},\n",
       " 'MLP': {'accuracy': 0.79999999999999993,\n",
       "  'f1': array([ 0.92839955,  0.52466184,  0.80590044]),\n",
       "  'precision': array([ 0.95127446,  0.60769077,  0.7645206 ]),\n",
       "  'recall': array([ 0.91000005,  0.48425885,  0.86705142]),\n",
       "  'thresholds': array([ 2.2175,  3.4725])},\n",
       " 'Nearest Neighbors': {'accuracy': 0.76866666666666661,\n",
       "  'f1': array([ 0.89567506,  0.39617104,  0.77882978]),\n",
       "  'precision': array([ 0.95814304,  0.42702785,  0.74358778]),\n",
       "  'recall': array([ 0.84421848,  0.38916432,  0.83032613]),\n",
       "  'thresholds': array([ 2.255 ,  3.4475])},\n",
       " 'Random Forest': {'accuracy': 0.84466666666666668,\n",
       "  'f1': array([ 0.94045448,  0.78524884,  0.80709853]),\n",
       "  'precision': array([ 0.95876508,  0.77273872,  0.8218054 ]),\n",
       "  'recall': array([ 0.92557651,  0.80642744,  0.80107434]),\n",
       "  'thresholds': array([ 2.19  ,  3.8525])},\n",
       " 'SVM': {'accuracy': 0.81599999999999984,\n",
       "  'f1': array([ 0.93206919,  0.52800453,  0.8208557 ]),\n",
       "  'precision': array([ 0.9573652 ,  0.56194996,  0.79601383]),\n",
       "  'recall': array([ 0.91341322,  0.51177491,  0.85474726]),\n",
       "  'thresholds': array([ 2.225 ,  3.5275])}}"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_thresh_scores_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S2, S6 and Pixel Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = {}\n",
    "df['s2'] = pd.read_table(dr + 's2.txt', delim_whitespace=True, dtype = dtype)\n",
    "df['s6'] = pd.read_table(dr + 's6.txt', delim_whitespace=True, dtype = dtype)\n",
    "df['px'] = pd.read_table(dr + 'pixel.txt', delim_whitespace=True, dtype = dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "for d in df.values():\n",
    "    d['BitRate'] /= 100     # transforming BitRate to percentages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "X = {}\n",
    "y = {}\n",
    "# y_bin = {}\n",
    "for k, d in df.items():\n",
    "    X[k], y[k] = np.array(d[features]), np.array(d['Quality'])\n",
    "    # y_bin[k] = label_binarize(y[k], classes = classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#mae = {}\n",
    "\n",
    "thresh = {}\n",
    "accuracy = {}\n",
    "'''\n",
    "acc = {}\n",
    "prec = {}\n",
    "recl = {}\n",
    "f1 = {}\n",
    "'''\n",
    "for r, reg in best_regressors_mae.items():\n",
    "    #mae[r] = {}\n",
    "    thresh[r] = {}\n",
    "    '''\n",
    "    acc[r] = {}\n",
    "    prec[r] = {}\n",
    "    recl[r] = {} \n",
    "    f1[r] = {}    \n",
    "    '''\n",
    "    for k in X.keys():\n",
    "        #mae[r][k] = {}\n",
    "        thresh[r][k] = {}\n",
    "        '''\n",
    "        acc[r][k] = {}\n",
    "        prec[r][k] = {}\n",
    "        recl[r][k] = {} \n",
    "        f1[r][k] = {}\n",
    "        '''\n",
    "        for k1 in X.keys():\n",
    "            if k1 != k: # train and test on other datasets\n",
    "                #pred = reg.fit(X[k], y[k]).predict(X[k1])\n",
    "                #mae[r][k][k1] = mean_absolute_error(y[k1], pred)\n",
    "                thresh[r][k][k1] = optimize_thresh(reg, X[k], y[k], X[k1], y[k1], t1_range, 10)\n",
    "                #y_label_true = to_label(y[k1], thresh_accuracy_mae[r][0])\n",
    "                #y_label_pred = to_label(pred, thresh_accuracy_mae[r][0])\n",
    "                #acc[r][k][k1] = accuracy_score(y_label_true, y_label_pred)\n",
    "                #prec[r][k][k1] = precision_score(y_label_true, y_label_pred, average = None) \n",
    "                #recl[r][k][k1] = recall_score(y_label_true, y_label_pred, average = None) \n",
    "                #f1[r][k][k1] = f1_score(y_label_true, y_label_pred, average = None)  \n",
    "            else:    # train and test on itself\n",
    "                X_tr, X_te, y_tr, y_te = train_test_split(X[k], y[k], test_size = 0.25, random_state = 1)\n",
    "                thresh[r][k][k] = optimize_thresh(reg, X_tr, y_tr, X_te, y_te, t1_range, 10)\n",
    "                #pred = reg.fit(X_tr, y_tr).predict(X_te)\n",
    "                #mae[r][k][k1] = mean_absolute_error(y_te, pred)\n",
    "                #y_label_true = to_label(y_te, thresh_accuracy_mae[r][0])\n",
    "                #y_label_pred = to_label(pred, thresh_accuracy_mae[r][0])\n",
    "                #acc[r][k][k] = accuracy_score(y_label_true, y_label_pred)\n",
    "                #prec[r][k][k] = precision_score(y_label_true, y_label_pred, average = None) \n",
    "                #recl[r][k][k] = recall_score(y_label_true, y_label_pred, average = None) \n",
    "                #f1[r][k][k] = f1_score(y_label_true, y_label_pred, average = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def print_results(dic, title):\n",
    "    print('#################################')\n",
    "    print('{} results:'.format(title))\n",
    "    for k, v in dic.items():\n",
    "        print(k)\n",
    "        for k1, v1 in v.items():\n",
    "            print(\"training set: {}\".format(k1))\n",
    "            for k2, v2 in v1.items():\n",
    "                print(\"optimal thresholds on {}: {}, {}\".format(k2, np.around(v2[0][0], decimals = 3), np.around(v2[0][1], decimals = 3)))\n",
    "                print(\"optimal accuracy on {}: {}\".format(k2, np.around(v2[1], decimals = 3)))\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "acc = {}\n",
    "prec = {}\n",
    "recl = {}\n",
    "f1 = {}\n",
    "for r, reg in best_regressors_mae.items():\n",
    "    acc[r] = {}\n",
    "    prec[r] = {}\n",
    "    recl[r] = {} \n",
    "    f1[r] = {}    \n",
    "    for k in X.keys():\n",
    "        acc[r][k] = {}\n",
    "        prec[r][k] = {}\n",
    "        recl[r][k] = {} \n",
    "        f1[r][k] = {}\n",
    "        for k1 in X.keys():\n",
    "            if k1 != k: # train and test on other datasets\n",
    "                pred = reg.fit(X[k], y[k]).predict(X[k1])\n",
    "                y_label_true = to_label(y[k1], thresh_accuracy_mse[r][0])\n",
    "                y_label_pred = to_label(pred, thresh_accuracy_mse[r][0])\n",
    "                acc[r][k][k1] = accuracy_score(y_label_true, y_label_pred)\n",
    "                prec[r][k][k1] = precision_score(y_label_true, y_label_pred, average = None) \n",
    "                recl[r][k][k1] = recall_score(y_label_true, y_label_pred, average = None) \n",
    "                f1[r][k][k1] = f1_score(y_label_true, y_label_pred, average = None)  \n",
    "            else:    # train and test on itself\n",
    "                X_tr, X_te, y_tr, y_te = train_test_split(X[k], y[k], test_size = 0.25, random_state = 1)\n",
    "                pred = reg.fit(X_tr, y_tr).predict(X_te)\n",
    "                y_label_true = to_label(y_te, thresh_accuracy_mse[r][0])\n",
    "                y_label_pred = to_label(pred, thresh_accuracy_mse[r][0])\n",
    "                acc[r][k][k] = accuracy_score(y_label_true, y_label_pred)\n",
    "                prec[r][k][k] = precision_score(y_label_true, y_label_pred, average = None) \n",
    "                recl[r][k][k] = recall_score(y_label_true, y_label_pred, average = None) \n",
    "                f1[r][k][k] = f1_score(y_label_true, y_label_pred, average = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def print_results(dic, title):\n",
    "    print('#################################')\n",
    "    print('{} results:'.format(title))\n",
    "    for k, v in dic.items():\n",
    "        print(k)\n",
    "        for k1, v1 in v.items():\n",
    "            print(\"training set: {}\".format(k1))\n",
    "            for k2, v2 in v1.items():\n",
    "                print(\"{} on {}: {}\".format(title, k2, np.around(v2, decimals = 3)))\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print_results(acc, 'accuracy')\n",
    "print_results(prec, 'precision')\n",
    "print_results(recl, 'recall')\n",
    "print_results(f1, 'f1_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD8CAYAAACYebj1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAHfdJREFUeJzt3X2cVWW99/HPF0RHkod4sPsk6kwe\nCNGBIceKNLXwgUy0DBPuStGCTKn77oFuLI8R8SpLT3ZMTyUnH48CgUJkdFMHUQ9hKegoIKGYKKOW\nBElSjDD4O3/sNcvtOA+LYdbsGfi+X6/9mrWufa21fvuamf3b17rWvpYiAjMzM4BupQ7AzMw6DycF\nMzNLOSmYmVnKScHMzFJOCmZmlnJSMDOzlJOCmZmlnBTMzCzlpGBmZqkDSh3AnhowYECUl5eXOgwz\nsy5l1apVf4mIga3V63JJoby8nJUrV5Y6DDOzLkXSs1nq+fSRmZmlnBTMzCzlpGBmZqkuN6ZgZvnb\ntWsXtbW11NXVlToU20NlZWUMGjSIHj16tGl7JwUze5Pa2lp69epFeXk5kkodjmUUEWzZsoXa2loq\nKiratA+fPjKzN6mrq6N///5OCF2MJPr3779XPTwnBTNrkhNC17S3vzcnBTMzS3lMwcxaVT7tl+26\nv41XfThTvQULFnDuueeybt06hg4d+qbnJ06cyFlnncW4ceOa3cfEiRO5//776dOnD3V1dUyYMIFv\nfOMbbY69sYULFzJkyBCGDRvWbvssJScFy6y93xj2VNY3Ett3zJ49mxNPPJE5c+Ywffr0Nu/n6quv\nZty4cdTV1TFs2DAuuOCCNg/ENrZw4ULOOuusfSYp+PSRmXVK27dv57e//S0//elPmTNnDlC4umbK\nlCkMGzaMD3/4w7z00ktp/RkzZnD88cdz7LHHMnnyZCLiTftsGIB9y1veAsDSpUsZOXIklZWVXHzx\nxbz66qstlk+bNo1hw4YxfPhwvvKVr7BixQoWLVrE1KlTqaqq4umnn861TTqCk4KZdUoLFy5kzJgx\nDBkyhH79+vHII4+wYMEC1q9fz+rVq5k1axYrVqxI60+ZMoWHH36YNWvWsGPHDu655570uYY37UGD\nBjF+/HgOPfRQ6urqmDhxInPnzmX16tXU19fzox/9qNnyrVu3smDBAtauXcvjjz/OFVdcwfve9z7O\nPvtsrr76ampqajjqqKNK0VTtyknBzDql2bNnM378eADGjx/P7NmzeeCBB5gwYQLdu3fn7W9/Ox/8\n4AfT+suWLeM973kPlZWV3HvvvaxduzZ9ruFN+09/+hNLly5lxYoVrF+/noqKCoYMGQLAhRdeyAMP\nPNBsee/evSkrK+Mzn/kMd999Nz179uzA1ug4HlMws05ny5Yt3HvvvaxZswZJ7N69G0l89KMfbfKS\ny7q6Oi699FJWrlzJ4YcfzvTp05u8Vv+QQw7hlFNOYfny5Zx++ulNHrup004ABxxwAA899BBLly5l\nzpw5XH/99dx7771790I7IfcUzKzTmT9/PhdccAHPPvssGzduZNOmTVRUVNCvXz/mzJnD7t27efHF\nF1m2bBnw+ljBgAED2L59O/Pnz29yv/X19fz+97/nqKOOYujQoWzcuJENGzYAcPvtt3PyySc3W759\n+3a2bdvGmWeeyQ9+8ANqamoA6NWrF6+88kreTdJh3FMws1Z19JVfs2fPZtq0aW8o+9jHPsa6desY\nPHgwlZWVDBkyhJNPPhmAvn37MmnSJCorKykvL+f4449/w7ZTp05l5syZ7Ny5k9GjR3PuueciiZtv\nvpnzzjuP+vp6jj/+eC655BIOOuigJsu3bt3KOeecQ11dHRHBtddeCxRObU2aNInrrruO+fPnd/lx\nBTXXVeqsqqurwzfZKQ1fkrr/WLduHUcffXSpw7A2aur3J2lVRFS3tq1PH5mZWcpJwczMUk4KZmaW\nclIwM7OUk4KZmaVyTQqSxkhaL2mDpGlNPH+EpGWSHpX0uKQz84zHzMxaltv3FCR1B24ATgNqgYcl\nLYqIJ4qqXQH8LCJ+JGkYsBgozysmM2uj6X3aeX/bWq3SvXt3Kisrqa+vp6Kigttvv52+ffvu9aE3\nbtzIWWedxZo1a/Z6X8WmT5/OrFmzGDhwIABjxozhqquuatdjNKipqeGFF17gzDPb/3N0nj2FdwMb\nIuKPEbETmAOc06hOAL2T5T7ACznGY2ZdyMEHH0xNTQ1r1qyhX79+3HDDDaUOqVVf/OIXqampoaam\nZo8Swu7du/foODU1NSxevHhPw8skz6RwGLCpaL02KSs2HfikpFoKvYTPN7UjSZMlrZS0cvPmzXnE\namad2KhRo3j++eeBwpTao0eP5l3veheVlZX8/Oc/Bwo9gKOPPppJkyZxzDHHcPrpp7Njxw4AVq1a\nxYgRIxg1atQbkktdXR0XXXQRlZWVjBw5Mp0245ZbbuEjH/kIY8eOpaKiguuvv57vf//7jBw5kve+\n971s3bo1c+zNTcNdXl7OjBkzOPHEE5k3bx5PP/00Y8aM4bjjjuP9738/f/jDHwCYN28exx57LCNG\njOCkk05i586dXHnllcydO5eqqirmzp279w1cJM+k0NSNQht/fXoCcEtEDALOBG6X9KaYIuLGiKiO\niOqGrpmZ7R92797N0qVLOfvsswEoKytjwYIFPPLIIyxbtowvf/nL6SR2Tz31FJdddhlr166lb9++\n3HXXXQBcdNFFXHfddTz44INv2HdDgli9ejWzZ8/mwgsvTOdRWrNmDXfeeScPPfQQX//61+nZsyeP\nPvooo0aN4rbbbmsy1muvvZaqqiqqqqpYsmRJs9NwNygrK2P58uWMHz+eyZMn88Mf/pBVq1ZxzTXX\ncOmllwKF+0QsWbKExx57jEWLFnHggQcyY8YMzj//fGpqajj//PPbsbXzTQq1wOFF64N48+mhTwM/\nA4iIB4EyYECOMZlZF7Fjxw6qqqro378/W7du5bTTTgMKs5h+7WtfY/jw4Zx66qk8//zz/PnPfwag\noqKCqqoqAI477jg2btzItm3bePnll9N5kj71qU+lx1i+fHm6PnToUI488kiefPJJAD7wgQ/Qq1cv\nBg4cSJ8+fRg7diwAlZWVbNy4scmYi08fnXHGGc1Ow92g4Q19+/btrFixgvPOO4+qqio++9nP8uKL\nLwJwwgknMHHiRGbNmrXHp5naIs+k8DAwWFKFpAOB8cCiRnWeA0YDSDqaQlLw+SEzS8cUnn32WXbu\n3Jl+qr/jjjvYvHkzq1atoqamhre97W3pp/uDDjoo3b579+7U19cTEU1Otw3NT5PdeF/dunVL17t1\n60Z9fX2m19Da3HINd4B77bXX6Nu3b5pQampqWLduHQA//vGPmTlzJps2baKqqootW7ZkOnZb5ZYU\nIqIemAIsAdZRuMporaQZks5Oqn0ZmCTpMWA2MDG62gx9ZparPn36cN1113HNNdewa9cutm3bxqGH\nHkqPHj1YtmwZzz77bIvb9+3blz59+rB8+XKgkFQanHTSSen6k08+yXPPPcc73/nOdou9uWm4G+vd\nuzcVFRXMmzcPKCSTxx57DICnn36a97znPcyYMYMBAwawadOmXKfrznXq7IhYTGEAubjsyqLlJ4AT\n8ozBzNpBhktI8zRy5EhGjBjBnDlz+MQnPsHYsWOprq6mqqqKoUOHtrr9zTffzMUXX0zPnj0544wz\n0vJLL72USy65hMrKSg444ABuueWWN/QQ9lZZWVmT03A35Y477uBzn/scM2fOZNeuXYwfP54RI0Yw\ndepUnnrqKSKC0aNHM2LECI444giuuuoqqqqquPzyy9t1XMFTZ1tmnjp7/+Gps7s2T51tZmbtwknB\nzMxSTgpm1qSudmrZCvb29+akYGZvUlZWxpYtW5wYupiIYMuWLZSVlbV5H7lefWRmXdOgQYOora3F\n08p0PWVlZQwaNKjN2zspmNmb9OjRg4qKilKHYSXg00dmZpZyUjAzs5STgpmZpZwUzMws5aRgZmYp\nJwUzM0s5KZiZWcpJwczMUk4KZmaW8jeareuY3qfExy/tjWbMOoJ7CmZmlnJSMDOzlJOCmZmlnBTM\nzCzlpGBmZiknBTMzSzkpmJlZyknBzMxSTgpmZpZyUjAzs5STgpmZpZwUzMws1WpSkDRE0lJJa5L1\n4ZKuyD80MzPraFl6CrOAy4FdABHxODA+z6DMzKw0siSFnhHxUKOy+jyCMTOz0sqSFP4i6SggACSN\nA17MNSozMyuJLDfZuQy4ERgq6XngGeCTuUZlZmYl0WpSiIg/AqdKegvQLSJeyT8sMzMrhSxXH31b\nUt+I+HtEvCLprZJmdkRwZmbWsbKMKXwoIl5uWImIvwJn5heSmZmVSpak0F3SQQ0rkg4GDmqhvpmZ\ndVFZksJ/AkslfVrSxcBvgFuz7FzSGEnrJW2QNK2ZOh+X9ISktZLuzB66mZm1tywDzd+TtBoYDQj4\nVkQsaW07Sd2BG4DTgFrgYUmLIuKJojqDKXwx7oSI+KukQ9v4OszMrB1kuSSViPgV8Ks93Pe7gQ3J\n1UtImgOcAzxRVGcScEMyTkFEvLSHxzAzs3aU5eqjcyU9JWmbpL9JekXS3zLs+zBgU9F6bVJWbAgw\nRNJvJf1O0pjsoZuZWXvL0lP4HjA2Itbt4b7VRFk0cfzBwCnAIOC/JR1bfLUTgKTJwGSAI444Yg/D\nMDOzrLIMNP+5DQkBCj2Dw4vWBwEvNFHn5xGxKyKeAdZTSBJvEBE3RkR1RFQPHDiwDaGYmVkWWXoK\nKyXNBRYCrzYURsTdrWz3MDBYUgXwPIWZVf93ozoLgQnALZIGUDid9MeMsZuZWTvLkhR6A/8ATi8q\nC6DFpBAR9ZKmAEuA7sBNEbFW0gxgZUQsSp47XdITwG5gakRsacPrMDOzdpDlktSL2rrziFgMLG5U\ndmXRcgBfSh5mZlZirSYFSWXAp4FjgLKG8oi4OMe4zMysBLIMNN8O/C/gDOB+CgPGninVzGwflCUp\n/HNE/Avw94i4FfgwUJlvWGZmVgpZksKu5OfLko4F+gDluUVkZmYlk+XqoxslvRW4AlgEHAL8S65R\nmZlZSWRJCkuTuYkeAN4BkHz3wMzM9jFZTh/d1UTZ/PYOxMzMSq/ZnoKkoRQuQ+0j6dyip3pTdGmq\nmZntO1o6ffRO4CygLzC2qPwVClNem5nZPqbZpBARP5d0D/D/IuLbHRiTmZmVSItjChGxm8Kd08zM\nbD+Q5eqjFZKuB+YCf28ojIhHcovKzMxKIktSeF/yc0ZRWQAfbP9wzMyslLLMkvqBjgjEzMxKL8s9\nmvtI+r6klcnjXyX16YjgzMysY2X58tpNFC5D/Xjy+Btwc55BmZlZaWQZUzgqIj5WtP5NSTV5BWRm\nZqWTpaewQ9KJDSuSTgB25BeSmZmVSpaewueAW5NxBAFbgQtzjcrMzEoiy9VHNcAISb2T9b/lHpWZ\nmZVElquP+ku6DrgPWCbp3yT1zz0yMzPrcFnGFOYAm4GPAeOS5bl5BmVmZqWRZUyhX0R8q2h9pqSP\n5BWQmZmVTpaewjJJ4yV1Sx4fB36Zd2BmZtbxsiSFzwJ3AjuTxxzgS5JekeRBZzOzfUiWq496dUQg\nZmZWelnGFJA0HCgvrh8Rd+cUk5mZlUirSUHSTcBwYC3wWlIcgJOCmdk+JktP4b0RMSz3SMzMrOSy\nDDQ/KMlJwcxsP5Clp3ArhcTwJ+BVCvMfRUQMzzUyMzPrcFmSwk3Ap4DVvD6mYGZm+6AsSeG5iFiU\neyRmZlZyWZLCHyTdCfyCwukjwJekmpnti7IkhYMpJIPTi8p8SaqZ2T4oyzeaL+qIQMzMrPSaTQqS\nfkihR9CkiPhCLhGZmVnJtNRTWNlhUZiZWafQbFKIiFs7MhAzMyu9LN9objNJYyStl7RB0rQW6o2T\nFJKq84zHzMxalltSkNQduAH4EDAMmNDUdBmSegFfAH6fVyxmZpZNnj2FdwMbIuKPEdFwc55zmqj3\nLeB7QF2OsZiZWQatJgVJQyQtlbQmWR8u6YoM+z4M2FS0XpuUFe97JHB4RNyzBzGbmVlOsvQUZgGX\nA7sAIuJxYHyG7dREWXqJq6RuwLXAl1vdkTRZ0kpJKzdv3pzh0GZm1hZZkkLPiHioUVl9hu1qgcOL\n1gcBLxSt9wKOBe6TtBF4L7CoqcHmiLgxIqojonrgwIEZDm1mZm2RJSn8RdJRJJ/yJY0DXsyw3cPA\nYEkVkg6k0LtIJ9aLiG0RMSAiyiOiHPgdcHZE+PsRZmYlkmXuo8uAG4Ghkp4HngE+0dpGEVEvaQqw\nBOgO3BQRayXNAFZ65lUzs86nxaSQnPevjohTJb0F6BYRr2TdeUQsBhY3KruymbqnZN2vmZnlo8XT\nRxHxGjAlWf77niQEMzPrerKMKfxG0lckHS6pX8Mj98jMzKzDZRlTuDj5eVlRWQDvaP9wzMyslLLc\nT6GiIwIxM7PSazUpSLqgqfKIuK39wzEzs1LKcvro+KLlMmA08AjgpGBmto/Jcvro88XrkvoAt+cW\nkZmZlUxbZkn9BzC4vQMxM7PSyzKm8Aten8iuG4V7I8zLMygzMyuNLGMK1xQt1wPPRkRtTvGYmVkJ\nZTl9dGZE3J88fhsRtZK+m3tkZmbW4bIkhdOaKPtQewdiZmal1+zpI0mfAy4F3iHp8aKnegG/zTsw\nMzPreC2NKdwJ/Ar4DjCtqPyViNiaa1RmZlYSzSaFiNgGbAMmAEg6lMKX1w6RdEhEPNcxIZqZWUdp\ndUxB0lhJT1G4uc79wEYKPQgzM9vHZBlonknh/slPJpPjjcZjCmZm+6QsSWFXRGwBuknqFhHLgKqc\n4zIzsxLI8uW1lyUdAvw3cIeklyh8ic3MzPYxWXoK51CY7+j/Av8feBoYm2dQZmZWGllmSf27pCOB\nwRFxq6SeQPf8QzMzs46W5eqjScB84CdJ0WHAwjyDMjOz0shy+ugy4ATgbwAR8RRwaJ5BmZlZaWRJ\nCq9GxM6GFUkH8PpU2mZmtg/JkhTul/Q14GBJp1G4l8Iv8g3LzMxKIUtSmAZsBlYDnwUWA1fkGZSZ\nmZVGS7OkHhERz0XEa8Cs5GFmZvuwlnoK6RVGku7qgFjMzKzEWkoKKlp+R96BmJlZ6bWUFKKZZTMz\n20e19I3mEZL+RqHHcHCyTLIeEdE79+jMzKxDtXSTHU9lYWa2n8lySaqZme0nnBTMzCzlpGBmZikn\nBTMzSzkpmJlZyknBzMxSTgpmZpbKNSlIGiNpvaQNkqY18fyXJD0h6XFJS5PbfpqZWYnklhQkdQdu\nAD4EDAMmSBrWqNqjQHVEDKdwy8/v5RWPmZm1Ls+ewruBDRHxx+TObXOAc4orRMSyiPhHsvo7YFCO\n8ZiZWSvyTAqHAZuK1muTsuZ8GvhVU09ImixppaSVmzdvbscQzcysWJ5JQU2UNTnbqqRPAtXA1U09\nHxE3RkR1RFQPHDiwHUM0M7NiLc2SurdqgcOL1gcBLzSuJOlU4OvAyRHxao7xmJlZK/LsKTwMDJZU\nIelAYDywqLiCpJHAT4CzI+KlHGMxM7MMcksKEVEPTAGWAOuAn0XEWkkzJJ2dVLsaOASYJ6lG0qJm\ndmdmZh0gz9NHRMRiYHGjsiuLlk/N8/hmZrZn/I1mMzNLOSmYmVnKScHMzFJOCmZmlnJSMDOzlJOC\nmZmlnBTMzCzlpGBmZiknBTMzSzkpmJlZyknBzMxSTgpmZpZyUjAzs1Sus6RaI9P7lPj420p7fLOu\nbj/4H3ZPwczMUk4KZmaWclIwM7OUk4KZmaWcFMzMLOWkYGZmKScFMzNLOSmYmVnKScHMzFJOCmZm\nlvI0F2bWZZRP+2VJj7+xrKSH7xDuKZiZWcpJwczMUk4KZmaWclIwM7OUk4KZmaV89ZHZ/mQ/uEmM\n7R33FMzMLLVf9RR8jbOZWcvcUzAzs5STgpmZpZwUzMws5aRgZmYpJwUzM0vlevWRpDHAvwHdgf+I\niKsaPX8QcBtwHLAFOD8iNuYZk1mplPrqN/AVcNa63HoKkroDNwAfAoYBEyQNa1Tt08BfI+KfgWuB\n7+YVj5mZtS7P00fvBjZExB8jYicwBzinUZ1zgFuT5fnAaEnKMSYzM2tBnknhMGBT0XptUtZknYio\nB7YB/XOMyczMWpDnmEJTn/ijDXWQNBmYnKxul7R+L2MrCcEA4C8lC+CbXbsT5vbbe27DvdPF2+/I\nLJXyTAq1wOFF64OAF5qpUyvpAKAPsLXxjiLiRuDGnOLsMJJWRkR1qePoqtx+e89tuHf2h/bL8/TR\nw8BgSRWSDgTGA4sa1VkEXJgsjwPujYg39RTMzKxj5NZTiIh6SVOAJRQuSb0pItZKmgGsjIhFwE+B\n2yVtoNBDGJ9XPGZm1rpcv6cQEYuBxY3KrixargPOyzOGTqbLnwIrMbff3nMb7p19vv3kszVmZtbA\n01yYmVnKSSEjSbsl1Uh6TNIjkt6XlL9d0vxkuUrSmUXbTJS0OdnuD5K+mOE4pzTsu7MrapOGR3kJ\nYrhF0jNFv5vRGbaZKOntRev/0cS37TuNztDOnUVnaIvkb25cDvv9WtFyuaQ17X2MLParO6/tpR0R\nUQUg6QzgO8DJEfEChSunAKqAat44jjI3IqZI6g+slzQ/Ioq/1NfYKcB2YEV7v4AcpG3SFEkHJF9K\nzNvUiJgv6QMUzvkObqX+RGANySXSEfGZfMPba52lnTuDfbktvgZ8u9RBuKfQNr2Bv8LrGT257HYG\ncH7yCeb84g0iYguwAfinZLuxkn4v6VFJ/yXpbcmnnkuALyb7eL+kgZLukvRw8jihA1/nHks+hc+T\n9Avg10nZ1CT2xyV9s6juJyU9lLzWn0jqLunsok+B6yU9k9Q9TtL9klZJWiLpn5o4/IMUfWte0pXJ\ncddIulEF4ygk7juSYxws6T5J1ck2EyStTrbptHNxdXQ7S/qCpCeSfc8pyYtuRin/5lpor/skfTc5\n1pOS3p+U95T0sySuucl7QLWkq4CDkxjuSHbfXdIsSWsl/VrSwTk3ZUFE+JHhAewGaoA/UJiO47ik\nvBxYkyxPBK4v2iZdB45Iti9L1t/K6wP9nwH+NVmeDnylaB93AicW7WNdqduiiTapARYUveZaoF+y\nfjqFT++i8CHkHuAk4GjgF0CPpN6/Axc02v/PgMuAHhR6TgOT8vMpXOIMcAswLln+CHBn0fb9ipZv\nB8Ymy/cB1UXP3UchUbwdeA4YSKEXfS/wEbdzQKFXdVCy3Hc/b4tbKJwdaKnOfbz+P30m8F/J8leA\nnyTLxwL1DX+LwPaiOMqT56qK4vpkR7SxTx9lV3z6aBRwm6RjM2x3vgqnNd4JTIrCZbhQ+Ib33OST\nxYHAM81sfyowTK/PE9hbUq+IeKWtL6QdNdeV/01ENHwz/fTk8WiyfgiF0zvDKUyZ/nDy2g4GXmrY\ngaSvJvu/IWnnY4HfJHW7Ay8WHe9qSd8DDgXeW1T+gWQ/PYF+wFoKbwrNOR64LyI2JzHcQeHNZGFL\njdABOkM7P06hd7WQ0rZHZ2iLBu9spc7dyc9VFN7kAU6kcDsBImKNpMdbeK3PRERNE/vIlZNCG0TE\ng5IGUPhE2ZqGMYVRwC8l/Soi/gT8EPh+RCySdAqFHkJTugGjImJHe8TeQf5etCzgOxHxk+IKkj4P\n3BoRlzfeWIXB4vMovCE37GNtRIxq5nhTKfwDfoHCrLvHSSqj8EmwOiI2SZoOtHY3ga42MU9HtvOH\nk3pnA/8i6ZjoXOfuO/pvLkudV5Ofu3n9vXZP/sZeLVreTSGJ5c5jCm0gaSiFTwVbGj31CtCrqW0i\n4kEKpzD+T1LUB3g+Wb6wqGrjffwamFJ07GYH2TqpJcDFkg4BkHSYpEOBpcC4ZBlJ/SQdKelICm/m\nHy9KhOuBgUliRVIPSccUHyQiXqPwCaybChcCNCSAvyTHLr5apLnf0++BkyUNUOF+IBOA+/e2ATpI\nbu0sqRtweEQsA74K9KXw6buz6pC/uYx1GlsOfDypPwyoLHpul6QebXzN7cY9hewOltTQlRNwYUTs\n1htv/7AMmJbU+04T+/gu8Iikb1PoGcyT9DzwO6AiqfMLYL6kc4DPU/j0e0PSzTwAeIDCYHSXEBG/\nlnQ08GDSVtspnBt9QtIVwK+TN51dFM7lnkFh+vQFSf0XIuJMFQaIr5PUh0I7/IDC6aDiY4WkmcBX\nI2K0pFnAamAjhbm4GtwC/FjSDmBU0fYvSrqcwu9RwOKI+Hn7tkg+cm7nJ4H/TMoEXBsRL3fwS8ys\no/7mImJnlr/LRv4duDX5f36Uwmm5bclzNwKPS3oE+Hp7tEVb+BvNZmYdJOmB9oiIOklHUei9DInC\njcg6BfcUzMw6Tk9gWXKaSMDnOlNCAPcUzMysiAeazcws5aRgZmYpJwUzM0s5KZiZWcpJwczMUk4K\nZmaW+h/0qLKSxoAxkgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0f71185550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p1 = plt.bar(np.arange(len(features)), best_regressors_mse['AdaBoost'].feature_importances_, width = -0.4, align = 'edge')\n",
    "p2 = plt.bar(np.arange(len(features)), best_regressors_mse['Random Forest'].feature_importances_, width = 0.4, align = 'edge')\n",
    "plt.xticks(np.arange(len(features)), tuple(features))\n",
    "plt.ylabel('Feature Importance')\n",
    "plt.legend((p1, p2), ('AdaBoost', 'Random Forest'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_roc(fpr, tpr, roc_auc, reg_name, lb):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = {0:.2f})'.format(roc_auc))\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.05])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic: {}, Class {}'.format(reg_name, lb))\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "        \n",
    "def get_roc(y_label_true, y_score_pred, class_name):\n",
    "    for x in np.nditer(y_label_true, op_flags=['readwrite']):\n",
    "        if class_name == 'Bad':\n",
    "            x[...] = 1 if x > 0 else 0\n",
    "        elif class_name == 'Good':\n",
    "            x[...] = 0 if x < 2 else 1\n",
    "        else:\n",
    "            print(\"invalid class name\")\n",
    "    fpr, tpr, _ = roc_curve(y_label_true, y_score_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    return (fpr, tpr, roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Good', 'Bad']\n",
    "roc_auc = {}\n",
    "for cn in class_names:\n",
    "    roc_auc[cn] = {}\n",
    "    for k, v in best_regressors_mse.items():\n",
    "        roc_auc[cn][k] = []\n",
    "        for i in range(num_splits):\n",
    "            y_score_pred = v.fit(X_train[i], y_train[i]).predict(X_test[i])\n",
    "            y_label_true = to_label(y_test[i], thresh_scores_mse[k][i][0])  \n",
    "            roc_auc[cn][k].append(get_roc(y_label_true, y_score_pred, cn)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROC AUC for 'Good'\n",
      "AdaBoost\n",
      "0.928\n",
      "MLP\n",
      "0.931\n",
      "Nearest Neighbors\n",
      "0.9\n",
      "Random Forest\n",
      "0.943\n",
      "SVM\n",
      "0.931\n",
      "##################\n",
      "Average ROC AUC for 'Bad'\n",
      "AdaBoost\n",
      "0.974\n",
      "MLP\n",
      "0.982\n",
      "Nearest Neighbors\n",
      "0.972\n",
      "Random Forest\n",
      "0.975\n",
      "SVM\n",
      "0.983\n",
      "##################\n"
     ]
    }
   ],
   "source": [
    "for cn, v in roc_auc.items():\n",
    "    print(\"Average ROC AUC for '{}'\".format(cn))\n",
    "    for k, v1 in v.items():\n",
    "        print(k)\n",
    "        print(np.around(np.average(v1), decimals = 3))\n",
    "    print(\"##################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def make_meshgrid(x, y, h=.02):\n",
    "    x_min, x_max = x.min() - 1, x.max() + 1\n",
    "    y_min, y_max = y.min() - 1, y.max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "\n",
    "def plot_contours(reg_name, xx, yy, **params):\n",
    "    Z = best_regressors_mae[reg_name].predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = to_label(Z, thresh_accuracy_mae[reg_name][0])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = plt.contourf(xx, yy, Z, **params)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "colors = ['red', 'green', 'blue']\n",
    "cmap = mpl.colors.ListedColormap(colors)\n",
    "rg = np.arange(0, 1.01, 0.01)\n",
    "x1, x2, lb = np.array(df_reg['BitRate']), np.array(df_reg['FreezeRatio']), np.array(df_reg['Quality'])\n",
    "xx1, xx2 = make_meshgrid(rg, rg)\n",
    "for reg, name in zip(list(best_regressors_mae.values()), list(best_regressors_mae.keys())):\n",
    "    plot_contours(name, xx1, xx2, cmap=cmap, alpha=0.8)\n",
    "    plt.scatter(x1, x2, c = lb, cmap=cmap, s=20, edgecolors='k')\n",
    "    plt.xlim(rg.min(), rg.max())\n",
    "    plt.ylim(rg.min(), rg.max())\n",
    "    plt.xlabel('Bit Rate')\n",
    "    plt.ylabel('Freeze Ratio')\n",
    "    plt.xticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.title(name)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
