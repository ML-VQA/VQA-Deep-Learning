{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_BATCH_NORM_DECAY = 0.997\n",
    "_BATCH_NORM_EPSILON = 1e-5\n",
    "DEFAULT_VERSION = 2\n",
    "DEFAULT_DTYPE = tf.float32\n",
    "CASTABLE_TYPES = (tf.float16,)\n",
    "ALLOWED_TYPES = (DEFAULT_DTYPE,) + CASTABLE_TYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_normalize(inputs, is_training, dFormat):\n",
    "    return tf.layers.batch_normalization(inputs, axis=1 if dFormat=='channels_first' else 3,\n",
    "                                         momentum=_BATCH_NORM_DECAY, epsilon=_BATCH_NORM_EPSILON,\n",
    "                                         training=is_training, fused=True)\n",
    "\n",
    "def fixed_pad(inputs, ksize, dFormat):\n",
    "    pad_total = ksize - 1\n",
    "    pad_left = pad_total//2\n",
    "    pad_right = pad_total - pad_left\n",
    "\n",
    "    if dFormat == 'channels_first':\n",
    "        return tf.pad(inputs, [[0,0],[0,0],[pad_left,pad_right],[pad_left,pad_right]])\n",
    "    else:\n",
    "        return tf.pad(inputs, [[0,0],[pad_left,pad_right],[pad_left,pad_right],[0,0]])\n",
    "\n",
    "def conv_fixed_pad(inputs, n_filters, k_size, strides, dFormat):    \n",
    "    if strides > 1:\n",
    "        inputs = fixed_pad(inputs, ksize, dFormat)\n",
    "    \n",
    "    return tf.layers.conv2d(inputs=inputs, filters=n_filters, kernel_size=k_size, \n",
    "                            strides=[strides]*2, padding='SAME' if strides==1 else 'VALID',\n",
    "                            data_format=dFormat)\n",
    "\n",
    "def conv_bn(inputs, n_filters, k_size, strides, is_training, dFormat, activation):\n",
    "    inputs = conv_fixed_pad(inputs, n_filters, k_size, strides, dFormat)\n",
    "    inputs = batch_normalize(inputs, is_training, dFormat)\n",
    "    return tf.nn.relu(inputs) if activation == 'RELU' else inputs\n",
    "\n",
    "conv_bn = tf.contrib.framework.add_arg_scope(conv_bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _res_block_v1(inputs, n_filters, strides, is_training, projection_shortcut, dFormat):\n",
    "    shortcut = inputs\n",
    "    \n",
    "    if projection_shortcut is not None:\n",
    "        shortcut = projection_shortcut(shortcut)\n",
    "        shortcut = batch_normalize(inputs=shortcut, is_training=is_training, dFormat=dFormat)\n",
    "    \n",
    "    with tf.contrib.framework.arg_scope([conv_bn], n_filters=n_filters, k_size=3, \n",
    "                                        is_training=is_training, dFormat=dFormat):\n",
    "        inputs = conv_bn(inputs=inputs, strides=strides, activation='RELU')\n",
    "        inputs = conv_bn(inputs=inputs, strides=1, activation=None)\n",
    "    \n",
    "    return tf.nn.relu(inputs + shortcut)\n",
    "\n",
    "def _res_block_v2(inputs, n_filters, strides, is_training, projection_shortcut, dFormat):\n",
    "    shortcut = inputs\n",
    "    inputs = batch_normalize(inputs=inputs, is_training=is_training, dFormat=dFormat)\n",
    "    inputs = tf.nn.relu(inputs)\n",
    "    \n",
    "    if projection_shortcut is not None:\n",
    "        shortcut = projection_shortcut(inputs)\n",
    "\n",
    "    inputs = conv_bn(inputs=inputs, n_filters=n_filters, k_size=3, strides=strides, \n",
    "                     is_training=is_training, dFormat=dFormat, activation='RELU')\n",
    "    inputs = conv_fixed_pad(inputs=inputs, n_filters=n_filters, k_size=3, strides=1, dFormat=dFormat)\n",
    "    \n",
    "    return inputs + shortcut\n",
    "\n",
    "def _bottleneck_res_block_v1(inputs, n_filters, strides, is_training, projection_shortcut, dFormat):\n",
    "    shortcut = inputs\n",
    "    \n",
    "    if projection_shortcut is not None:\n",
    "        shortcut = projection_shortcut(shortcut)\n",
    "        shortcut = batch_normalize(inputs=shortcut, is_training=is_training, dFormat=dFormat)\n",
    "    \n",
    "    with tf.contrib.framework.arg_scope([conv_bn], n_filters=n_filters, is_training=is_training, \n",
    "                                        dFormat=dFormat, activation='RELU'):\n",
    "        inputs = conv_bn(inputs=inputs, k_size=1, strides=1)\n",
    "        inputs = conv_bn(inputs=inputs, k_size=3, strides=strides)\n",
    "    \n",
    "    inputs = conv_bn(inputs=inputs, n_filters=4*n_filters, k_size=1, strides=1, \n",
    "                     is_training=is_training, dFormat=dFormat, activation=None)\n",
    "    \n",
    "    return tf.nn.relu(inputs + shortcut)\n",
    "\n",
    "def _bottleneck_res_block_v2(inputs, n_filters, strides, is_training, projection_shortcut, dFormat):\n",
    "    shortcut = inputs\n",
    "    inputs = batch_normalize(inputs=inputs, is_training=is_training, dFormat=dFormat)\n",
    "    inputs = tf.nn.relu(inputs)\n",
    "    \n",
    "    if projection_shortcut is not None:\n",
    "        shortcut = projection_shortcut(inputs)\n",
    "    \n",
    "    with tf.contrib.framework.arg_scope([conv_bn], n_filters=n_filters, is_training=is_training, \n",
    "                                        dFormat=dFormat, activation='RELU'):\n",
    "        inputs = conv_bn(inputs=inputs, k_size=1, strides=1)\n",
    "        inputs = conv_bn(inputs=inputs, k_size=3, strides=strides)\n",
    "    \n",
    "    inputs = conv_fixed_pad(inputs=inputs, n_filters=4*n_filters, k_size=1, strides=1, dFormat=dFormat)\n",
    "    \n",
    "    return inputs + shortcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_layer(inputs, n_blocks, block_func, bottleneck, \n",
    "                  n_filters, strides, is_training, dFormat, output_name):\n",
    "    # each block chain has a fixed n_filters\n",
    "    \n",
    "    n_filters_out = 4*n_filters if bottleneck else n_filters\n",
    "    \n",
    "    def projection_shortcut(inputs):\n",
    "        return conv_fixed_pad(inputs=inputs, n_filters=filters_out, k_size=1, strides=strides, dFormat=dFormat)    \n",
    "    \n",
    "    # the input is projected to have depth=n_filters in the first block\n",
    "    inputs = block_func(inputs, n_filters, strides, is_training, projection_shortcut, dFormat)\n",
    "    \n",
    "    for _ in n_blocks:\n",
    "        inputs = block_func(inputs, n_filters, 1, is_training, None, dFormat)\n",
    "    \n",
    "    return tf.identity(inputs, output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_Model():\n",
    "    def __init__(self, resnet_size, final_size, n_classes,\n",
    "                 n_filters_initial, block_sizes, block_strides, bottleneck,\n",
    "                 first_conv_size, first_conv_strides, first_pool_size, first_pool_strides,\n",
    "                 version=DEFAULT_VERSION, data_format=None, dtype=DEFAULT_DTYPE):\n",
    "        \n",
    "        self.resnet_size = resnet_size\n",
    "        self.final_size = final_size\n",
    "        self.n_classes = n_classes\n",
    "        self.n_filters_initial = n_filters_initial\n",
    "        self.block_sizes = block_sizes\n",
    "        self.block_strides = block_strides\n",
    "        self.bottleneck = bottleneck  \n",
    "        self.first_conv_size = first_conv_size\n",
    "        self.first_conv_strides = first_conv_strides\n",
    "        self.first_pool_size = first_pool_size\n",
    "        self.first_pool_strides = first_pool_strides\n",
    "        \n",
    "        if version not in {1, 2}:\n",
    "            raise ValueError('Resnet version should be 1 or 2.')\n",
    "        self.version = version\n",
    "        \n",
    "        if data_format not in {'channes_first', 'channels_last'}:\n",
    "            raise ValueError('Data format should be \"channel_first\" or \"channel_last\"')\n",
    "        self.data_format = data_format\n",
    "        \n",
    "        if dtype not in ALLOWED_TYPES:\n",
    "            raise ValueError('dtype must be one of: {}'.format(ALLOWED_TYPES))\n",
    "        self.dtype = dtype\n",
    "        \n",
    "        if bottleneck == True:\n",
    "            if version == 1:\n",
    "                self.block_func = _bottleneck_res_block_v1\n",
    "            else:\n",
    "                self.block_func = _bottleneck_res_block_v2\n",
    "        else:\n",
    "            if version == 1:\n",
    "                self.block_func = _res_block_v1\n",
    "            else:\n",
    "                self.block_func = _res_block_v2\n",
    "    \n",
    "    def _custom_dtype_getter(self, getter, name, shape=None, dtype=DEFAULT_DTYPE, *args, **kwargs):\n",
    "        if dtype in CASTABLE_TYPES:\n",
    "            var = getter(name, shape, tf.float32, *args, **kwargs)\n",
    "            return tf.cast(var, dtype=dtype, name=name + '_cast')\n",
    "        return getter(name, shape, dtype, *args, **kwargs)\n",
    "    \n",
    "    def _model_variable_scope(self):\n",
    "        return tf.variable_scope('resnet_model', custom_getter=self._custom_dtype_getter)\n",
    "    \n",
    "    def __call__(inputs, is_training):\n",
    "        with self._model_variabel_scope():          \n",
    "            if self.data_format == 'channels_first':\n",
    "                inputs = tf.transpose(inputs, [0,3,1,2])\n",
    "\n",
    "            inputs = conv_fixed_pad(inputs=inputs, n_filters=self.n_filters_initial, k_size=self.first_conv_size, \n",
    "                                    strides=self.first_conv_strides, dFormat=self.data_format)\n",
    "\n",
    "            if self.first_pool_size:\n",
    "                inputs = tf.layers.max_pooling2d(inputs=inputs, pool_size=self.first_pool_size,\n",
    "                                                 strides=self.first_pool_strides, padding='SAME',\n",
    "                                                 data_format=self.data_format)\n",
    "                inputs = tf.identity(inputs, 'initial_maxpool')\n",
    "\n",
    "            for i, n_blocks in enumerate(self.block_sizes):\n",
    "                n_filters = self.n_filters * (2**i)\n",
    "                inputs = block_layer(inputs=inputs, n_blocks=n_blocks, block_func=self.block_func, \n",
    "                                     bottleneck=self.bottleneck, n_filters=n_filters, \n",
    "                                     strides=self.block_strides[i], is_training=is_training, \n",
    "                                     dFormat=self.data_format, output_name='block_layer_{}'.format(i))\n",
    "\n",
    "            inputs = tf.nn.relu(batch_normalize(inputs, is_training, self.data_format))\n",
    "\n",
    "            axes = [2, 3] if self.data_format == 'channels_first' else [1, 2]\n",
    "            inputs = tf.reduce_mean(inputs, axes, keepdims=True)\n",
    "            inputs = tf.identity(inputs, 'final_reduce_mean')\n",
    "\n",
    "            inputs = tf.reshape(inputs, [-1, self.final_size])\n",
    "            inputs = tf.layers.dense(inputs=inputs, units=self.n_classes)\n",
    "            inputs = tf.identity(inputs, 'final_dense')\n",
    "            return inputs     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
