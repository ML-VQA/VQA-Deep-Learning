{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list that specifies convolution-pooling architecture\n",
    "# list index indicate layer position in stack; \n",
    "# a pooling layer is represented by a tuple: (pooling type, kernel_size, strides)\n",
    "# a convolution layer is represented by a typle: (filter_height, filter_width, depth)\n",
    "layers = [(5, 5, 6),\n",
    "          ('MAX', (1,2,2,1), (1,2,2,1)),\n",
    "          (5, 5, 16),\n",
    "          ('MAX', (1,2,2,1), (1,2,2,1)),\n",
    "          (5, 5, 60),\n",
    "          ('MAX', (1,2,2,1), (1,2,2,1))]\n",
    "\n",
    "ResNet_block_layers = [(1, 1, 128, 'relu'),\n",
    "                       (3, 3, 128, 'relu'),\n",
    "                       (1, 1, 512, None)]\n",
    "\n",
    "inception_depths = [64, (96, 128), (16, 32), 32]\n",
    "\n",
    "def conv_pool(x, layers):\n",
    "    out = x\n",
    "    n_conv, n_pool = 0, 0\n",
    "    prev_depth = int(x.shape[3])\n",
    "    for l in layers:\n",
    "        if type(l[0]) == int:\n",
    "            n_conv += 1\n",
    "            with tf.variable_scope('conv_{}'.format(n_conv), reuse = tf.AUTO_REUSE):\n",
    "                w = tf.get_variable('filter', initializer=tf.truncated_normal((l[0],l[1],prev_depth,l[2]),0,0.1))\n",
    "                b = tf.get_variable('bias', initializer=tf.zeros(l[2]))\n",
    "            out = tf.nn.relu(tf.nn.conv2d(out, w, strides=(1,1,1,1), padding='SAME') + b)\n",
    "            prev_depth = l[2]\n",
    "        else:\n",
    "            n_pool += 1\n",
    "            out = tf.nn.pool(out, pooling_type=l[0], window_shape=l[1], strides=l[2],\n",
    "                             padding='SAME', name='pool_{}'.format(n_pool))\n",
    "    return out\n",
    "\n",
    "def ResNet_block(x, layers, name):\n",
    "    out = x\n",
    "    n = 0\n",
    "    if int(x.shape[3]) != layers[-1][2]:\n",
    "        print('Input to ResNet block must have the same shape as output of convolution layers')\n",
    "        return\n",
    "    prev_depth = int(x.shape[3])\n",
    "    with tf.variable_scope(name, reuse = tf.AUTO_REUSE):\n",
    "        for l in layers:\n",
    "            n += 1\n",
    "            with tf.variable_scope('conv_'.format(n), reuse = tf.AUTO_REUSE):\n",
    "                w = tf.get_variable('filter', initializer=tf.truncated_normal((l[0],l[1],prev_depth,l[2]),0,0.1))\n",
    "                b = tf.get_variable('bias', initializer=tf.zeros(l[2]))\n",
    "            out = tf.nn.conv2d(out, w, strides=(1,1,1,1), padding='SAME') + b\n",
    "            if l[3] == 'relu':\n",
    "                out = tf.nn.relu(out)\n",
    "            prev_depth = l[2]\n",
    "    return tf.nn.relu(out + x)\n",
    "\n",
    "def Inception_module(x, depths):\n",
    "    layers = [[(1, 1, depths[0])]\n",
    "              [(1, 1, depths[1][0]), (3, 3, depths[1][1])],\n",
    "              [(1, 1, depths[2][0]), (5, 5, depths[2][1])], \n",
    "              [('MAX', (1,3,3,1), (1,1,1,1)), (1, 1, depths[3])]]\n",
    "    out = []\n",
    "    for i in range(4):\n",
    "        with tf.variable_scope('component_{}'.format(i+1), reuse = tf.AUTO_REUSE):\n",
    "            out.append(conv_pool(x, layers[i]))               \n",
    "    return tf.concat(out, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all frames from video downscaled by a factor\\n\"\n",
    "# return an ndarray of shape (n_frames, height, width, channels)\n",
    "\n",
    "def get_frames(path, n_frames, downscale_factor):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    seq = []\n",
    "    count = 0\n",
    "    while True:\n",
    "        success,frame = cap.read()\n",
    "        if count == n_frames or not success:\n",
    "            break\n",
    "        # downscale frame\n",
    "        width = int(frame.shape[1] / downscale_factor)\n",
    "        height = int(frame.shape[0] / downscale_factor)\n",
    "        resized = cv2.resize(frame, (width, height), interpolation = cv2.INTER_AREA)\n",
    "        if resized.shape[0] > resized.shape[1]:\n",
    "            resized = np.transpose(resized, (1,0,2))\n",
    "        seq.append(resized)\n",
    "        count += 1\n",
    "    return np.stack(seq)\n",
    "\n",
    "# mini-batch generator\n",
    "def next_batch(path, labels, n_batches, batch_size, n_frames, downscale_factor):\n",
    "    perm = np.random.permutation(300)\n",
    "    for i in range(n_batches):\n",
    "        x_batch, y_batch = [], []\n",
    "        for j in range(0, batch_size):\n",
    "            all_frames = get_frames(path.format(perm[i*batch_size+j]+1), n_frames, downscale_factor)\n",
    "            #print(all_frames.shape)\n",
    "            x_batch.append(all_frames)\n",
    "            y_batch.append(labels[perm[i*batch_size+j]])\n",
    "        x_batch = np.stack(x_batch)\n",
    "        yield x_batch, y_batch\n",
    "            \n",
    "# generate feature maps for each video in mini-batch\n",
    "# x has shape (batch_size, n_frames, height, width, channels)\n",
    "def get_feature_maps(x):\n",
    "    instances = []\n",
    "    for i in range(x.shape[0]):\n",
    "        instances.append(tf.contrib.layers.flatten(conv_pool(x[i, :, :, :, :], layers)))\n",
    "    return tf.stack(instances, axis=0)\n",
    "\n",
    "def score_to_label(scores, thresh_1, thresh_2):\n",
    "    for x in np.nditer(scores, op_flags=['readwrite']):\n",
    "        if x < thresh_1:\n",
    "            x[...] = 0\n",
    "        elif x < thresh_2:\n",
    "            x[...] = 1\n",
    "        else:\n",
    "            x[...] = 2\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/mallesh/video-qoe-labeling_1/VQA-Deep-Learning/data/set1-4/trace_{}.mp4'\n",
    "height, width, n_channels = 1080, 1920, 3\n",
    "downscale_factor = 8\n",
    "n_frames = 100\n",
    "n_classes = 3\n",
    "n_batches, batch_size = 30, 10\n",
    "n_hidden = 100 # number of hidden cells in LSTM\\n\"\n",
    "X = tf.placeholder(tf.float32, shape=\n",
    "                   (batch_size, n_frames, int(height/downscale_factor), int(width/downscale_factor), n_channels))\n",
    "y = tf.placeholder(tf.int32, shape=(batch_size,))\n",
    "labels = score_to_label(np.loadtxt('/home/mallesh/video-qoe-labeling_1/VQA-Deep-Learning/data/set1-4.txt'), 2, 3.8)\n",
    "X_features = get_feature_maps(X)\n",
    "print(X_features.shape)\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(n_hidden)\n",
    "output, _ = tf.nn.dynamic_rnn(cell, X_features, initial_state = cell.zero_state(batch_size, dtype=tf.float32))\n",
    "with tf.variable_scope('out', reuse = tf.AUTO_REUSE):\n",
    "    w = tf.get_variable('weight', shape=(n_hidden, n_classes))\n",
    "    b = tf.get_variable('bias', initializer=tf.zeros(n_classes))\n",
    "    pred = tf.matmul(output[:,-1,:], w) + b\n",
    "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    loss_summary = tf.summary.scalar('loss', loss)\n",
    "    file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    batch_num = 0\n",
    "    for X_batch, y_batch in next_batch(path, labels, n_batches, batch_size, n_frames, downscale_factor):\n",
    "        print(X_batch.shape)\n",
    "        batch_num += 1\n",
    "        summary_str = loss_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        file_writer.add_summary(summary_str, batch_num)\n",
    "        sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        saver.save(sess, '/tmp/after_batch_{}.ckpt'.format(batch_num))\n",
    "        print(pred.eval(feed_dict={X: X_batch, y: y_batch}))\n",
    "        print(loss.eval(feed_dict={X: X_batch, y: y_batch}))\n",
    "        saver.save(sess, '/tmp/final.ckpt')\n",
    "        file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):    \n",
    "    with open(file, 'rb') as fo:\n",
    "        dic = pickle.load(fo, encoding='bytes')\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'Tensor' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f03d99b529c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_normalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/layers/normalization.py\u001b[0m in \u001b[0;36mbatch_normalization\u001b[0;34m(inputs, axis, momentum, epsilon, center, scale, beta_initializer, gamma_initializer, moving_mean_initializer, moving_variance_initializer, beta_regularizer, gamma_regularizer, beta_constraint, gamma_constraint, training, trainable, name, reuse, renorm, renorm_clipping, renorm_momentum, fused, virtual_batch_size, adjustment)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0m_reuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m       _scope=name)\n\u001b[0;32m--> 780\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    826\u001b[0m       \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \"\"\"\n\u001b[0;32m--> 828\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m   def _add_inbound_node(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0min_deferred_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m             raise ValueError('A layer\\'s `call` method should return a Tensor '\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/layers/normalization.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    612\u001b[0m                                      \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m                                      \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m                                      self.epsilon)\n\u001b[0m\u001b[1;32m    615\u001b[0m     \u001b[0;31m# If some components of the shape got lost due to adjustments, fix that.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py\u001b[0m in \u001b[0;36mbatch_normalization\u001b[0;34m(x, mean, variance, offset, scale, variance_epsilon, name)\u001b[0m\n\u001b[1;32m    828\u001b[0m   \"\"\"\n\u001b[1;32m    829\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"batchnorm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m     \u001b[0minv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariance\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvariance_epsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    831\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0minv\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'Tensor' and 'float'"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[1,2,3], [4,5,6]])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    b = tf.layers.batch_normalization(a, axis = 0)\n",
    "    print(b.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
