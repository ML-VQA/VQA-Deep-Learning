{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Tensorboard logging and visualization\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list that specifies convolution-pooling architecture; \n",
    "# list index indicate layer position in stack; \n",
    "# a pooling layer is represented by a tuple: (pooling type, kernel_size, strides) \n",
    "# a convolution layer is represented by a typle: (filter_height, filter_width, depth)\n",
    "layers = [(5, 5, 6),\n",
    "          ('max', (1,2,2,1), (1,2,2,1)),\n",
    "          (5, 5, 16), \n",
    "          ('max', (1,2,2,1), (1,2,2,1)),\n",
    "          (5, 5, 60),\n",
    "          ('max', (1,2,2,1), (1,2,2,1))]  \n",
    "\n",
    "def conv_pool(x, layers):\n",
    "    out = x\n",
    "    n_conv, n_pool = 0, 0\n",
    "    prev_depth = int(x.shape[3])\n",
    "    for l in layers:\n",
    "        if type(l[0]) == int:\n",
    "            n_conv += 1\n",
    "            with tf.variable_scope('conv_{}'.format(n_conv), reuse = tf.AUTO_REUSE):\n",
    "                w = tf.get_variable('filter', initializer=tf.truncated_normal((l[0], l[1], prev_depth, l[2]),0,0.1))\n",
    "                b = tf.get_variable('bias', initializer=tf.zeros(l[2]))  \n",
    "                out = tf.nn.relu(tf.nn.conv2d(out, w, strides=(1,1,1,1), padding='SAME') + b)\n",
    "            prev_depth = l[2]\n",
    "        elif l[0] == 'max':\n",
    "            n_pool += 1\n",
    "            out = tf.nn.max_pool(out, l[1], l[2], padding='SAME', name='pool_{}'.format(n_pool))\n",
    "        elif l[0] == 'avg':\n",
    "            n_pool += 1\n",
    "            out = tf.nn.avg_pool(out, l[1], l[2], padding='SAME', name='pool_{}'.format(n_pool))\n",
    "    return out\n",
    "\n",
    "# get all frames from video downscaled by a factor\n",
    "# return an ndarray of shape (n_frames, height, width, channels)\n",
    "def get_frames(path, n_frames, downscale_factor):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    seq = []\n",
    "    count = 0\n",
    "    while True:\n",
    "        success,frame = cap.read()\n",
    "        if count == n_frames or not success:\n",
    "            break\n",
    "        # downscale frame\n",
    "        width = int(frame.shape[1] / downscale_factor)\n",
    "        height = int(frame.shape[0] / downscale_factor)\n",
    "        resized = cv2.resize(frame, (width, height), interpolation = cv2.INTER_AREA)\n",
    "        if resized.shape[0] > resized.shape[1]:\n",
    "            resized = np.transpose(resized, (1,0,2))\n",
    "        seq.append(resized)\n",
    "        count += 1\n",
    "    return np.stack(seq)\n",
    "\n",
    "# mini-batch generator\n",
    "def next_batch(path, labels, n_batches, batch_size, n_frames, downscale_factor):\n",
    "    perm = np.random.permutation(300)\n",
    "    for i in range(n_batches):\n",
    "        x_batch, y_batch = [], []\n",
    "        for j in range(0, batch_size):\n",
    "            all_frames = get_frames(path.format(perm[i*batch_size+j]+1), n_frames, downscale_factor)\n",
    "            #print(all_frames.shape)\n",
    "            x_batch.append(all_frames)\n",
    "            y_batch.append(labels[perm[i*batch_size+j]])\n",
    "        x_batch = np.stack(x_batch)\n",
    "        yield x_batch, y_batch\n",
    "        \n",
    "# generate feature maps for each video in mini-batch\n",
    "# x has shape (batch_size, n_frames, height, width, channels)\n",
    "def get_feature_maps(x):\n",
    "    instances = []\n",
    "    for i in range(x.shape[0]):\n",
    "        instances.append(tf.contrib.layers.flatten(conv_pool(x[i, :, :, :, :], layers)))\n",
    "    return tf.stack(instances, axis=0)\n",
    "\n",
    "def score_to_label(scores, thresh_1, thresh_2):\n",
    "    for x in np.nditer(scores, op_flags=['readwrite']):\n",
    "        if x < thresh_1:\n",
    "            x[...] = 0\n",
    "        elif x < thresh_2:\n",
    "            x[...] = 1\n",
    "        else:\n",
    "            x[...] = 2\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "(10, 100, 30600)\n"
     ]
    }
   ],
   "source": [
    "path = '/home/mallesh/video-qoe-labeling_1/VQA-Deep-Learning/data/set1-4/trace_{}.mp4'\n",
    "\n",
    "height, width, n_channels = 1080, 1920, 3\n",
    "downscale_factor = 8\n",
    "n_frames = 100\n",
    "n_classes = 3\n",
    "n_batches, batch_size = 30, 10\n",
    "n_hidden = 100 # number of hidden cells in LSTM\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=\n",
    "                   (batch_size, n_frames, int(height/downscale_factor), int(width/downscale_factor), n_channels))\n",
    "y = tf.placeholder(tf.int32, shape=(batch_size,))\n",
    "\n",
    "labels = score_to_label(np.loadtxt('/home/mallesh/video-qoe-labeling_1/VQA-Deep-Learning/data/set1-4.txt'), 2, 3.8)\n",
    "\n",
    "X_features = get_feature_maps(X)\n",
    "print(X_features.shape)\n",
    "\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(n_hidden)\n",
    "output, _ = tf.nn.dynamic_rnn(cell, X_features, initial_state = cell.zero_state(batch_size, dtype=tf.float32))\n",
    "\n",
    "with tf.variable_scope('out', reuse = tf.AUTO_REUSE):\n",
    "    w = tf.get_variable('weight', shape=(n_hidden, n_classes))\n",
    "    b = tf.get_variable('bias', initializer=tf.zeros(n_classes))\n",
    "    pred = tf.matmul(output[:,-1,:], w) + b\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "training_op = optimizer.minimize(loss)\n",
    "loss_summary = tf.summary.scalar('loss', loss)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 100, 135, 240, 3)\n",
      "[[ 0.4174981  -1.0018234  -0.6342016 ]\n",
      " [ 0.6103216  -0.51104087  0.01119593]\n",
      " [ 0.40747958 -0.27480763 -0.74518925]\n",
      " [ 0.20012076 -0.6476899   0.07149868]\n",
      " [ 0.45678324 -0.28826642 -0.25301382]\n",
      " [ 0.54582065 -0.24579637 -0.26788443]\n",
      " [ 0.6002198  -0.05261083 -0.03244453]\n",
      " [ 0.54348373 -0.9414733  -1.0088395 ]\n",
      " [ 0.22715957 -0.23753387 -0.16339573]\n",
      " [ 0.1973783  -0.64249223 -0.4302865 ]]\n",
      "1.1603103\n",
      "(10, 100, 135, 240, 3)\n",
      "[[ 0.19832787  0.8647749   0.37825832]\n",
      " [ 0.2931341   1.0047479   0.19141704]\n",
      " [ 0.2007918   0.88519174  0.42430237]\n",
      " [ 0.4827534   0.4256199   0.44925913]\n",
      " [ 0.28557256  0.85731757  0.32078674]\n",
      " [ 0.31966028  1.0215192   0.22625132]\n",
      " [ 0.3346729   0.5464126  -0.07177597]\n",
      " [ 0.10489751  0.7356182   0.10347681]\n",
      " [ 0.283435    0.84828556  0.3380723 ]\n",
      " [ 0.25059026  1.0959179   0.0278153 ]]\n",
      "0.99492186\n",
      "(10, 100, 135, 240, 3)\n",
      "[[ 0.14351866  1.2301936   0.6916934 ]\n",
      " [ 0.14351866  1.2301936   0.6916934 ]\n",
      " [-0.11161161  0.8429192   0.2947703 ]\n",
      " [ 0.18260294  1.0078763   0.9544062 ]\n",
      " [ 0.14351866  1.2301936   0.6916934 ]\n",
      " [-0.03938169  1.0203629   0.8076093 ]\n",
      " [-0.17419076  1.2182403   0.7176156 ]\n",
      " [ 0.18260282  1.0078712   0.95440996]\n",
      " [ 0.18569556  1.1395161   0.85619605]\n",
      " [ 0.11791363  0.6694189   0.21372956]]\n",
      "1.0608329\n",
      "(10, 100, 135, 240, 3)\n",
      "[[-0.25400418  1.2631313   0.48853695]\n",
      " [-0.19157866  0.88694847  0.06739835]\n",
      " [-0.21416797  1.0405232   0.75034666]\n",
      " [-0.21416797  1.0405232   0.75034666]\n",
      " [-0.20017937  1.149438    0.54829043]\n",
      " [-0.30934745  1.0161117   0.922083  ]\n",
      " [-0.21416797  1.0405232   0.75034666]\n",
      " [-0.25631177  1.1324884   0.58493185]\n",
      " [-0.21416797  1.0405232   0.75034666]\n",
      " [-0.3095044   1.0160714   0.92236614]]\n",
      "1.1867896\n",
      "(10, 100, 135, 240, 3)\n",
      "[[-0.08423146  0.679803    0.27678493]\n",
      " [-0.1266254   0.7706609   0.11247747]\n",
      " [-0.08423146  0.679803    0.27678493]\n",
      " [-0.2353484   0.8892021  -0.06452824]\n",
      " [-0.08423584  0.6798078   0.27677777]\n",
      " [ 0.23055711  0.7422286   0.20644914]\n",
      " [ 0.38164118  0.5328653   0.54770887]\n",
      " [-0.08423146  0.679803    0.27678493]\n",
      " [-0.26936263  0.926288   -0.11990489]\n",
      " [-0.08423501  0.6798068   0.2767792 ]]\n",
      "1.0571736\n",
      "(10, 100, 135, 240, 3)\n",
      "[[-0.17658073  0.7885169   0.08294588]\n",
      " [-0.17658073  0.7885169   0.08294588]\n",
      " [ 0.04163028  0.55067205  0.43611282]\n",
      " [-0.53910804  0.56507164 -0.38107407]\n",
      " [-0.17658073  0.7885169   0.08294588]\n",
      " [-0.21934354  0.87975    -0.0811491 ]\n",
      " [ 0.39743355  0.52349365  0.5316401 ]\n",
      " [-0.2193447   0.8797513  -0.08115098]\n",
      " [-0.17658073  0.7885169   0.08294588]\n",
      " [-0.17658071  0.7885169   0.08294588]]\n",
      "1.1819468\n",
      "(10, 100, 135, 240, 3)\n",
      "[[-0.20895325  0.8716086  -0.09004941]\n",
      " [-0.20895325  0.8716086  -0.09004941]\n",
      " [-0.20895325  0.8716086  -0.09004941]\n",
      " [-0.1658887   0.7799328   0.07423247]\n",
      " [-0.1658887   0.7799328   0.07423247]\n",
      " [-0.20895325  0.8716086  -0.09004941]\n",
      " [-0.1658887   0.7799328   0.07423247]\n",
      " [-0.1658887   0.7799328   0.07423247]\n",
      " [-0.1658887   0.7799328   0.07423247]\n",
      " [-0.1658887   0.7799328   0.07423247]]\n",
      "0.97361887\n",
      "(10, 100, 135, 240, 3)\n",
      "[[-0.20622873  0.8715941  -0.09444244]\n",
      " [-0.16297738  0.77951646  0.07015328]\n",
      " [-0.20622873  0.8715941  -0.09444244]\n",
      " [-0.16297738  0.77951646  0.07015328]\n",
      " [-0.16297738  0.77951646  0.07015328]\n",
      " [-0.16297738  0.77951646  0.07015328]\n",
      " [-0.20622873  0.8715941  -0.09444244]\n",
      " [-0.16297738  0.77951646  0.07015328]\n",
      " [-0.20622873  0.8715941  -0.09444244]\n",
      " [-0.16297738  0.77951646  0.07015328]]\n",
      "0.809231\n",
      "(10, 100, 135, 240, 3)\n",
      "[[-0.51955646  0.5543073  -0.4018693 ]\n",
      " [-0.51955646  0.5543073  -0.4018693 ]\n",
      " [-0.5630664   0.6468125  -0.5666745 ]\n",
      " [-0.5630664   0.6468125  -0.5666745 ]\n",
      " [-0.5630664   0.6468125  -0.5666745 ]\n",
      " [-0.51955646  0.5543073  -0.4018693 ]\n",
      " [-0.51955646  0.5543073  -0.4018693 ]\n",
      " [-0.51955646  0.5543073  -0.4018693 ]\n",
      " [-0.5630664   0.6468125  -0.5666745 ]\n",
      " [-0.51955646  0.5543073  -0.4018693 ]]\n",
      "1.0531124\n",
      "(10, 100, 135, 240, 3)\n",
      "[[-0.51069176  0.55240345 -0.41416228]\n",
      " [-0.51069176  0.55240345 -0.41416228]\n",
      " [-0.51069176  0.55240345 -0.41416228]\n",
      " [-0.5544759   0.6453202  -0.57911545]\n",
      " [-0.5544759   0.6453202  -0.57911545]\n",
      " [-0.51069176  0.55240345 -0.41416228]\n",
      " [-0.5544759   0.6453202  -0.57911545]\n",
      " [-0.65861666  0.21014026 -0.9239738 ]\n",
      " [-0.51069176  0.55240345 -0.41416228]\n",
      " [-0.51069176  0.55240345 -0.41416228]]\n",
      "0.9191082\n",
      "(10, 100, 135, 240, 3)\n",
      "[[-0.5002209   0.54686326 -0.42552313]\n",
      " [-0.5002209   0.54686326 -0.42552313]\n",
      " [-0.5002209   0.54686326 -0.42552313]\n",
      " [-0.54428256  0.64021033 -0.5906584 ]\n",
      " [-0.54428256  0.64021033 -0.5906584 ]\n",
      " [-0.54428256  0.64021033 -0.5906584 ]\n",
      " [-0.5002209   0.54686326 -0.42552313]\n",
      " [-0.5002209   0.54686326 -0.42552313]\n",
      " [-0.5002209   0.54686326 -0.42552313]\n",
      " [-0.5002209   0.54686326 -0.42552313]]\n",
      "1.0462945\n",
      "(10, 100, 135, 240, 3)\n",
      "[[-0.5350471   0.6355324  -0.60106766]\n",
      " [-0.5350471   0.6355324  -0.60106766]\n",
      " [-0.5350471   0.6355324  -0.60106766]\n",
      " [-0.49068516  0.5417465  -0.435779  ]\n",
      " [-0.49068516  0.5417465  -0.435779  ]\n",
      " [-0.49068516  0.5417465  -0.435779  ]\n",
      " [-0.5350471   0.6355324  -0.60106766]\n",
      " [-0.5350471   0.6355324  -0.60106766]\n",
      " [-0.49068516  0.5417465  -0.435779  ]\n",
      " [-0.49068516  0.5417465  -0.435779  ]]\n",
      "0.937823\n",
      "(10, 100, 135, 240, 3)\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    batch_num = 0\n",
    "    for X_batch, y_batch in next_batch(path, labels, n_batches, batch_size, n_frames, downscale_factor):      \n",
    "        print(X_batch.shape)\n",
    "        batch_num += 1\n",
    "        summary_str = loss_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        file_writer.add_summary(summary_str, batch_num)\n",
    "        sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        saver.save(sess, '/tmp/after_batch_{}.ckpt'.format(batch_num))\n",
    "        print(pred.eval(feed_dict={X: X_batch, y: y_batch}))\n",
    "        print(loss.eval(feed_dict={X: X_batch, y: y_batch}))\n",
    "    \n",
    "    saver.save(sess, '/tmp/final.ckpt')\n",
    "\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
